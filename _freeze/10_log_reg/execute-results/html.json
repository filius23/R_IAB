{
  "hash": "0f3147e5230c500c9e0c4f60122ef9bf",
  "result": {
    "markdown": "# Logistische Regressionsmodelle \n\n\n\n\n\n\nIn diesem Kapitel widmen wir uns dem Fall einer binären abhängigen Variable/Dummyvariable. Für solche Fälle sind logistische Regressionsmodelle gebräuchlich, die sich in Ihrer Anwendung etwas von 'normalen', linearen Regressionsmodellen unterscheiden. Kern dieses Unterschieds ist die Link-Funktion, welche die Koeffizienten etwas schwerer interpretierbar macht - daher haben sich sog. marginal effects als Darstellungsform für Ergebnisse logistischer Regressionen etabliert. \nIn R steht uns dafür das Paket [`{marginaleffects}`](https://vincentarelbundock.github.io/marginaleffects/), welches sich in der Anwendung sehr dem `margins`-Befehl in Stata ähnelt.\n\n\nBisher hatten wir immer Regressionsmodelle betrachtet, die eine metrisch skalierte abhängige Variable hatten.[^1]\nAber gerade Individualmerkmale sind nur selten metrisch skaliert, z.B. Erwerbstatus, Familienstand, Geschlecht, Elternstand, ... Ein lineares OLS-Regressionsmodell wie wir es bisher kennen gelernt haben, hilft uns hier nicht weiter. \nSchauen wir uns beispielsweise die Frage nach der Social Media-Nutzung der Befragten an (`PSM0100`)[^3] :\n\n[^1]: Leseempfehlung: [Logistische Regression von Henning Best & Christof Wolf, S. 827-854 in \"Handbuch der sozialwissenschaftlichen Datenanalyse\"](www.doi.org/10.1007/978-3-531-92038-2_31)\n\n\n\n**Nutzung von sozialen Netzwerken?**\n   \nDie 1 steht dabei jeweils für \"ja\", die `2` für \"nein\". Wir verändern die Codierung aber so, dass die \"nein\"-Antworten mit `0` versehen werden. Die neue Variable nennen wir `soc_med`. \n<!-- Außerdem teilen wir `F518_SUF` durch 100 und legen die so erstellte Variable \"Einkommen in 100EUR\" in `palter` ab, um die Nachkommastellen des Koeffizienten zu reduzieren: -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\npend10 <- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                          col_select = c(\"pnr\",\"welle\",\"zpsex\",\"famstand\",\"palter\",\"PSM0100\")) %>% \n  mutate(across(everything(),~ifelse(.x<0,NA,.x)),\n         soc_med = 2- PSM0100)\n\npend10 %>% count(soc_med,PSM0100)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 3\n  soc_med PSM0100     n\n    <dbl>   <dbl> <int>\n1       0       2  2873\n2       1       1  2589\n3      NA      NA 22962\n```\n:::\n:::\n\n\n## Das logistische Regressionsmodell {#logmod}\n\nSomit sieht unser logistisches Regressionsmodell in der allgemeinen Schreibweise wie folgt aus:\n\n\\begin{equation*}\n\\widehat{Logit(soc\\_med=1)} = \\widehat{ln\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{palter}\n\\end{equation*}\n\nIn R können wir ein solches Modell mit `glm()` und der Option `family=\"binomial\"` berechnen:[^log_fam]\n\n\n[^log_fam]: `family=\"binomial\"` ist dabei entscheidend: `glm(soc_med ~ palter, data = pend10)` oder `glm(soc_med ~ palter, family = gaussian(), data = pend10)` ist gleichbedeutend mit `lm(soc_med ~ palter, data = pend10)`: es wird ein lineares OLS-Modell berechnet.\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- glm(soc_med ~ palter, family = \"binomial\", data = pend10)\nsummary(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = soc_med ~ palter, family = \"binomial\", data = pend10)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1014  -0.9246  -0.4485   0.8999   2.4047  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  3.194321   0.107660   29.67   <2e-16 ***\npalter      -0.073518   0.002315  -31.75   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7557.2  on 5461  degrees of freedom\nResidual deviance: 6217.5  on 5460  degrees of freedom\n  (22962 Beobachtungen als fehlend gelöscht)\nAIC: 6221.5\n\nNumber of Fisher Scoring iterations: 3\n```\n:::\n:::\n\n\nDie Interpretation der $\\beta$ aus einem logistischen Regressionsmodell bezieht sich also auf die Logits (die logarithmierten Odds):  \n\n::: inter\n\nEs besteht ein am 0,001-Niveau signifikanter Zusammenhang zwischen dem Alter und der Wahrscheinlichkeit, Social Media zu verwenden. Mit einem um 1 Jahr Lebensalter Einkommen gehen um 0.073518 niedrigere *Logits* einher, dass die Befragten Social Media zu verwenden.\n:::\n\n## average marginal effects\n\nLogits sind aber sehr unhandlich - wie verändert sich jetzt aber die *Wahrscheinlichkeit* für $\\texttt{soc\\_med} = 1$ mit `palter`? Hier haben wir das Problem, dass die Ableitung der \"rücktransformierten Funktion\" nicht so einfach ist wie im Fall der OLS. Verändern wir nämlich auch die [Regressionsgleichung von oben[^2]](#logmod) mit `exp()` und $p=\\frac{Odds}{1+Odds}$, so landen wir bei \n\n\\begin{equation*}\n\\widehat{P(soc\\_med=1)} = \\frac{e^{\\hat\\beta0+\\hat\\beta1 \\times \\texttt{palter}}}{1+e^{\\hat\\beta0+\\hat{\\beta1}\\times \\texttt{palter}}}\n\\end{equation*}\n\n[^2]: $\\widehat{Logit(soc\\_med=1)} = \\widehat{ln\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{palter}$\n\n\nDiesen Ausdruck müssten wir nach `palter` ableiten, um eine Antwort zu bekommen um wieviel sich die vorhergesagte Wahrscheinlichkeit für $\\texttt{soc\\_med} = 1$ mit einem um einen Jahr höheren Befragtenalter verändert. \nDurch die Tatsache dass `palter` hier im Exponenten der e-Funktion und sowohl im Dividenden als auch Divisor (\"oben und unten\") steht, wird die Ableitung hier aber deutlich komplizierter als das in den bisherigen `lm()`-Modellen der Fall war. \nFür uns ist an dieser Stelle aber nur wichtig, dass wir für die Berechnung der Veränderung der vorhergesagten Wahrscheinlichkeiten die sog. marginalen Effekte aus dem Paket `{marginaleffects}` brauchen. \nDarin findet sich der Befehl `avg_slopes()`, welcher uns erlaubt ein $\\beta$ zwischen dem Einkommen und der _Wahrscheinlichkeit_ für $\\texttt{soc\\_med} = 1$ zu berechnen. Dieses wird auch als *average marginal effect* bezeichnet, da sie den *durchschnittlichen marginalen Effekt* der betrachteten unabhängigen Variable auf die abhängige Variable wiedergeben. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"marginaleffects\") # nur einmal nötig\nlibrary(marginaleffects)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\navg_slopes(m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Term Estimate Std. Error     z Pr(>|z|)   2.5 %  97.5 %\n palter  -0.0142   0.000266 -53.4   <0.001 -0.0147 -0.0137\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high \n```\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n::: inter\n\nMit einem um 1 Jahr höheren Lebensalter geht im Durchschnitt eine um 0.01419 (1.41891 Prozentpunkte) geringere Wahrscheinlichkeit einher, Social Media zu verwenden.\n\n:::\n\n## Predictions {#pred}\n\nAlternativ können die Ergebnisse aus log. Regressionen auch als vorhergesagte Werte dargestellt werden.\nVorhergesagte Werte können wir mit `predictions()` aus `{marginaleffects}` erstellen:\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions(m2, newdata = datagrid(palter  = c(18,25,65))) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n Estimate Pr(>|z|) 2.5 % 97.5 % palter\n    0.867   <0.001 0.850  0.881     18\n    0.795   <0.001 0.777  0.812     25\n    0.170   <0.001 0.155  0.186     65\n\nColumns: rowid, estimate, p.value, conf.low, conf.high, soc_med, palter \n```\n:::\n:::\n\n\nDas können wir in einem `ggplot()` grafisch darstellen:\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions(m2, newdata = datagrid(palter  = 18:65)) %>% # vorhergesagte Werte\n  data.frame() %>% \n  ggplot(aes(y = estimate , x = palter)) + \n  geom_errorbar(aes(ymin = conf.low, ymax= conf.high), color = \"slateblue\",width = .1) + # konfidenzintervalle\n  geom_point(color = \"slateblue\") + # punktschätzer\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-5-1.png){width=576}\n:::\n:::\n\n\n\n## [Übung 1](#ame1)\n\n\n## Fixed effects logistische Regression mit `{fixest}` {#feglm}\n\n\nMit `feglm()` lassen sich auch logistische FE-Modelle schätzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fixest)\nfeglm(soc_med ~ palter |pnr, data = pend10, family = binomial)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNOTES: 22,962 observations removed because of NA values (LHS: 22,962, RHS: 60).\n       2,284 fixed-effects (4,563 observations) removed because of only 0 (or only 1) outcomes.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nGLM estimation, family = binomial, Dep. Var.: soc_med\nObservations: 899 \nFixed-effects: pnr: 332\nStandard-errors: Clustered (pnr) \n       Estimate Std. Error  t value Pr(>|t|) \npalter 0.097697   0.118551 0.824096  0.40988 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood:  -582.6   Adj. Pseudo R2: -0.468364\n           BIC: 3,430.1     Squared Cor.:  0.08793 \n```\n:::\n\n```{.r .cell-code}\nfe_log1 <- feglm(soc_med ~ palter |pnr, data = pend10, family = binomial)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNOTES: 22,962 observations removed because of NA values (LHS: 22,962, RHS: 60).\n       2,284 fixed-effects (4,563 observations) removed because of only 0 (or only 1) outcomes.\n```\n:::\n\n```{.r .cell-code}\navg_slopes(fe_log1,by = TRUE, variables = \"palter\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   Term Estimate Std. Error     z Pr(>|z|)   2.5 % 97.5 %\n palter   0.0223     0.0313 0.711    0.477 -0.0391 0.0837\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high \n```\n:::\n:::\n\n\n\n## Übung {#ame1}\n\n::: {.cell}\n\n```{.r .cell-code}\npend10 <- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                          col_select = c(\"pnr\",\"welle\",\"zpsex\",\"palter\",\"PAS0400\")) %>% \n  mutate(across(everything(),~ifelse(.x<0,NA,.x)),\n         zpsex_fct = factor(zpsex,levels = 1:2, labels = c(\"Männer\",\"Frauen\")),\n         search = 2- PAS0400) %>% \n  filter(!is.na(search))\n```\n:::\n\n\n\n+ Erstellen Sie ein logistisches Regressionsmodell mit `PAS0400` basierend auf der Frage\n\n**Nicht-Erwerbstaetige: Stellensuche in den letzten vier Wochen?**\n\nals abhängiger Variable (1 = ja, 0 = nein.) Verwenden Sie das Alter `palter` als unabhängige Variable. \n\n**Bonusübung**: Stellen Sie die * adjusted predictions* in einem Plot auf Basis der [Predictions](#pred) dar. \n\nBerechnen Sie die AME mit `marginaleffects`.\n\n\n## Anhang: Hintergrund zu log. Regression & average marginal effects\n\nWenn wir uns fragen, ob sich Befragte mit höherem Einkommen seltener im Freien arbeiten, hilft uns die OLS-Vorgehensweise nicht so richtig weiter. Die \"Punktewolke\" zur Optimierung der Abweichung zwischen tatsächlichen und vorhergesagten Werten (Residuen) sieht hier anders aus als bisher:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(pend10, aes(x = palter, y = soc_med)) +\n  geom_point(color = \"#172869\") +\n  theme(aspect.ratio = .75)\n```\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=336}\n:::\n:::\n\nUm trotzdem ein Regressionsmodell zu berechnen, könnten wir die abhängige Variable uminterpretieren. $\\hat{y}$ wird dann nicht mehr dichotom, sondern als metrische Wahrscheinlichkeit interpretiert, dass der Befragte mehr als die Hälfte der Arbeitszeit im Freien arbeitet (also die Wahrscheinlichkeit für soc_med = 1). Das können wir dann wie gehabt in eine Regressionsgleichung aufnehmen, zB. mit dem Einkommen als unabhängiger Variable:   \n\n\\begin{equation*}\n\\widehat{y_i} = P(soc\\_med\\texttt{\\small{=}}1) = \\hat\\beta0 + \\hat\\beta1 * \\texttt{palter}_i\n\\end{equation*}\n\nAllerdings führt das zwangsläufig zu Verstößen gegen die Annahmen bzgl. der Residuen - die Fehler werden immer heteroskedastisch und nicht normalverteilt sein. Zudem wird es vorhergesagte Werte geben, die nicht sinnvoll interpretiert werden können, weil es mit 0 und 1 Grenzen gibt, jenseits derer Wahrscheinlichkeiten nicht existieren (zB gibt es keine negativen Wahrscheinlichkeiten).\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nggplot(pend10, aes(x = palter, y = soc_med)) +\n  geom_point(color = \"#172869\", size = .75) +\n  geom_smooth(method = \"lm\", color = lacroix_palette(\"PeachPear\",6)[2],se = F ) + \n  labs(y = \"P(soc_med = 1)\", x = \"Einkommen (in 100 EUR)\",\n       title = \"lineares Wahrscheinlichkeitsmodell\")\n```\n\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=480}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggfortify)\nautoplot(m1,which = 1:2) # Homosk. & NV \n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n### Logistische Linkfunktion\nUm diese Probleme zu umgehen, sind für dichotome abhängige Variablen logistische Regressionsmodelle ein sehr verbreitetes Vorgehen. Dafür werden neben dem bereits angesprochenen Schritt der Betrachtung von $\\hat{y}$ als Wahrscheinlichkeit zwei weitere Transformationen der abhängigen Variable vorgenommen:\n\n- *Odds statt Wahrscheinlichkeiten*: Um die obere Grenze des Wertebereichs der abhängigen Variablen auf $+\\infty$ auszudehnen, werden statt Wahrscheinlichkeiten Odds betrachtet. Odds sind definiert als der Quotient aus Wahrscheinlichkeit und der Gegenwahrscheinlichkeit für ein gegebenes Ereignis. In unserem Beispiel sind also die Odds dafür, dass ein*e Befragte*r angibt, social media zu nutzen:\n\n$$Odds(soc\\_med=1) = \\frac{P(soc\\_med=1)}{P(soc\\_med=0)}= \\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)} $$ \n\nDie Odds gehen gegen 0, je unwahrscheinlicher das betrachtete Ereignis ist. Für sehr wahrscheinliche Ereignisse nehmen die Odds Werte an, die gegen $+\\infty$ gehen, das Verhältnis zwischen Dividend (\"Zähler\") und Divisor (\"Nenner\") wird immer größer.\n\n- *Logits statt Odds*: Damit bleibt aber noch das Problem der negativen Werte bestehen: Auch Odds sind nur für [0;$+\\infty$] definiert. Um auch den negativen Wertebereich sinnvoll interpretierbar zu machen, werden die Odds logarithmiert, wir erhalten die sogenannten Logits: \n\n$$Logit(soc\\_med=1) = log(Odds(soc\\_med=1)) = log\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)$$ \n\nDie Logarithmierung führt für Werte zwischen 0 und 1 zu negativen Werten, für Werte größer als 1 zu positiven Werten. \n\nDementsprechend gibt es bei logistischen Regressionen drei Einheiten:\n\n + Wahrscheinlichkeiten $P = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl aller Möglichkeiten}}$\n \n + $\\text{Odds} = \\frac{P}{1-P} = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}}$\n \n + $\\text{log-Odds/Logits} = log(Odds) = log( \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}})$\n\n  \n  \n<br>  \n\n\n::: {.cell}\n::: {.cell-output-display}\n```{=html}\n<div id=\"equljyomcz\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>html {\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#equljyomcz .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: hidden;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: hidden;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#equljyomcz .gt_heading {\n  background-color: #FFFFFF;\n  text-align: right;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#equljyomcz .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#equljyomcz .gt_title {\n  color: #333333;\n  font-size: small;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#equljyomcz .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#equljyomcz .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#equljyomcz .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#equljyomcz .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#equljyomcz .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#equljyomcz .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#equljyomcz .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#equljyomcz .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#equljyomcz .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#equljyomcz .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#equljyomcz .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#equljyomcz .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#equljyomcz .gt_row {\n  padding-top: 1px;\n  padding-bottom: 1px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#equljyomcz .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#equljyomcz .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#equljyomcz .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#equljyomcz .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#equljyomcz .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#equljyomcz .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#equljyomcz .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#equljyomcz .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#equljyomcz .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#equljyomcz .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#equljyomcz .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#equljyomcz .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#equljyomcz .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#equljyomcz .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#equljyomcz .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#equljyomcz .gt_left {\n  text-align: left;\n}\n\n#equljyomcz .gt_center {\n  text-align: center;\n}\n\n#equljyomcz .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#equljyomcz .gt_font_normal {\n  font-weight: normal;\n}\n\n#equljyomcz .gt_font_bold {\n  font-weight: bold;\n}\n\n#equljyomcz .gt_font_italic {\n  font-style: italic;\n}\n\n#equljyomcz .gt_super {\n  font-size: 65%;\n}\n\n#equljyomcz .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#equljyomcz .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#equljyomcz .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#equljyomcz .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#equljyomcz .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#equljyomcz .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#equljyomcz .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" style=\"table-layout: fixed;; width: 0px\">\n  <colgroup>\n    <col style=\"width:120px;\"/>\n    <col style=\"width:200px;\"/>\n    <col style=\"width:100px;\"/>\n    <col style=\"width:200px;\"/>\n  </colgroup>\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"$$P$$\">$$P$$</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"$$Odds = \\frac{P}{1-P}$$\">$$Odds = \\frac{P}{1-P}$$</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"\"></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"$$Logits = log(Odds)$$\">$$Logits = log(Odds)$$</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{2}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$1$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:1</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>0</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{3}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$0.5$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:2</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>-0.6931</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{4}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$0.33$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:3</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>-1.0986</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{5}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$0.25$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 1:5</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>-1.3863</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{2}{3}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$2$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 2:1</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>0.6931</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{3}{4}$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$3$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>oder 3:1</p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>1.0986</p>\n</div></td></tr>\n    <tr><td headers=\"p\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$1$$</p>\n</div></td>\n<td headers=\"odds1\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>$$\\frac{1}{0}$$</p>\n</div></td>\n<td headers=\"odds2\" class=\"gt_row gt_right\"><div class='gt_from_md'><p><em>sicher</em></p>\n</div></td>\n<td headers=\"logodds\" class=\"gt_row gt_right\"><div class='gt_from_md'><p>Inf</p>\n</div></td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\n\n\n### Vorhergesagte Werte\n\nZunächst stellt sich die Frage, was Logits denn bedeuten. Eigentlich möchten wir ja Wahrscheinlichkeiten im Wertebereich zwischen 0 und 1 (bzw. 0% und 100%) als Interpretationseinheit haben. Die Berechnung eines vorhergesagten Werts für einen Befragten mit einem Alter von 25 Jahren (`palter`=25) ergibt durch einsetzen bzw. `predict()` natürlich auch die Logits:\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m2)$coefficients\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Estimate  Std. Error   z value      Pr(>|z|)\n(Intercept)  3.1943207 0.107659911  29.67048 1.846515e-193\npalter      -0.0735175 0.002315329 -31.75251 2.931805e-221\n```\n:::\n\n```{.r .cell-code}\n3.1943207    + -0.0735175  * 25\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.356383\n```\n:::\n\n```{.r .cell-code}\npredict(m2, data.frame(palter = 25))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n1.356383 \n```\n:::\n:::\n\n\n    \n::: inter\n\nBefragte mit einem Alter von 25 Jahren haben dem Modell zu Folge Logits von 1.35638, social media zu verwenden.\n\n:::\n\nUm an die Wahrscheinlichkeit für `soc_med` = 1 zu bekommen, müssen wir die Transformationsschritte sozusagen \"rückabwickeln\"! Dafür müssen wir zunächst mit `exp` den `ln()` vor den Odds heraus rechnen und können dann durch die die Formel $p=\\frac{Odds}{1+Odds}$ die Wahrscheinlichkeit aus den odds berechnen:\n\n::: {.cell}\n\n```{.r .cell-code}\nlogits <- predict(m2, data.frame(palter = 25)) \nexp(logits) # Odds statt Logits\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1 \n3.882127 \n```\n:::\n\n```{.r .cell-code}\nodds <- exp(logits) \nodds/(1+odds) # Wahrscheinlichkeit statt Odds \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n0.7951712 \n```\n:::\n\n```{.r .cell-code}\nexp(logits)/(1+exp(logits)) # beide Schritte auf einmal\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n0.7951712 \n```\n:::\n:::\n\n\n    \n::: inter\n\nDie Wahrscheinlichkeit, dass ein Befragter mit einem Einkommen von 1000 Euro angibt, mehr als die Hälfte Ihrer Arbeitszeit im Freien zu arbeiten, liegt also unserem Modell zu Folge bei 92.123\\%.   \n\n::: \n\nMit der Option `type=\"response\"` können wir das auch mit `predict()` direkt berechnen:\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(m2, data.frame(palter = 25), type=\"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        1 \n0.7951712 \n```\n:::\n:::\n\n\n### Die Idee von average marginal effects\n\nWie verändern sich dann die vorhergesagten Werte, wenn wir `palter` um eine Einheit (also 100€) erhöhen? Die Logits verändern sich pro Einheit `palter` natürlich genau um $\\hat\\beta1$, also hier -0.07352. Um sich die Steigung an einigen Werten anzusehen, berechnen wir jeweils die Abstände der vorhergesagten Werte für $x-0.5$ und $x+0.5$:\n\n\n*Um die Werte jeweils mit dem eingesetzten Wert zu beschriften, stellen wir den Wert mit * `\"\"=` *voran:*\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(m2, data.frame(palter=c(\"19.5\"=19.5,\"20.5\"=20.5,\"30.5\"=30.5,\"31.5\"=31.5,\n                                \"54.5\"=54.5,\"55.5\"=55.5)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      19.5       20.5       30.5       31.5       54.5       55.5 \n 1.7607294  1.6872119  0.9520369  0.8785194 -0.8123832 -0.8859007 \n```\n:::\n:::\n\n\nDie Differenzen sind immer gleich - entsprechend der Interpretation gehen mit einem um eine Einheit höheren `palter` um 0.07352 höhere Logits einher, dass die Befragten Social Media verwenden:\n\n+ Steigung bei `palter` = 20: 1.68721 $-$ 1.76073 = -0.07352  \\quad\\textsf{\\small{Vorhersage bei 20.5 - Vorhersage bei 19.5}}\n\n+ Steigung bei `palter` = 31: 0.87852 $-$ 0.95204 = -0.07352  \\quad\\textsf{\\small{Vorhersage bei 56.5 - Vorhersage bei 30.5}}\n\n+ Steigung bei `palter` = 45: -0.88590 $-$ -0.81238 = -0.07352  \\quad\\textsf{\\small{Vorhersage bei 55.5 - Vorhersage bei 54.5}}\n\nWenn wir uns diese Schritte aber jeweils für die vorhergesagten Wahrscheinlichkeiten ansehen, sieht das aber anders aus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(m2, data.frame(palter=c(\"19.5\"=19.5,\"20.5\"=20.5,\"30.5\"=30.5,\"31.5\"=31.5,\n                                \"54.5\"=54.5,\"55.5\"=55.5)), type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     19.5      20.5      30.5      31.5      54.5      55.5 \n0.8533010 0.8438571 0.7215246 0.7065153 0.3073829 0.2919565 \n```\n:::\n:::\n\n\nHier werden die Differenzen mit zunehmendem `palter` immer kleiner:\n\n+ Steigung bei `palter` = 20: 0.84386 $-$ 0.85330 = -0.00944  \\quad\\textsf{\\small{Vorhersage bei 20.5 - Vorhersage bei 19.5}}\n\n+ Steigung bei `palter` = 31: 0.70652 $-$ 0.72152 = -0.01501  \\quad\\textsf{\\small{Vorhersage bei 31.5 - Vorhersage bei 30.5}}\n\n+ Steigung bei `palter` = 55: 0.29196 $-$ 0.30738 = -0.01543  \\quad\\textsf{\\small{Vorhersage bei 55.5 - Vorhersage bei 54.5}}\n\n\n\n\n\n::: {.cell layout-align=\"center\" fig.caption='true'}\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/AME1-1.png){fig-align='center' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\" fig.caption='true'}\n::: {.cell-output-display}\n![](10_log_reg_files/figure-html/AME2-1.png){fig-align='center' width=672}\n:::\n:::\n\nDiese Steigungen werden für alle Beobachtungen aus dem zu Grunde liegenden Datensatz aufsummiert und dann der Durchschnitt gebildet ($\\rightarrow$ *average* marginal effects)\n\n\n## Links\n\n+ [Die Seite zu `{marginaleffects}`](https://vincentarelbundock.github.io/marginaleffects/articles/marginaleffects.html) bietet sehr ausführliche und anschauliche Beispiele zu den verschiedenen Varianten marginaler Effekte\n\n+ [Ausführliche Einführung zu marginalen Effekten von Andrew Heiss](https://www.andrewheiss.com/blog/2022/05/20/marginalia/)\n\n\n[Ableitungen grafisch erstellt](https://twitter.com/allison_horst/status/1554921698742468625?s=11&t=Ac_YizlsYkOfUIkuWmaaWQ)\n",
    "supporting": [
      "10_log_reg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}