[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R am IAB",
    "section": "",
    "text": "Willkommen\nEine Einführung in R für Mitarbeitende am IAB.\n\n\n\n\n\n\n\n\n\nKursinformationen\n\n   12.06., 13.06., 16.06. & 19.06.2023\n   8:30 – 15:30 Uhr\n   E09"
  },
  {
    "objectID": "01_intro.html#installation-und-einrichten-von-r-rstudio",
    "href": "01_intro.html#installation-und-einrichten-von-r-rstudio",
    "title": "1  Einstieg in R",
    "section": "1.1 Installation und Einrichten von R & RStudio",
    "text": "1.1 Installation und Einrichten von R & RStudio\nBei R handelt es sich um ein vollständig kostenloses Programm, das Sie unter CRAN herunterladen können. Ebenfalls kostenlos ist die Erweiterung RStudio, die Sie unter hier herunterladen können. RStudio erweitert R um eine deutlich informativere und ansprechendere Oberfläche, Hilfe und Auto-Vervollständigung beim Schreiben von Syntax und insgesamt eine verbesserte Nutzeroberfläche. Jedoch ist RStudio eine Erweiterung von R, sodass Sie beide Programme benötigen.\n\n\n\n\n\n\nInstallieren Sie zuerst R und dann RStudio, dann erkennt RStudio die installierte R-Version und die beiden Programme verbinden sich in der Regel automatisch. R ist dabei sozusagen der Motor, RStudio unser Cockpit. Wir könnten direkt mit R arbeiten, aber mit RStudio haben wir eine komfortablere Option und einen besseren Überblick.\n\n\n\n\n\n\n\n \n\n\nFigure 1.1: R und RStudio"
  },
  {
    "objectID": "01_intro.html#rstudio-einrichten",
    "href": "01_intro.html#rstudio-einrichten",
    "title": "1  Einstieg in R",
    "section": "1.2 RStudio einrichten",
    "text": "1.2 RStudio einrichten\nÖffnen Sie nach erfolgreicher Installation die Anwendung RStudio  und Sie sollten folgende Ansicht vor sich sehen:\n\nUm Probleme bei der künftigen Arbeit mit R zu vermeiden, deaktivieren Sie bitte das automatische Speichern und Laden des Workspace. Rufen Sie dazu das entsprechende Menü unter dem Reiter “Tools -&gt; Global options” auf und deaktivieren Sie bitte “Restore .RData into workspace at startup” und setzen Sie “Save workspace to .RData on exit:” auf Never. RStudio speichert ansonsten alle geladenen Objekte wenn Sie die Sitzung beenden und lädt diese automatisch wenn Sie das Programm das nächste Mal öffnen. Dies führt erfahrungsgemäß zu Problemen.\n\nBestätigen Sie die Einstellungen mit “Apply” und schließen Sie das Fenster mit “OK”."
  },
  {
    "objectID": "01_intro.html#erste-schritte-in-r",
    "href": "01_intro.html#erste-schritte-in-r",
    "title": "1  Einstieg in R",
    "section": "1.3 Erste Schritte in R",
    "text": "1.3 Erste Schritte in R\nNach diesen grundlegenden Einstellungen können wir uns an die ersten Schritte in R machen. Öffnen Sie dazu zunächst ein Script, indem Sie auf das weiße Symbol links oben klicken oder drücken Sie gleichzeitig STRG/Command + Shift + N .\n\nEs öffnet sich ein viertes Fenster, sodass Sie nun folgende Ansicht vor sich haben sollten:\n\nDieser Scripteditor ist der Ort, an dem wir Befehle erstellen und anschließend durchführen werden. Der Scripteditor dient dabei als Sammlung aller durchzuführenden Befehle. Wir können diese Sammlungen speichern, um sie später wieder aufzurufen und vor allem können wir so Befehlssammlungen mit anderen teilen oder Skripte von anderen für uns selbst nutzen. Wir entwerfen also zunächst im Scripteditor eine Rechnung:\n\nUm diese nun auszuführen, klicken wir in die auszuführende Zeile, sodass der Cursor in dieser Zeile ist und drücken gleichzeitig STRG und Enter (Mac-User Command und Enter):\n\n\n\n\n\n\n\n\n\n\nFigure 1.2: Shortcuts für Berechnungen\n\n\nR gibt die Ergebnisse unten in der Console aus:\n\nDas funktioniert auch für mehrere Rechnungen auf einmal indem wir mehrere Zeilen markieren und dann wieder STRG und Enter (Mac-User Command und Enter) drücken:\n\nEingaben aus dem Script-Editor und Ergebnisse aus der Konsole werden in Zukunft so dargestellt:\n\n2+5\n\n[1] 7\n\n3-4\n\n[1] -1\n\n5*6\n\n[1] 30\n\n7/8\n\n[1] 0.875\n\n\nR beherrscht natürlich auch längere Berechnungen, zum Beispiel wird auch Punkt vor Strich beachtet:\n\n2+3*2\n\n[1] 8\n\n(2+3)*2\n\n[1] 10\n\n\nAuch weitere Operationen sind möglich:\n\n4^2 ## 4²\nsqrt(4) ## Wurzel \nexp(1) ## Exponentialfunktion (Eulersche Zahl)\nlog(5) ## Natürlicher Logarithmus\nlog(exp(5)) ## log und exp heben sich gegenseitig auf\n\nZahlenreihen können wir mit seq() oder : erstellen:\n\n2:6\n\n[1] 2 3 4 5 6\n\nseq(2,11,3)\n\n[1]  2  5  8 11\n\n\n\n1.3.1 Objekte erstellen\nBisher haben wir uns unsere Berechnungen immer direkt ausgeben lassen. Für umfangreichere Berechnungen - wir wollen ja ab dem nächsten Kapitel mit Datensätzen arbeiten - wollen wir aber die Zwischenschritte speichern.\nErgebnisse lassen sich mit einem &lt;- unter einem beliebigen Namen als Objekt speichern. Dann wird R uns nicht das Ergebnis anzeigen, sondern den Befehl in der Konsole wiederholen:\n\nx &lt;- 4/2\n\nIm Fenster “Environment” rechts oben sehen wir jetzt das abgelegte Objekt x:\n\nWir können es später wieder aufrufen:\n\nx\n\n[1] 2\n\n\nAußerdem können wir Objekte in Rechnungen weiter verwenden - wir setzen einfach x ein und erstellen zB. y:\n\ny &lt;- x * 5\ny\n\n[1] 10\n\n\n\n\n\n1.3.2 Mehrere Werte ablegen\nMit c() lassen sich mehrere Werte unter einem Objekt ablegen und auch mit diesen lässt sich rechnen:\n\nx1 &lt;- c(1,2,3)\nx1\n\n[1] 1 2 3\n\nx1* 2\n\n[1] 2 4 6\n\n\nMit length() können wir die Anzahl der abgelegten Werte nachsehen:\n\nlength(x1)\n\n[1] 3\n\n\n\ny1 &lt;- c(10,11,9)\ny1\n\n[1] 10 11  9\n\ny1/x1\n\n[1] 10.0  5.5  3.0\n\n\n\n\n1.3.3 Werte löschen\nNatürlich können wir Objekte auch wieder löschen und zwar mit rm(). Wenn wir ein nicht existierendes Objekt aufrufen bekommen wir eine Fehlermeldung:\n\nrm(x1)\nx1\n\nError in eval(expr, envir, enclos): Objekt 'x1' nicht gefunden\n\n\nMit rm(list = ls()) können alle Objekte aus dem Environment gelöscht werden.\n\n\n1.3.4 Scripte speichern\nDas Script können wir speichern, um es später wieder aufzurufen.\n\nWichtig ist dabei, der gespeicherten Datei die Endung “.R” zu geben, also zum Beispiel “01_Script.R”.\n\n\n1.3.5 Kommentare\nNeben den eigentlichen Befehlen sind Kommentare ein zentraler Bestandteil einer Datenanalyse-Syntax. Nur so können künftige Nutzende (insbesondere wir selbst in 3 Wochen oder 2 Jahren) nachvollziehen was passiert. Kommentare in R können mit # eingefügt werden:\n\n2+ 5 # hier steht ein Kommentar\n\n[1] 7\n\n2+ # auch hier kann ein Kommentar stehen\n  5\n\n[1] 7\n\n\n\n( 2 + # ein\n    3) * # kommentar\n  2 # über mehrere Zeilen\n\n[1] 10\n\n\nTipp: Erstellen Sie sich am besten sofort einen Ordner, in dem Sie alle R Scripte und Datensätze aus dieser Veranstaltung gesammelt ablegen.\n\n\n1.3.6 Skripte strukturieren\n\n# Überschrift 1 ----\n\n## Abschnit 1.1 ----\n3+2*4\n3+2*3\n## Abschnit 1.2 ----\n3+2*sqrt(3)\n\n# Überschrift 2 ----\nx &lt;- c(2,6,8,2,35)\ny &lt;- seq(2,10,2)\n\ny/x"
  },
  {
    "objectID": "01_intro.html#übungen",
    "href": "01_intro.html#übungen",
    "title": "1  Einstieg in R",
    "section": "1.4 Übungen",
    "text": "1.4 Übungen\n\nLegen Sie eine Zahlenreihe von 7 bis 13 an. Wie können Sie die Zahlenreihe mit seq() anpassen, sodass nur die ungeraden Zahlen generiert werden?\nLegen Sie die Anzahl der Studierenden an der Uni Oldenburg (15643) unter stud ab.\nLegen Sie die Anzahl der Professuren an der Uni Oldenburg (210) unter prof ab.\nBerechnen Sie die Anzahl der Studierenden pro Professur an der Uni Oldenburg indem Sie die Objekte stud und prof verwenden.\nLegen Sie das Ergebnis unter studprof ab und rufen Sie das das Objekt noch einmal auf!\nSehen Sie die erstellten Variablen im Environment-Fenster?\nLegen Sie die Studierendenzahlen der Uni Bremen (19173), Uni Vechta (5333) und Uni Oldenburg (15643) zusammen unter studs ab.\nLegen Sie die Zahl der Profs der Uni Bremen (322), Uni Vechta (67) und Uni Oldenburg (210) zusammen unter profs ab.\nBerechnen die Anzahl der Studierenden pro Professur für alle drei Universitäten.\nSie möchten zusätzlich die Zahl der Studierenden (14000) und Professuren (217) der Uni Osnabrück in studs und profs ablegen. Wie gehen Sie vor?\nBerechnen Sie für alle vier Universitäten das Verhältnis von Studierenden und Professuren!\nLöschen Sie das Objekt stud. Woran erkennen Sie, dass das funktioniert hat?\nLöschen Sie alle Objekte aus dem Environment. Woran erkennen Sie, dass das funktioniert hat?"
  },
  {
    "objectID": "02_intro.html#datenstrukturen-in-r-data.frame",
    "href": "02_intro.html#datenstrukturen-in-r-data.frame",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.1 Datenstrukturen in R: data.frame",
    "text": "2.1 Datenstrukturen in R: data.frame\nIm vorherigen Kapitel haben wir die Studierendenzahlen der Uni Bremen (19173), Uni Vechta (5333) und Uni Oldenburg (15643) zusammen unter studs abgelegt und mit den in profs abgelegten Professurenzahlen ins Verhältnis gesetzt. Das funktioniert soweit gut, allerdings ist es übersichtlicher, zusammengehörige Werte auch zusammen ablegen. Dafür gibt es in R data.frame. Wir können dazu die beiden Objekte in einem Datensatz ablegen, indem wir sie in data.frame eintragen und das neue Objekt unter dat1 ablegen. Wenn wir dat1 aufrufen sehen wir, dass die Werte zeilenweise zusammengefügt wurden:\n\nstuds &lt;- c(19173,5333,15643)    # Studierendenzahlen unter \"studs\" ablegen \nprofs       &lt;- c(322,67,210)    # Prof-Zahlen unter \"profs\" ablegen\ndat1_orig &lt;- data.frame(studs, profs)\ndat1_orig\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\n\n\n\ndat1 &lt;- data.frame(studs = c(19173,5333,15643), \n                   profs = c(322,67,210),\n                   gegr  = c(1971,1830,1973)) # ohne zwischen-Objekte\ndat1    # zeigt den kompletten Datensatz an\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\n\nIn der ersten Zeile stehen also die Werte der Uni Bremen, in der zweiten Zeile die Werte der Uni Vechta usw. Die Werte können wir dann mit datensatzname$variablenname aufrufen. So können wir die Spalte profs anzeigen lassen:\n\ndat1$profs \n\n[1] 322  67 210\n\n\nMit colnames()/names() können wir die Variablen-/Spaltennamen des Datensatzes anzeigen lassen, zudem können wir mit nrow und ncol die Zahl der Zeilen bzw. Spalten aufrufen:\n\ncolnames(dat1) ## Variablen-/Spaltennamen anzeigen\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nnames(dat1) ## Variablen-/Spaltennamen anzeigen\n\n[1] \"studs\" \"profs\" \"gegr\" \n\nncol(dat1) ## Anzahl der Spalten/Variablen\n\n[1] 3\n\nnrow(dat1) ## Anzahl der Zeilen/Fälle\n\n[1] 3\n\n\nNeue zusätzliche Variablen können durch datensatzname$neuevariable in den Datensatz eingefügt werden:\n\ndat1$stu_prof &lt;- dat1$studs/dat1$profs\n## dat1 hat also nun eine Spalte mehr:\nncol(dat1) \n\n[1] 4\n\ndat1\n\n  studs profs gegr stu_prof\n1 19173   322 1971 59.54348\n2  5333    67 1830 79.59701\n3 15643   210 1973 74.49048\n\n\nWir können auch ein oder mehrere Wörter in einer Variable ablegen, jedoch müssen Buchstaben/Wörter immer in \"\" gesetzt werden.\n\ndat1$uni &lt;- c(\"Uni Bremen\",\"Uni Vechta\", \"Uni Oldenburg\")\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nMit View(dat1) öffnet sich zudem ein neues Fenster, in dem wir den gesamten Datensatz ansehen können:\n\nView(dat1)"
  },
  {
    "objectID": "02_intro.html#datentypen-in-r",
    "href": "02_intro.html#datentypen-in-r",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.2 Datentypen in R",
    "text": "2.2 Datentypen in R\nDamit haben wir bisher zwei Variablentypen kennen gelernt: numeric (enthält Zahlen) und character (enthält Text oder Zahlen, die als Text verstanden werden sollen). Zudem haben wir eine Organisationsmöglichkeit kennengelernt: data.frame.\nFür uns sind es folgende Variablentypen in R wichtig:2\n\n\n\n\n\n\n\n\n\n\n\n\n\nVektoren\n\n\n\n\n\ninteger\ndouble\n\n\nNumerische Werte (numeric)\n\n\n\n\ncharacter\n\n\nText (oder als Text verstandende Zahlen)\n\n\n\n\nfactor\n\n\nText oder als Text verstandende Zahlen mit vorgegebener Sortierung und fixem Werteuniversum\n\n\n\n\nlogical\n\n\nTRUE oder FALSE - meist das Ergebnis eines Vergleichs (größer/kleiner/gleich)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nZusammengefasste Vektoren\n\n\n\n\n\ndata.frame\ntibble\n\n\nZweidimensionale Datenstruktur, die in Tabellenform organisiert ist - tibble sind eine Weiterentwicklung des data.frame im tidyverse (mehr dazu gleich)\n\n\n\n\nlist\n\n\nGeordnete Sammlung von Vektoren unterschiedlicher Typen - kann andere Wertetypen, data.frame oder sogar andere Listen enthalten\n\n\n\n\n\n\n\n\nVorerst fokussieren wir uns auf character und numerische Variablen. Die weiteren Typen, besprechen wir wenn sie nötig sind. Mit class() kann die Art der Variable untersucht werden oder mit is.numeric() bzw. is.character() können wir abfragen ob eine Variable diesem Typ entspricht:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\nclass(dat1$uni)\n\n[1] \"character\"\n\nis.numeric(dat1$profs)\n\n[1] TRUE\n\nis.character(dat1$profs)\n\n[1] FALSE\n\n\nMit as.character() bzw. as.numeric() können wir einen Typenwechsel erzwingen:\n\nas.character(dat1$profs) ## die \"\" zeigen an, dass die Variable als character definiert ist\n\n[1] \"322\" \"67\"  \"210\"\n\n\nDas ändert erstmal nichts an der Ausgangsvariable dat1$profs:\n\nclass(dat1$profs)\n\n[1] \"numeric\"\n\n\nWenn wir diese Umwandlung für dat1$profs behalten wollen, dann müssen wir die Variable überschreiben:\n\ndat1$profs &lt;- as.character(dat1$profs)\ndat1$profs \n\n[1] \"322\" \"67\"  \"210\"\n\nclass(dat1$profs)\n\n[1] \"character\"\n\n\nMit character-Variablen kann nicht gerechnet werden, auch wenn sie Zahlen enthalten:\n\ndat1$profs / 2 \n\nError in dat1$profs/2: nicht-numerisches Argument für binären Operator\n\n\nWir können aber natürlich dat1$profs spontan mit as.numeric umwandeln, um mit den Zahlenwerten zu rechnen:\n\nas.numeric(dat1$profs)\n\n[1] 322  67 210\n\nas.numeric(dat1$profs) / 2\n\n[1] 161.0  33.5 105.0\n\n\nWenn wir Textvariablen in numerische Variablen umwandeln, bekommen wir NAs ausgegeben. NA steht in R für fehlende Werte:\n\nas.numeric(dat1$uni)\n\nWarning: NAs durch Umwandlung erzeugt\n\n\n[1] NA NA NA\n\n\nR weiß (verständlicherweise) also nicht, wie die Uni-Namen in Zahlen umgewandelt werden sollen.\n\n\n\n\n\n\nNicht selten ist ein Problem bei einer Berechnung auf den falschen Variablentypen zurückzuführen."
  },
  {
    "objectID": "02_intro.html#zeilen-spalten-auswählen",
    "href": "02_intro.html#zeilen-spalten-auswählen",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.3 Zeilen & Spalten auswählen",
    "text": "2.3 Zeilen & Spalten auswählen\nEine typische Aufgabe in der Arbeit mit Datensätzen ist die Auswahl von Zeilen (“Fällen”) und Spalten (“Variablen”).\nDazu stellt uns R in der Basisversion3 eine Auswahlmöglichkeit zur Verfügung, welche [ ] verwendet. Die grundlegende Struktur ist dabei [Zeilenauswahl, Spaltenauswahl]. Lassen wir den Part vor oder nach dem Komma leer, werden alle Zeilen/Spalten ausgewählt. Achtung: das vergessene Komma ist wohl einer der Fehlerquellen in R.\n\ndat1 # vollständiger Datensatz\ndat1[1,1] # erste Zeile, erste Spalte\ndat1[1,]  # erste Zeile, alle Spalten\ndat1[,1]  # alle Zeilen, erste Spalte (entspricht hier dat1$studs)\ndat1[,\"studs\"] # alle Zeilen, Spalte mit Namen studs -&gt; achtung: \"\"\n\nIn diese eckigen Klammern können wir auch Bedingungen schreiben, um so Auswahlen aus dat1 zu treffen.\n\ndat1[dat1$studs &gt; 10000, ] # Zeilen in denen studs größer 10000, alle Spalten\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg\n\ndat1[dat1$studs &gt; 10000 & dat1$profs &lt; 300, ] # & bedeutet UND\n\n  studs profs gegr stu_prof           uni\n3 15643   210 1973 74.49048 Uni Oldenburg\n\ndat1$profs[dat1$studs &gt; 10000] # Nur Prof-Zahl nachsehen: kein Komma \n\n[1] \"322\" \"210\"\n\n\n\n2.3.1 Übung\nDie Wiederholung des Datensatznamens in den [ ] macht die Syntax aber recht lang und etwas schreibintensiv. Daher gibt es eine bessere/bequemere Lösung. Dazu verwenden wir das Paket {dplyr}4."
  },
  {
    "objectID": "02_intro.html#packages",
    "href": "02_intro.html#packages",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.4 Pakete in R",
    "text": "2.4 Pakete in R\nPakete sind Erweiterungen für R, die zusätzliche Funktionen beinhalten.  Pakete müssen einmalig installiert werden und dann vor der Verwendung in einer neuen Session (also nach jedem Neustart von R/RStudio) geladen werden. install.packages() leistet die Installation, mit library() werden die Pakete geladen:\n\ninstall.packages(\"Paket\") # auf eurem PC nur einmal nötig\nlibrary(Paket) # nach jedem Neustart nötig\n\nHäufig werden bei install.packages() nicht nur das angegebene Paket, sondern auch eine Reihe weiterer Pakete heruntergeladen, die sog. “dependencies”. Das sind Pakete, welche im Hintergrund verwendet werden, um die Funktionen des eigentlich gewünschten Pakets zu ermöglichen. Also nicht erschrecken, wenn die Installation etwas umfangreicher ausfällt.\nMit install.packages() schrauben wir sozusagen die Glühbirne in R, mit library() betätigen wir den Lichtschalter, sodass wir die Befehle aus dem Paket auch verwenden können. Mit jedem Neustart geht die Glühbirne wieder aus und wir müssen sie mit library() wieder aktivieren. Das hat aber den Vorteil, dass wir nicht alle Glühbirnen auf einmal anknipsen müssen, wenn wir R starten.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninstall.packages() im IAB-Netzwerk\n\n\n\nAufgrund der VPN-Einstellungen im IAB muss in R folgende Option gesetzt werden, damit Downloads möglich sind:\noptions(download.file.method = \"wininet\")\nDazu bieten sich zwei Möglichkeiten:\n\nnach jedem Neustart von RStudio vor install.packages() mit setzen:\n\n\noptions(download.file.method = \"wininet\")\ninstall.packages()\n\n\ndiese Option permanent “verankern”: wer den Befehl nicht zu Beginn jeden R-Scripts aufführen möchte, kann ihn in die Rprofile-Datei (Rprofile.site) mit globalen Einstellungen aufnehmen. Diese Datei liegt beim BIBB Arbeitsgerät unter folgendem Pfad: C:\\RforWindows_4_2_1\\etc Mehr zu RProfile\n\n\n\n\n\n\n\n\n\nPakete einmalig laden\n\n\n\n\n\nNeben library() gibt es auch die Möglichkeit, Funktionen aus Paketen mit :: aufzurufen:\n\npaket::function()\n\nDiese Option wird häufig verwendet, wenn lediglich eine Funktion aus einem Paket einmalig verwendet wird und oder um deutlich zu machen, aus welchem Paket die verwendete Funktion kommt. Das kann auch bei Problemen mit einem Befehl hilfreich sein: evtl. wurde ein weiteres Paket mit einem gleichnamigen Befehl geladen - dann wird der erste Befehl überschrieben (meist mit einer Warnung), die bespielweise so aussehen kann:\n\nDie folgenden Objekte sind maskiert von ‘package:dplyr’:\n\n    between, first, last\n\nDas folgende Objekt ist maskiert ‘package:purrr’:\n\n    transpose\n\nDas kann umgangen werden, wenn gewisse Pakte gar nicht vollständig geladen, sondern lediglich die nötigen Funktionen mit :: aufgerufen werden.\n\n\n\n\n\n\n\n\n\nAllgemeine Lösung für install.packages() wenn keine Internetverbindung besteht\n\n\n\n\n\nUnter R Packages können die benötigten Pakete heruntergeladen werden. Nachdem wir das Paket als .zip-Datei gespeichert haben, wir mit folgendem Befehl das Paket in der R-Umgebung installieren:\n\n# Installation von Paket \"XML\"\ninstall.packages(\"E:/XML_3.98-1.3.zip\", repos = NULL, type = \"source\")"
  },
  {
    "objectID": "02_intro.html#tidyverse",
    "href": "02_intro.html#tidyverse",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.5 {tidyverse}",
    "text": "2.5 {tidyverse}\nWir werden in diesem Kurs vor allem mit Paketen aus dem {tidyverse} arbeiten. tidyverse ist eine Sammlung an Paketen, die übergreifende Syntaxlogik haben und so besonders gut miteinander harmonisieren und eine riesige Bandbreite an Anwendungsfällen abdecken. Mit\n\ninstall.packages(\"tidyverse\")\n\nwerden folgende Pakete installiert:\nbroom, conflicted, cli, dbplyr, dplyr, dtplyr, forcats, ggplot2, googledrive, googlesheets4, haven, hms, httr, jsonlite, lubridate, magrittr, modelr, pillar, purrr, ragg, readr, readxl, reprex, rlang, rstudioapi, rvest, stringr, tibble, tidyr, xml2, tidyverse\nWir werden einige im Laufe des Kurses kennen lernen. Das zunächst wichtigste ist {dplyr}, welches unter anderem die Auswahl von Fällen und Variablen erleichtert:\n\n\n\n\n\nDarstellung basierend auf dem {dplyr} Cheatsheet\n\n\n\n\n\ninstall.packages(\"tidyverse\") \n# installiert die komplette Paketsammlung des tidyverse\n\nEine Installation ist aber nur der erste Schritt, jetzt müssen wir mit library() noch das Paket laden:\n\nlibrary(tidyverse) # nach einmaligem install.packages(\"tidyverse\")"
  },
  {
    "objectID": "02_intro.html#zeilen-auswählen-mit-slice",
    "href": "02_intro.html#zeilen-auswählen-mit-slice",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.6 Zeilen auswählen mit slice()",
    "text": "2.6 Zeilen auswählen mit slice()\nEine erste Funktion aus dem {tidyverse} ist slice(), mit welcher wir Zeilen auswählen können:\n\nslice(dat1,1) # erste Zeile\nslice(dat1,2:3) # Zeile 2-3\nslice(dat1,c(1,3)) # Zeile 1 und 3"
  },
  {
    "objectID": "02_intro.html#filter",
    "href": "02_intro.html#filter",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.7 Beobachtungen auswählen mit filter()",
    "text": "2.7 Beobachtungen auswählen mit filter()\nMit filter() können wir Zeilen aus dat1 mit Hilfe von Bedingungen auswählen:\n\nfilter(dat1,uni == \"Uni Oldenburg\", studs &gt; 1000)\n\n  studs profs gegr stu_prof           uni\n1 15643   210 1973 74.49048 Uni Oldenburg\n\n\nDie Auswahl ändert das Ausgangsobjekt dat1 aber nicht:\n\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\nMöchten wir das Ergebnis unserer Auswahl mit filter() für weitere Schritte behalten, können wir unser Ergebnis in einem neuen data.frame-Objekt ablegen:\n\nueber_10tsd &lt;- filter(dat1, studs &gt; 10000)\nueber_10tsd\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n\n\n\n2.7.1 Auswahloperatoren\nR und {dplyr} stellen uns einige weitere Operatoren zur Auswahl von Zeilen zu Verfügung:\n\n&lt;= und &gt;=\n| oder\n%in% “eines von”\nbetween() ist eine Hilfsfunktion aus {dplyr} für Wertebereiche\n\n\nfilter(dat1, studs &gt;= 10000)\nfilter(dat1, studs &lt;= 10000)\nfilter(dat1,studs &gt; 10000 | profs &lt; 200) # mehr als 10.000 Studierende *oder* weniger als 200 Professuren\nfilter(dat1, gegr %in% c(1971,1830)) # gegründet 1971 oder 1830\nfilter(dat1, between(gegr,1971,1830)) # gegründet zwischen 1971 und 1830 (einschließlich)"
  },
  {
    "objectID": "02_intro.html#select",
    "href": "02_intro.html#select",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.8 Variablen auswählen mit select()",
    "text": "2.8 Variablen auswählen mit select()\nMit select() enthält {dplyr} auch einen Befehl zu Auswahl von Spalten/Variablen:\n\ndat1\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\nselect(dat1, studs,profs)\n\n  studs profs\n1 19173   322\n2  5333    67\n3 15643   210\n\n\nWir können auch hier einige Operatoren verwenden: : um einen Bereich auszuwählen oder ! als “nicht”-Operator:\n\nselect(dat1, 1:3) # Spalte 1-3\n\n  studs profs gegr\n1 19173   322 1971\n2  5333    67 1830\n3 15643   210 1973\n\nselect(dat1, !profs) # alles außer profs\n\n  studs gegr stu_prof           uni\n1 19173 1971 59.54348    Uni Bremen\n2  5333 1830 79.59701    Uni Vechta\n3 15643 1973 74.49048 Uni Oldenburg\n\n\nAuch hier gilt: wenn wir die Veränderungen auch weiter verwenden wollen, müssen wir sie in einem neuen Objekt ablegen:\n\ndat_ohne_profs &lt;- select(dat1, !profs) \ndat_ohne_profs\n\n  studs gegr stu_prof           uni\n1 19173 1971 59.54348    Uni Bremen\n2  5333 1830 79.59701    Uni Vechta\n3 15643 1973 74.49048 Uni Oldenburg\n\ndat1 # unverändert\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg\n\n\n\n2.8.1 Hilfsfunktionen\nselect() hat außerdem einige Hilfsfunktionen, welche die Variablenauswahl auf Basis der Variablennamen einfacher machen.\n\ncontains(\"b\"): Variablenname enthält ..., bspw. select(dat1,contains(\"b\"))\nmatches(): Variablenauswahl mit einer regular expression, bspw. select(dat1,matches(\"b$\")): alle Variablen mit b am Ende des Namens.\n\nEs gibt noch einige weitere Hilfsfunktionen, für eine vollständige Auflistung ?select_helpers.\n\n\n2.8.2 Übung"
  },
  {
    "objectID": "02_intro.html#pipe",
    "href": "02_intro.html#pipe",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.9 Arbeiten mit der Pipe: filter() und select() kombinieren",
    "text": "2.9 Arbeiten mit der Pipe: filter() und select() kombinieren\nWenn wir jetzt aber einige Zeilen und einige Spalten auswählen möchten, dann können wir filter() und select() kombinieren:\n\nselect(filter(dat1,studs &lt; 10000),uni)\n\n         uni\n1 Uni Vechta\n\n\nDiese Befehlsschachtel können wir mit der sog. Pipe %&gt;% auflösen. %&gt;% steht einfach für “und dann”. Die Pipe kommt aus dem Paket {magrittr}, welches wiederum Teil des tidyverse ist und automatisch mit {dplyr} geladen wird.\n\nfilter(dat1,studs &lt; 10000) %&gt;% select(uni)\n\n         uni\n1 Uni Vechta\n\n\nHäufig wird die Pipe dann so verwendet, dass zu Beginn lediglich der zu bearbeitende Datensatz steht und sich dann die Schritte anschließen:\n\ndat1 %&gt;% filter(.,studs &lt; 10000) %&gt;% select(.,uni)\n\n         uni\n1 Uni Vechta\n\n\nDer Punkt . steht jeweils für das Ergebnis des vorherigen Schritts. Hier also:\n\nRufe dat1 auf und dann (%&gt;%)\nWähle nur Zeilen aus in denen studs &lt; 10000 und dann (%&gt;%)\nBehalte nur die Spalte uni\n\nDan Punkt können wir auch weglassen:\n\ndat1 %&gt;% filter(studs &lt; 10000) %&gt;% select(uni)\n\n         uni\n1 Uni Vechta\n\n\n\n\n\n\n\n\n%&gt;% kann mit STRG+SHIFT+m (cmd+shift+m für Mac) eingefügt werden."
  },
  {
    "objectID": "02_intro.html#variablentyp-factor---eigene-reihenfolgen-festlegen",
    "href": "02_intro.html#variablentyp-factor---eigene-reihenfolgen-festlegen",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.10 Variablentyp factor - eigene Reihenfolgen festlegen",
    "text": "2.10 Variablentyp factor - eigene Reihenfolgen festlegen\nEin weitere häufige Aufgabe in der Datenanalyse ist das Sortieren von Datensätzen. Dazu haben wir arrange() zur Verfügung:\n\ndat1 %&gt;% arrange(studs)\n\n  studs profs gegr stu_prof           uni\n1  5333    67 1830 79.59701    Uni Vechta\n2 15643   210 1973 74.49048 Uni Oldenburg\n3 19173   322 1971 59.54348    Uni Bremen\n\n\nDas funktioniert auch für string-Variablen:\n\ndat1 %&gt;% arrange(uni)\n\n  studs profs gegr stu_prof           uni\n1 19173   322 1971 59.54348    Uni Bremen\n2 15643   210 1973 74.49048 Uni Oldenburg\n3  5333    67 1830 79.59701    Uni Vechta\n\n\nWas aber, wenn wir eine fixe Ordnung vergeben möchten, die nicht der numerischen oder alphabetischen Ordnung entspricht? Hier bspw. wenn wir die Unis in folgende Ordnung bringen möchten: 1) Uni Oldenburg, 2) Uni Bremen und 3) Uni Vechta. Dabei hilft uns ein dritter Variablentyp: factor.\nMit dem Argument levels = können wir eine Reihenfolge festlegen:\n\nfactor(dat1$uni, levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\n[1] Uni Bremen    Uni Vechta    Uni Oldenburg\nLevels: Uni Oldenburg Uni Bremen Uni Vechta\n\ndat1$uni_fct &lt;- factor(dat1$uni,\n                       levels = c(\"Uni Oldenburg\", \"Uni Bremen\", \"Uni Vechta\"))\n\nWenn wir nun nach uni_fct sortieren, dann wird die Reihenfolge der levels berücksichtigt:\n\nclass(dat1$uni_fct)\n\n[1] \"factor\"\n\ndat1 %&gt;% arrange(uni_fct)\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n\n\nMit desc() können wir in umgekehrter Reihenfolge sortieren:\n\ndat1 %&gt;% arrange(desc(uni_fct))\n\n  studs profs gegr stu_prof           uni       uni_fct\n1  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\nDas mag für den Moment relativ trivial erscheinen, ist aber später sehr praktisch um in Grafiken Variablen in eine gewisse Ordnung zu bringen oder in Regressionsmodellen die Referenzkategorie festzulegen.\nNatürlich können wir auch nach mehreren Variablen sortieren, dazu fügen wir einfach weitere in arrange() ein:\n\ndat1 %&gt;% arrange(desc(uni_fct), gegr, studs)\n\n  studs profs gegr stu_prof           uni       uni_fct\n1  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n2 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\n\n(Macht in diesem Beispiel aber wenig Sinn)\n\n2.10.1 Übung"
  },
  {
    "objectID": "02_intro.html#import",
    "href": "02_intro.html#import",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.11 Datensätze einlesen",
    "text": "2.11 Datensätze einlesen\nIn der Regel werden wir aber Datensätze verwenden, deren Werte bereits in einer Datei gespeichert sind und die wir lediglich einlesen müssen. Dafür gibt es unzählige Möglichkeiten.\nIn diesem Seminar werden wir mit dem Campus-File des PASS arbeiten, dessen Teile als Stata-Dateien vorliegen.\nUm den Datensatz nun in R zu importieren, müssen wir R mitteilen unter welchem Dateipfad der Datensatz zu finden ist. Der Dateipfad ergibt sich aus der Ordnerstruktur Ihres Gerätes, so würde der Dateipfad im hier dargestellten Fall “D:/Kurse/R-Kurs/” lauten:\nNatürlich hängt der Dateipfad aber ganz davon ab, wo Sie den Datensatz gespeichert haben:\n\n\n\n\n\n\n\n\n\nDiesen Dateipfad müssen wir also R mitteilen.\n\n2.11.1 Projekt einrichten\nGrundsätzlich lohnt es sich, in RStudio Projekte einzurichten. Projekte sind .Rproj-Dateien , die automatisch Arbeitsverzeichnis auf den Ort setzen, an dem sie gespeichert sind. Das erleichtert das kollaborative Arbeiten: egal wer und auf welchem Gerät gerade an einem Projekt arbeitet - durch die Projektdatei sind alle Pfade immer relativ zum Projektverzeichnis. Im weiteren können auch Versionkontrolle via git, bspw. github und weitere Funktionen in der Projektdatei hinterlegt werden und so für alle Nutzenden gleich gesetzt werden. Außerdem bleiben die zuletzt geöffneten Scripte geöffnet, was ein Arbeiten an mehreren Projekten erleichtert.\n\n\n\n\n\n\n\n\n\nMit getwd() lässt sich überprüfen, ob das funktioniert hat:\n\ngetwd()\n\n\n\n[1] \"D:/Kurse/R-Kurs\"\n\n\n\n\n\n\n\n\n\n\n\nAlternativ könnten wir auch mit folgendem Befehl ein .Rproj - Projekt erstellen (hier ein Beispiel für den Aufruf eines Pakets mit ::):\n\nrstudioapi::initializeProject(path = \"D:/Kurse/R-Kurs\")\n\n\n\n2.11.2 Der Einlesebefehl\nJetzt können wir den eigentlichen Einlesebefehl read.table verwenden. Für den Pfad können wir nach file = lediglich die Anführungszeichen angeben und innerhalb dieser die Tab-Taste drücken. Dann bekommen wir alle Unterverzeichnisse und Tabellen im Projektordner angezeigt.5\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\") \n\nDer Einlesevorgang besteht aus zwei Teilen: zuerst geben wir mit pend den Objektnamen an, unter dem R den Datensatz ablegt. Nach dem &lt;- steht dann der eigentliche Befehl read_dta(), der wiederum mehrere Optionen enthält. Als erstes geben wir den genauen Datensatznamen an - inklusive der Dateiendung.\n\n\n\n\n\n\nR hat Probleme mit Windows-typischen \\ in Datenpfaden\n\n\n\n\n\nLeider nutzen Windows-Systeme \\ in den Dateipfaden - das führt in R zu Problemen. Daher müssen Dateipfade immer mit / oder alternativ mit \\\\ angegeben werden. RStudio kann zumindest mit der STRG + F/der Suchen & Ersetzen Funktion etwas unterstützen.\n\n\n\nDas so erstellte Objekt ist ein data.frame:\n\nclass(pend)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nGenau genommen handelt es sich um ein tibble - das ist eine Weiterentwicklung von data.frames im tidyverse, welcher u.a. Labels enthält und außerdem in der Darstellung einige zusätzliche Informationen enthält - in der ersten Zeile stehen bspw. die Variablenklassen.\nWürden hier jetzt einfach pend eintippen bekämen wir den kompletten Datensatz angezeigt. Für einen Überblick können wir head verwenden:\n\nhead(pend)\n\n# A tibble: 6 × 123\n     pnr    hnr welle   pintj…¹ pintmon pintmod  zpsex   palter PD0400    PA0100\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt; &lt;dbl+&gt;\n1 1.00e9 1.00e7 1 [Wel… 2007    5 [Mai]  1 [CAP… 2 [Wei… 36       2 [Ehe… 8     \n2 1.00e9 1.00e7 1 [Wel… 2007    5 [Mai] NA       1 [Mae… 39       2 [Ehe… 8     \n3 1.00e9 1.00e7 3 [Wel… 2009    3 [Mae…  1 [CAP… 2 [Wei… 38      -9 [Ite… 9     \n4 1.00e9 1.00e7 1 [Wel… 2007    4 [Apr…  1 [CAP… 1 [Mae… 66     -10 [Ite… 8     \n5 1.00e9 1.00e7 1 [Wel… 2007    4 [Apr…  1 [CAP… 2 [Wei… 61       3 [Ehe… 2     \n6 1.00e9 1.00e7 2 [Wel… 2008    5 [Mai]  1 [CAP… 2 [Wei… 62       3 [Ehe… 2     \n# … with 113 more variables: PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nMit nrow und ncol können wir kontrollieren, ob das geklappt hat. Der Datensatz sollte 28424 Zeilen und 123 Spalten haben:\n\nnrow(pend)\n\n[1] 28424\n\nncol(pend)\n\n[1] 123\n\n\nNatürlich können wir wie oben auch aus diesem, viel größeren, Datensatz Zeilen und Spalten auswählen. Zum Beispiel können wir die Daten aus dem Jahr 2006 auswählen und diese unter pend06 ablegen:\n\npend06 &lt;- pend %&gt;% filter(pintjahr == 2006)\n\nAußerdem hat pend06 natürlich deutlich weniger Zeilen als pend:\n\nnrow(pend06)\n\n[1] 168\n\n\nMöchten wir die genauen Altersangaben der Befragten aus pend06 sehen, können wir die entsprechende Spalte mit pend06$palter aufrufen:\n\npend06$palter\n\n&lt;labelled&lt;double&gt;[168]&gt;: Alter (Welle 1: gen. aus P1; ab Welle 2: beste Inf.), generiert\n  [1] 71 66 64 64 63 51 64 65 26 38 41 63 58 58 69 45 59 37 28 63 56 29 29 49 47\n [26] 66 34 22 21 37 36 58 56 80 44 65 61 66 40 53 34 70 69 54 65 62 58 54 51 57\n [51] 72 52 25 34 55 44 68 73 46 87 74 83 46 40 62 58 66 41 53 71 66 79 54 42 68\n [76] 68 81 92 70 66 68 77 44 66 66 67 62 43 35 35 52 54 20 48 48 20 41 24 22 33\n[101] 55 41 50 36 19 52 25 36 37 29 37 36 43 49 16 59 28 19 43 44 30 43 50 50 53\n[126] 52 71 43 58 58 58 38 49 30 27 50 58 26 36 44 28 19 42 44 23 20 33 24 31 32\n[151] 31 44 50 58 45 57 37 62 46 52 50 47 40 62 40 19 28 35\n\nLabels:\n value                                   label\n   -10 Item in Fragebogenversion nicht erhoben\n    -9             Item in Welle nicht erhoben\n    -8                       Unplausibler Wert\n    -4        Frage irrtuemlich nicht gestellt\n    -3                Trifft nicht zu (Filter)\n    -2                            Keine Angabe\n    -1                             Weiss nicht\n\n\nWie wir beim Überblick gesehen haben, gibt es aber noch deutlich mehr Variablen im PASS als palter und nicht alle haben so aussagekräftige Namen - z.B. PD0400. Um diese Variablennamen und auch die Bedeutung der Ausprägungen zu verstehen brauchen wir das Codebuch. Außerdem können wir auf die attributes() einer Variable zurückgreifen - mehr zu labels später.\n\n\n2.11.3 Übung"
  },
  {
    "objectID": "02_intro.html#objekte-exportieren",
    "href": "02_intro.html#objekte-exportieren",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.12 Objekte exportieren",
    "text": "2.12 Objekte exportieren\n\n\n\n\n\n\n\n\n\n\nDer Begriff speichern kann in R bisweilen zu Missverständnissen führen: Ist gemeint, einen Datensatz o.ä. (1) auf der Festplatte als .csv, .dta, .sav für andere Programme zugänglich abzulegen oder (2) lediglich die Ergebnisse intern in R unter einem Objektnamen abzulegen? Ich vermeide daher das Wort speichern und spreche entweder von exportieren (Fall 1: in eine Datei schreiben) oder ablegen (Fall 2: Ergebnisse/Werte innerhalb von R in einem Objekt ablegen)\n\n\nWir können data.frames exportieren und später wieder einlesen, das R-eigene Format dafür ist .RData:\n\nsaveRDS(pend06, file = \"./data/pend06.RData\")\nrm(pend06)\n\npend06_neu &lt;- readRDS(file = \"./data/pend06.RData\")\nhead(pend06) # gibt es nicht mehr\n\nError in head(pend06): Objekt 'pend06' nicht gefunden\n\nhead(pend06_neu) # das gibt es\n\n# A tibble: 6 × 123\n     pnr    hnr welle   pintj…¹ pintmon  pintmod zpsex   palter PD0400    PA0100\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+&gt; &lt;dbl+lbl&gt; &lt;dbl+&gt;\n1 1.00e9 1.00e7 1 [Wel… 2006    12 [Dez… 0 [CAT… 1 [Mae… 71     -10 [Ite… 2     \n2 1.00e9 1.00e7 1 [Wel… 2006    12 [Dez… 0 [CAT… 2 [Wei… 66     -10 [Ite… 9     \n3 1.00e9 1.00e7 1 [Wel… 2006    12 [Dez… 0 [CAT… 2 [Wei… 64       3 [Ehe… 9     \n4 1.00e9 1.00e7 1 [Wel… 2006    12 [Dez… 0 [CAT… 1 [Mae… 64       3 [Ehe… 8     \n5 1.00e9 1.00e7 1 [Wel… 2006    12 [Dez… 0 [CAT… 2 [Wei… 63       1 [Ueb… 7     \n6 1.00e9 1.00e7 1 [Wel… 2006    12 [Dez… 0 [CAT… 1 [Mae… 51       1 [Ueb… 7     \n# … with 113 more variables: PA0200 &lt;dbl+lbl&gt;, PA0300 &lt;dbl+lbl&gt;,\n#   PA0445 &lt;dbl+lbl&gt;, PA0800 &lt;dbl+lbl&gt;, PA0900 &lt;dbl+lbl&gt;, PA1000 &lt;dbl+lbl&gt;,\n#   PSM0100 &lt;dbl+lbl&gt;, PEO0100a &lt;dbl+lbl&gt;, PEO0100b &lt;dbl+lbl&gt;,\n#   PEO0100c &lt;dbl+lbl&gt;, PEO0100d &lt;dbl+lbl&gt;, PEO0100e &lt;dbl+lbl&gt;,\n#   PEO0200a &lt;dbl+lbl&gt;, PEO0200b &lt;dbl+lbl&gt;, PEO0200c &lt;dbl+lbl&gt;,\n#   PEO0200d &lt;dbl+lbl&gt;, PEO0300a &lt;dbl+lbl&gt;, PEO0300b &lt;dbl+lbl&gt;,\n#   PEO0300c &lt;dbl+lbl&gt;, PEO0300d &lt;dbl+lbl&gt;, PEO0300e &lt;dbl+lbl&gt;, …\n\n\nAuch andere Objekte können wir exportieren und dann wieder einlesen - hier wird aber der Objektname wiederhergestellt:\n\nsave(studs, file = \"./data/stud_vektor.RData\")\nrm(studs)\nstuds\nload(file = \"./data/stud_vektor.RData\") # studs wieder mit selbem Namen zurück im environment\nstuds\n\nDas funktioniert auch für mehrere Objekte:\n\nsave(studs,profs, file = \"./data/meine_vektoren.RData\")\nrm(studs,profs)\nstuds\nprofs\nload(file = \"./data/meine_vektoren.RData\") # studs & profs mit selbem Namen zurück im environment\nstuds\nprofs\n\n\n2.12.1 Übung"
  },
  {
    "objectID": "02_intro.html#überblick-einlesen-und-exportieren",
    "href": "02_intro.html#überblick-einlesen-und-exportieren",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.13 Überblick: Einlesen und Exportieren",
    "text": "2.13 Überblick: Einlesen und Exportieren\n\n2.13.1 Datensätze einlesen\n\nÜberblickCode\n\n\n\n\n\n\n\nDateityp\nR Funktion\nR Paket\nAnmerkung\n\n\n\n\n.csv\nread.table()\n-\nmit `sep = \";\"` Trennzeichen angeben\n\n\n.Rdata (R format)\nreadRDS\n-\n\n\n\ngroße .csv\nvroom()\n{vroom}\nmit `delim = \";\"` Trennzeichen angeben\n\n\n.dta (Stata)\nread_dta()\n{haven}\n\n\n\n.dat (SPSS)\nread_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nread_xlsx()\n{readxl}\nmit `sheet = 1` Tabellenblatt angeben (funktioniert auch mit Namen)\n\n\n\n\n\n\n\n\n\n\n# csv Datei\ndat1 &lt;- read.table(file = \"Dateiname.csv\",sep = \";\")\n# Rdata\ndat1 &lt;- readRDS(file = \"Dateiname.Rdata\")\n# große csv\nlibrary(vroom)\ndat1 &lt;- vroom(file = \"Dateiname.csv\",delim = \";\")\n# Stata dta\nlibrary(haven)\ndat1 &lt;- read_dta(file = \"Dateiname.dta\")\n# SPSS sav\ndat1 &lt;- read_sav(file = \"Dateiname.sav\")\n# Excel\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"1\")\ndat1 &lt;- read_xlsx(path = \"Dateiname.xlsx\", sheet = \"Tabellenblatt1\")\n\n\n\n\n\n\n2.13.2 Datensätze exportieren\n\nÜberblickCode\n\n\n\n\n\n\n\n\n\n\n\n\n\nDateityp\nR Funktion\nR Paket\nAnmerkung\n\n\n\n\n.Rdata (R format)\nsaveRDS()\n-\nalle Variableneigenschaften bleiben erhalten\n\n\n.csv\nwrite.table()\n-\nmit `sep = \";\"` Trennzeichen angeben\nmit row.names= F Zeilennummerierung unterdrücken\n\n\n.dta (Stata)\nwrite_dta()\n{haven}\n\n\n\n.dat (SPSS)\nwrite_spss()\n{haven}\n\n\n\n.xlsx (Excel)\nwrite.xlsx()\n{xlsx}\nmit `sheetName` ggf. Tabellenblattname angeben\n\n\n\n\n\n\n\n\n\n\n# Rdata\nsaveRDS(dat1,file = \"Dateiname.Rdata\")\n# csv\nwrite.table(dat1,file = \"Dateiname.csv\",sep = \";\",row.names = F)\n# dta\nlibrary(haven)\nwrite_dta(dat1,path = \"Dateiname.dta\")\n# sav\nlibrary(haven)\nwrite_sav(dat1,path = \"Dateiname.sav\")\n# xlsx\nlibrary(xlsx)\nwrite.xlsx(dat1,file = \"Dateiname.xlsx\", sheetName = \"Tabellenblatt 1\")"
  },
  {
    "objectID": "02_intro.html#hilfe-zu-paketen-und-funktionen",
    "href": "02_intro.html#hilfe-zu-paketen-und-funktionen",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.14 Hilfe zu Paketen und Funktionen",
    "text": "2.14 Hilfe zu Paketen und Funktionen\nR Pakete kommen (häufig) mit sehr ausführlichen Hilfeseiten, die entweder direkt aus RStudio abgerufen werden können:\n\n# Hilfe zu Paketen\nvignette(\"dplyr\")\nvignette(package = \"dplyr\")\nvignette(\"rowwise\")\nhelp(\"dplyr\")\nhelp(package = \"dplyr\")\n\n\n# Hilfe zu Funktionen\n?select()\n\nAlternativ führt aber Google auch zum Ziel, bspw. R dplyr select()\nOder auf CRAN (woher auch install.packages() die Pakete bezieht):\n\n\n\n\n\nCRAN-Seite für {dplyr}"
  },
  {
    "objectID": "02_intro.html#übungen",
    "href": "02_intro.html#übungen",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.15 Übungen",
    "text": "2.15 Übungen\n\n2.15.1 Übung 1\n\nErstellen Sie den Datensatz mit den Studierenden- & Prof-Zahlen wie gezeigt:\n\n\ndat2 &lt;- data.frame(studs = c(14954,47269 ,23659,9415 ,38079), \n                   profs = c(250,553,438 ,150,636),\n                   prom_recht = c(FALSE,TRUE,TRUE,TRUE,FALSE),\n                   gegr  = c(1971,1870,1457,1818,1995))\n\n\nSehen Sie den dat2 in Ihrem Environment?\nLassen Sie sich dat2 in der Console ausgeben.\nFügen Sie die Namen der Unis als neue Spalte in den Datensatz ein. Diese sind in dieser Reihenfolge:\n\n\nc(\"FH Aachen\",\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Bonn-Rhein-Sieg\")\n\n\nLassen Sie sich dat2 anzeigen - in der Console oder mit View()\nBerechnen Sie das Verhältnis Studierende pro Professur und legen Sie die Ergebnisse in einer neuen Variable an. Sehen Sie sich das Ergebnis an.\nLassen Sie sich nur die dritte Zeile von dat2 anzeigen.\nLassen Sie sich nur die dritte Spalte von dat2 anzeigen.\nLassen Sie sich nur die Unis mit unter 10000 Studierenden anzeigen.\n\nZurück nach oben\n\n\n2.15.2 Übung 2\n\nInstallieren Sie die Pakete des tidyverse mit fdz_install(\"tidyverse\"), nachdem Sie die .Rprofile-Datei in unter PFAD abgelegt haben.\nVerwenden Sie wieder den data.frame dat2 aus Übung 1\nNutzen Sie filter, um sich nur die Unis mit unter 10000 Studierenden anzeigen zu lassen. (Denken Sie daran, {tidyverse} zu installieren und mit library() zu laden)\nLassen Sie sich nur die Spalte gegr anzeigen.\nLassen Sie sich nur Zeilen der Hochschulen mit Promotionsrecht (prom_recht) anzeigen.\n\nZurück nach oben\n\n\n2.15.3 Übung 3\n\nVerwenden Sie weiterhin den Datensatz aus Übung 1 & 2.\nLassen Sie sich nur Hochschulen anzeigen, die 1971, 1457 oder 1995 gegründet wurden - und für diese Fälle nur den Namen und das Gründungsjahr.\nSortieren Sie den Datensatz entsprechend dieser Reihenfolge. (Legen Sie dazu eine factor-Variable an, welche die entsprechende Reihenfolge festlegt.)\n\n\nc(\"RWTH Aachen\",\"Uni Freiburg\",\"Uni Bonn\",\"FH Aachen\",\"FH Bonn-Rhein-Sieg\")\n\nZurück nach oben\n\n\n2.15.4 Übung 4\n\nErstellen Sie in Ihrem Verzeichnis für diesen Kurs ein R-Projekt\nSpeichern Sie die Personendaten des PASS-CampusFile (PENDDAT_cf_W13.dta) in Ihrem Verzeichnis im Unterordner orig.\nLesen Sie den Datensatz PENDDAT_cf_W13.dta wie oben gezeigt in R ein und legen Sie den Datensatz unter dem Objektnamen pend ab.\nNutzen Sie head() und View(), um sich einen Überblick über den Datensatz zu verschaffen.\nWie viele Befragte (Zeilen) enthält der Datensatz?\nLassen Sie sich die Variablennamen von pend mit names() anzeigen!\nWie können Sie sich die Zeilen anzeigen lassen, welche den/die Befragte*n mit der pnr 1000908201 enthält?\nWählen Sie alle Befragten aus, die älter als 60 (Alter: palter) sind legen Sie diese Auswahl unter ue_1960 ab.\nWie müssen Sie den Befehl anpassen, sodass ue_1960 nur die Variablen pnr, hnr, welle, pintjahr und palter enthält?\nWie viele Spalten hat ue_1960? Wie viele Zeilen?\n\nBonusübungen:\n\n\nWie alt ist der/die Befragte mit der pnr 1000908201 in welle 10 (im pintjahr 2016)?\nErstellen Sie eine neue Variable mit dem Geburtsjahr der Befragten (basierend auf dem Alter palter und dem Interviewjahr pintjahr).\n\n\nZurück nach oben\n\n\n2.15.5 Übung 5\n\nExportieren Sie den data.frame mit den in der vorherigen Übung erstellten kleineren Datensatz-Version (ue_1960) als .Rdata-Datei.\nLaden Sie die eben exportierte .Rdata-Datei unter einem beliebigen Namen, bspw. ue_1960_neu.\nHat alles geklappt? Vergleichen Sie das neu geladene mit dem ursprünglichen Objekt: identical(ue_1960,ue_1960_neu) - sind beide Objekte identisch?\n\nZurück nach oben"
  },
  {
    "objectID": "02_intro.html#anhang",
    "href": "02_intro.html#anhang",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "2.16 Anhang",
    "text": "2.16 Anhang\n\n2.16.1 Alternativen zu R-Projekten\nNeben dem Einrichten eines Projekts können wir den Pfad auch mit setwd() setzen oder direkt in read_dta() bzw. anderen read...()-Befehlen angeben. Das hat allerdings den Nachteil, dass diese Strategie nicht auf andere Rechner übertragbar ist: wenn jemand anderes die .Rproj-Datei öffnet, wird R automatisch die Pfade relativ zum Speicherort der Datei setzen. Das gilt auch wenn wir das Verzeichnis verschieben auf unserem Gerät - R wird automatisch das Arbeitsverzeichnis auf den neuen Speicherort setzen.\nZum Setzen des Arbeitsverzeichnis mit setwd() setzen wir in die Klammern den Pfad des Ordners ein. Wichtig dabei ist dass Sie ggf. alle \\ durch /ersetzen müssen:\n\nsetwd(\"D:/Kurse/R_IAB\")\n\nMit getwd() lässt sich überprüfen, ob das funktioniert hat:\n\ngetwd()\n\nHier sollte der mit setwd() gesetzte Pfad erscheinen.\nAlternativ können wir auch in read_dta() den vollen Pfad angeben:\n\npend &lt;- haven::read_dta(\"C:/Kurse/R_IAB/orig/PENDDAT_cf_W13.dta\")\n\n\n\n2.16.2 Zeilen & Spaltenauswahl ohne {dplyr}\nNatürlich kann auch base R (also R ohne Erweiterungen wie {dplyr} Datensätze filtern usw.), dazu wird [ ] verwendet:\n\ndat1[1,1] # erste Zeile, erste Spalte\n\n[1] 19173\n\ndat1[1,]  # erste Zeile, alle Spalten\n\n  studs profs gegr stu_prof        uni    uni_fct\n1 19173   322 1971 59.54348 Uni Bremen Uni Bremen\n\ndat1[,1]  # alle Zeilen, erste Spalte (entspricht hier dat1$studs)\n\n[1] 19173  5333 15643\n\ndat1[,\"studs\"] # alle Zeilen, Spalte mit Namen studs -&gt; achtung: \"\"\n\n[1] 19173  5333 15643\n\n\nNatürlich können wir auch mehrere Zeilen oder Spalten auswählen. Dafür müssen wir wieder auf c( ) zurückgreifen:\n\ndat1[c(1,2),]  ## 1. & 2. Zeile, alle Spalten\ndat1[,c(1,3)]  ## alle Zeilen, 1. & 3. Spalte (entspricht dat1$studs & dat1$stu_prof)\ndat1[,c(\"studs\",\"uni\")] ## alle Zeilen, Spalten mit Namen studs und uni\n\nIn diese eckigen Klammern können wir auch Bedingungen schreiben, um so Auswahlen aus dat1 zu treffen.\n\ndat1 # vollständiger Datensatz\n\n  studs profs gegr stu_prof           uni       uni_fct\n1 19173   322 1971 59.54348    Uni Bremen    Uni Bremen\n2  5333    67 1830 79.59701    Uni Vechta    Uni Vechta\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\ndat1[dat1$uni == \"Uni Oldenburg\", ] # Zeilen in denen uni gleich \"Uni Oldenburg\", alle Spalten\n\n  studs profs gegr stu_prof           uni       uni_fct\n3 15643   210 1973 74.49048 Uni Oldenburg Uni Oldenburg\n\ndat1$studs[dat1$uni == \"Uni Oldenburg\" ] # Nur Studi-Zahl nachsehen: kein Komma \n\n[1] 15643\n\n\nDas funktioniert soweit wie gewünscht und wir können das Ganze jetzt erweitern:\n\ndat1[dat1$uni == \"Uni Oldenburg\" & dat1$studs &gt; 10000, ] # & bedeutet UND\n\nWir können auch hier einen ODER-Operator verwenden:\n\ndat1[dat1$uni == \"Uni Oldenburg\" | dat1$studs &gt; 10000, ]\n\n\n\n2.16.3 select() vs $\nWenn wir mit select() eine spezifische Variable auswählen, wird trotzdem die Datenstruktur als data.frame() erhalten, während die Auswahl dat1$variablenname die Spalte als Vektor (also Wertereihe) ausgibt:\n\ndat1$studs\n\n[1] 19173  5333 15643\n\nclass(dat1$studs)\n\n[1] \"numeric\"\n\ndat1$studs/ 20\n\n[1] 958.65 266.65 782.15\n\n\nselect() erhält die Werte als Spalte eines data.frame:\n\ndat1 %&gt;% select(studs)\n\n  studs\n1 19173\n2  5333\n3 15643\n\ndat1 %&gt;% select(studs) %&gt;% class()\n\n[1] \"data.frame\"\n\ndat1 %&gt;% select(studs)/20 \n\n   studs\n1 958.65\n2 266.65\n3 782.15"
  },
  {
    "objectID": "02_intro.html#footnotes",
    "href": "02_intro.html#footnotes",
    "title": "2  Arbeiten mit Datensätzen",
    "section": "",
    "text": "In vielen anderen Programmiersprachen ist auch von Bibliotheken/“libraries” die Rede.↩︎\nEs gibt noch weitere und diese Aufzählung ignoriert die technischen Hintergründe - für eine fortgeschrittene Einführung zu Vektoren in R hier entlang↩︎\nWir werden gleich sehen, wie sehr Erweiterungen (“Pakete”) uns das Arbeiten in R erleichtern.↩︎\nEs hat sich in der R-Community etabliert, Pakete mit {} zu schreiben um sie deutlicher von Funktionen zu unterscheiden. Ich folge in diesem Skript dieser Konvention.↩︎\nManchmal kann der Datensatz aber nicht im Unterordner des Projekts liegen, dann kann natürlich auch der gesamte Pfad in read_dta() angegeben werden: pend &lt;- read_dta(file = \"D:/Kurse/R-Kurs/data/PENDDAT_cf_W13.dta\")↩︎"
  },
  {
    "objectID": "03_desc.html#häufigkeitsauszählungen",
    "href": "03_desc.html#häufigkeitsauszählungen",
    "title": "3  Einen Überblick erhalten",
    "section": "3.1 Häufigkeitsauszählungen",
    "text": "3.1 Häufigkeitsauszählungen\nUns stehen verschiedene Befehle zur Verfügung, um eine Häufigkeitsauszählung zu erstellen:\n\ntable()\ncount() aus {dplyr}\n\nEinfachster Befehl für die Auszählung von Häufigkeiten ist der table() Befehl. Beispielsweise mit der Variable statakt zur Ausbildung der Befragten.\n\ntable(pend$statakt)\n\n\n -10   -9   -5    1    2    3 \n3765 3289  280 9470 6139 5481 \n\n\nWir bekommen hier die absoluten Häufigkeiten angezeigt. In der ersten Zeile werden die verschiedenen Ausprägungen aufgelistet, in der zweiten Zeile stehen dann die Häufigkeiten.\nAllerdings werden sowohl für table() die Labels in der Ausgabe erstmal ignoriert. Mit as_factor() aus dem Paket {haven} können wir die Labels aus dem Datensatz abrufen und die numerischen Werte mit den Labels überschreiben. Der table() zeigt dann die Labels als Beschriftungen an:\n\ntable(as_factor(pend$statakt))\n\n\nItem fuer Fragebogenversion nicht relevant \n                                      3765 \n               Item in Welle nicht erhoben \n                                      3289 \n   Generierung nicht mgl. (fehlende Werte) \n                                       280 \n                             Erwerbstaetig \n                                      9470 \n        Arbeitslos (Gemeldet und sonstige) \n                                      6139 \n                                   Inaktiv \n                                      5481 \n\n\n9470 Befragte sind erwerbstätig, 5481 Befragte sind inaktiv usw. (Zu labels und die Arbeit mit value labels in R später mehr)\nMit count() aus {dplyr} bekommen wir die labels direkt angezeigt, auch hier verwenden wir wieder die Schreibweise mit der Pipe %&gt;%:\n\npend %&gt;% count(statakt)\n\n# A tibble: 6 × 2\n  statakt                                              n\n  &lt;dbl+lbl&gt;                                        &lt;int&gt;\n1 -10 [Item fuer Fragebogenversion nicht relevant]  3765\n2  -9 [Item in Welle nicht erhoben]                 3289\n3  -5 [Generierung nicht mgl. (fehlende Werte)]      280\n4   1 [Erwerbstaetig]                               9470\n5   2 [Arbeitslos (Gemeldet und sonstige)]          6139\n6   3 [Inaktiv]                                     5481\n\n\nWir können auch Tabellen unter einem frei wählbaren Namen ablegen und später wieder aufrufen:\n\nt1 &lt;- table(pend$statakt)\nt2 &lt;- pend %&gt;% count(statakt)\n\nWir sehen hier, dass die Tabelle mit xtabs() eine neue Objektform ist, ein table. Mit count() wird hingegen ein data.frame erstellt.\n\nclass(t1)\n\n[1] \"table\"\n\nclass(t2)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\""
  },
  {
    "objectID": "03_desc.html#NA03",
    "href": "03_desc.html#NA03",
    "title": "3  Einen Überblick erhalten",
    "section": "3.2 Fehlende Werte in R: NA",
    "text": "3.2 Fehlende Werte in R: NA\nEtwas störend sind aber die negativen Werte.\nUm die Werte wie -5 auch in R als fehlende Angabe zu kennzeichnen, müssen wir sie in pend auf NA setzen. Dazu rufen wir pend$statakt auf und filtern mit [] nur die Werte für statakt gleich -1 heraus. Im vorherigen Kapitel haben wir kennengelernt, dass wir so spezifische Werte aufrufen können:\n\npend$statakt[pend$statakt == -5] # nur statakt = -5 aufrufen\n\n&lt;labelled&lt;double&gt;[280]&gt;: Aktueller Hauptstatus, generiert (ab Welle 2)\n  [1] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [26] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [51] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n [76] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[101] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[126] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[151] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[176] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[201] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[226] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[251] -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5 -5\n[276] -5 -5 -5 -5 -5\n\nLabels:\n value                                      label\n   -10 Item fuer Fragebogenversion nicht relevant\n    -9                Item in Welle nicht erhoben\n    -5    Generierung nicht mgl. (fehlende Werte)\n     1                              Erwerbstaetig\n     2         Arbeitslos (Gemeldet und sonstige)\n     3                                    Inaktiv\n\n\n(Hier bekommen wir nochmal die Labels ausgespuckt, was etwas suboptimal für die Übersichtlichkeit ist.)\nWenn wir daran mit &lt;- einen neuen Wert angeben, werden die aufgerufenen Werte damit überschrieben - hier überschreiben wir also alle Werte für statakt == -1 mit NA:\n\npend$statakt[pend$statakt == -5]  &lt;- NA\n\nNA ist in der R der Code für fehlende Angaben, sie werden dann in table() nicht aufgeführt:\n\ntable(pend$statakt)\n\n\n -10   -9    1    2    3 \n3765 3289 9470 6139 5481 \n\n\nWir können aber mit der Option exclude = NULL die Auszählung von NA explizit anfordern:\n\ntable(pend$statakt,exclude = NULL)\n\n\n -10   -9    1    2    3 &lt;NA&gt; \n3765 3289 9470 6139 5481  280 \n\n\nAllerdings haben wir ja jetzt noch nicht alle negativen Werte überschrieben, die -10 und -9 fehlen noch. Natürlich wäre es so etwas möglich, aber etwas umständlich:\n\npend$statakt[pend$statakt == -9 ]  &lt;- NA\npend$statakt[pend$statakt == -10]  &lt;- NA\n\nStattdessen können wir den %in%-Operator verwenden, den wir schon im Zusammenhang mit filter() kennengelernt hatten - alternativ klappt für die PASS-Daten auch &lt; 0, weil alle Missing-Codes kleiner 0 sind:\n\npend$statakt[pend$statakt %in% c(-9,-10)]  &lt;- NA\npend$statakt[pend$statakt &lt; 0 ]  &lt;- NA\n\nDamit sind wir für statakt am Ziel:\n\ntable(pend$statakt)\n\n\n   1    2    3 \n9470 6139 5481 \n\ntable(pend$statakt,exclude = NULL)\n\n\n   1    2    3 &lt;NA&gt; \n9470 6139 5481 7334 \n\n\nIn count() wird NA auch mit ausgezählt:\n\npend %&gt;% count(statakt)\n\n# A tibble: 4 × 2\n  statakt                                     n\n  &lt;dbl+lbl&gt;                               &lt;int&gt;\n1  1 [Erwerbstaetig]                       9470\n2  2 [Arbeitslos (Gemeldet und sonstige)]  6139\n3  3 [Inaktiv]                             5481\n4 NA                                       7334\n\n\nMöchten wir das umgehen, nehmen wir wieder filter() zu Hilfe - mit is.na() können wir NA identifizieren. Durch Voranstellen von ! können wir damit anfordern, dass alle nicht-NA-Werte mit TRUE behalten werden:\n\npend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt)\n\n# A tibble: 3 × 2\n  statakt                                    n\n  &lt;dbl+lbl&gt;                              &lt;int&gt;\n1 1 [Erwerbstaetig]                       9470\n2 2 [Arbeitslos (Gemeldet und sonstige)]  6139\n3 3 [Inaktiv]                             5481\n\n\nMehr zu fehlenden Werten findet sich beispielsweise im The missing book von Nicholas Tierney & Allison Horst.\n\n3.2.1 Übung"
  },
  {
    "objectID": "03_desc.html#andere-tabellenwerte",
    "href": "03_desc.html#andere-tabellenwerte",
    "title": "3  Einen Überblick erhalten",
    "section": "3.3 Andere Tabellenwerte",
    "text": "3.3 Andere Tabellenwerte\nMit Hilfe weiterer Funktionen können wir die Häufigkeitstabellen jeweils anpassen:\n\nprop.table(): relative Werte/Anteile\n\n\ntable(pend$statakt) %&gt;% prop.table(.) \n\n\n        1         2         3 \n0.4490280 0.2910858 0.2598862 \n\n\n29.109% aller Befragten sind arbeitslos.\n\ncumsum(): kumulierte Werte\n\n\ntable(pend$statakt) %&gt;% cumsum(.)\n\n    1     2     3 \n 9470 15609 21090 \n\n\n15609 Befragte sind erwerbstätig oder sind arbeitslos.\n\nprop.table() mit cumsum(): kumulierte relative Häufigkeiten\n\n\ntable(pend$statakt) %&gt;% prop.table() %&gt;% cumsum()\n\n        1         2         3 \n0.4490280 0.7401138 1.0000000 \n\n\n74.011% aller Befragten sind erwerbstätig oder arbeitslos (und nicht inaktiv)."
  },
  {
    "objectID": "03_desc.html#mehrere-kennzahlen-in-einer-tabelle",
    "href": "03_desc.html#mehrere-kennzahlen-in-einer-tabelle",
    "title": "3  Einen Überblick erhalten",
    "section": "3.4 Mehrere Kennzahlen in einer Tabelle",
    "text": "3.4 Mehrere Kennzahlen in einer Tabelle\nAus Stata kennen viele sicherlich folgende Ansicht mit tab statakt:\n\n\n   Aktueller Hauptstatus, generiert (ab |\n                               Welle 2) |      Freq.     Percent        Cum.\n----------------------------------------+-----------------------------------\n                          Erwerbstaetig |      9,470       33.32       33.32\n     Arbeitslos (Gemeldet und sonstige) |      6,139       21.60       54.91\n                                Inaktiv |      5,481       19.28       74.20\n                                      . |      7,334       25.80      100.00\n----------------------------------------+-----------------------------------\n                                  Total |     28,424      100.00\n\n\nStandardmäßig ein table() oder count() immer nur eine Art von Kennzahlen. Da wir aber mit count() die Auszählungen als data.frame() erhalten, können wir die relativen und kumulierten Häufigkeiten einfach als neue Variablen anfügen.\nDazu verwenden wir dat1$var &lt;- ...., das wir im vorherigen Kapitel kennen gelernt hatten. Um also eine neue Spalte pctin unseren data.frame mit den Auszählungen einzufügen gehen wir wie folgt vor: + Zuerst erstellen wir einen data.frame mit der Auszählung mit Hilfe von count()\n\ntab_statakt &lt;- pend %&gt;% count(statakt) # ausgangsbefehl\ntab_statakt\n\n# A tibble: 4 × 2\n  statakt                                     n\n  &lt;dbl+lbl&gt;                               &lt;int&gt;\n1  1 [Erwerbstaetig]                       9470\n2  2 [Arbeitslos (Gemeldet und sonstige)]  6139\n3  3 [Inaktiv]                             5481\n4 NA                                       7334\n\n\n\nDann fügen wir eine neue Spalte für die relativen Häufigkeiten hinzu, welche mit prop.table() berechnet werden:\n\n\ntab_statakt$pct &lt;- prop.table(tab_statakt$n)\ntab_statakt\n\n# A tibble: 4 × 3\n  statakt                                     n   pct\n  &lt;dbl+lbl&gt;                               &lt;int&gt; &lt;dbl&gt;\n1  1 [Erwerbstaetig]                       9470 0.333\n2  2 [Arbeitslos (Gemeldet und sonstige)]  6139 0.216\n3  3 [Inaktiv]                             5481 0.193\n4 NA                                       7334 0.258\n\n\nWenn wir jetzt noch die kumulierten Häufigkeiten erstellen möchten, dann können wir cumsum() auf pct anwenden:\n\ntab_statakt$Cum &lt;- cumsum(tab_statakt$pct)\n\nEtwas störend ist aber noch das NA, die für fehlende Angaben steht und nicht berücksichtigt werden soll. Das können wir einfach !is.na() in filter() ausschließen:\n\ntab_statakt2 &lt;- pend %&gt;% filter(!is.na(statakt)) %&gt;% count(statakt) \ntab_statakt2$pct &lt;- prop.table(tab_statakt2$n)\ntab_statakt2$Cum &lt;- cumsum(tab_statakt2$pct)\ntab_statakt2\n\n# A tibble: 3 × 4\n  statakt                                    n   pct   Cum\n  &lt;dbl+lbl&gt;                              &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 1 [Erwerbstaetig]                       9470 0.449 0.449\n2 2 [Arbeitslos (Gemeldet und sonstige)]  6139 0.291 0.740\n3 3 [Inaktiv]                             5481 0.260 1"
  },
  {
    "objectID": "03_desc.html#kontingenztabellen",
    "href": "03_desc.html#kontingenztabellen",
    "title": "3  Einen Überblick erhalten",
    "section": "3.5 Kontingenztabellen",
    "text": "3.5 Kontingenztabellen\nAus Kontingenztabellen erfahren wir, wie häufig Merkmalskombinationen auftreten. Auch für Kontingenztabellen können wir table() verwenden. Zum Beispiel können wir uns eine Tabelle anzeigen lassen, die uns die Häufigkeiten des Erwerbsstatus getrennt nach Geschlechtern zeigt:\n\ntable(pend$zpsex, pend$statakt)\n\n   \n       1    2    3\n  1 4685 3240 2047\n  2 4785 2899 3434\n\n\nWir erkennen aus dieser Tabelle beispielsweise, dass 3434 Befragte weiblich (zpsex=2) und inaktiv (statakt = 3) sind.\nMöchten wir jetzt die relativen Häufigkeiten, dann wenden wir wieder prop.table() an:\n\ntable(pend$zpsex, pend$statakt) %&gt;% prop.table()\n\n   \n             1          2          3\n  1 0.22214320 0.15362731 0.09706022\n  2 0.22688478 0.13745851 0.16282598\n\n\nFür Zeilenprozente benötigen wir die zusätzliche Option margin = 1:\n\ntable(pend$zpsex, pend$statakt) %&gt;% prop.table(margin = 1)\n\n   \n            1         2         3\n  1 0.4698155 0.3249097 0.2052748\n  2 0.4303832 0.2607483 0.3088685\n\n\n\n30.89% der weiblichen Befragten (zpsex=2) sind inaktiv (statakt = 3).\n\nFür Zeilenprozente dann margin = 2:\n\ntable(pend$zpsex, pend$statakt) %&gt;% prop.table(margin = 2)\n\n   \n            1         2         3\n  1 0.4947202 0.5277733 0.3734720\n  2 0.5052798 0.4722267 0.6265280\n\n\n\n62.65% der inaktiven Befragten (statakt = 3) sind weiblich (zpsex=2).\n\nFür eine Kontingenztabelle mit count() geben wir einfach die Variablen in count() an. Das Ergebnis wird immer im “long shape” Format ausgegeben:\n\npend %&gt;% count(zpsex,statakt)\n\n# A tibble: 8 × 3\n  zpsex         statakt                                     n\n  &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt;                               &lt;int&gt;\n1 1 [Maennlich]  1 [Erwerbstaetig]                       4685\n2 1 [Maennlich]  2 [Arbeitslos (Gemeldet und sonstige)]  3240\n3 1 [Maennlich]  3 [Inaktiv]                             2047\n4 1 [Maennlich] NA                                       3555\n5 2 [Weiblich]   1 [Erwerbstaetig]                       4785\n6 2 [Weiblich]   2 [Arbeitslos (Gemeldet und sonstige)]  2899\n7 2 [Weiblich]   3 [Inaktiv]                             3434\n8 2 [Weiblich]  NA                                       3779\n\n\nHier ist count() informativer als table(). Hier werden die Labels verwendet. Der Übersichtlichkeit halber verwende ich meistens count(), auch wenn das long shape Format etwas gewöhnungsbedürftig ist.\n\n3.5.1 Übung\n\n\n\n\n\n\nBei langen Tabellen gibt count() nicht alle Zeilen aus\n\n\n\n\n\nBei langen Tabellen werden nicht alle Werte ausgegeben, sondern nur die ersten Zeilen. Um hier alle Werte zu bekommen, hilft print(n=Inf):\n\npend %&gt;% count(palter) # wird abgeschnitten\n\n# A tibble: 84 × 2\n   palter                n\n   &lt;dbl+lbl&gt;         &lt;int&gt;\n 1 -2 [Keine Angabe]    60\n 2 14                    1\n 3 15                  271\n 4 16                  308\n 5 17                  276\n 6 18                  282\n 7 19                  266\n 8 20                  296\n 9 21                  282\n10 22                  330\n# … with 74 more rows\n\npend %&gt;% count(palter) %&gt;% print(n=Inf) # alle Werte werden gezeigt\n\n# A tibble: 84 × 2\n   palter                n\n   &lt;dbl+lbl&gt;         &lt;int&gt;\n 1 -2 [Keine Angabe]    60\n 2 14                    1\n 3 15                  271\n 4 16                  308\n 5 17                  276\n 6 18                  282\n 7 19                  266\n 8 20                  296\n 9 21                  282\n10 22                  330\n11 23                  338\n12 24                  325\n13 25                  371\n14 26                  401\n15 27                  438\n16 28                  460\n17 29                  449\n18 30                  502\n19 31                  495\n20 32                  502\n21 33                  515\n22 34                  513\n23 35                  511\n24 36                  500\n25 37                  474\n26 38                  504\n27 39                  484\n28 40                  517\n29 41                  521\n30 42                  526\n31 43                  536\n32 44                  540\n33 45                  552\n34 46                  610\n35 47                  604\n36 48                  600\n37 49                  585\n38 50                  601\n39 51                  621\n40 52                  597\n41 53                  598\n42 54                  615\n43 55                  575\n44 56                  566\n45 57                  561\n46 58                  618\n47 59                  589\n48 60                  568\n49 61                  512\n50 62                  507\n51 63                  534\n52 64                  469\n53 65                  438\n54 66                  424\n55 67                  376\n56 68                  326\n57 69                  316\n58 70                  291\n59 71                  259\n60 72                  239\n61 73                  212\n62 74                  188\n63 75                  177\n64 76                  134\n65 77                  126\n66 78                  119\n67 79                   96\n68 80                   74\n69 81                   62\n70 82                   54\n71 83                   48\n72 84                   40\n73 85                   26\n74 86                   27\n75 87                   23\n76 88                   15\n77 89                   11\n78 90                   12\n79 91                   11\n80 92                    9\n81 93                    7\n82 94                    4\n83 95                    2\n84 97                    2"
  },
  {
    "objectID": "03_desc.html#lage--konzentrationsmaße",
    "href": "03_desc.html#lage--konzentrationsmaße",
    "title": "3  Einen Überblick erhalten",
    "section": "3.6 Lage- & Konzentrationsmaße",
    "text": "3.6 Lage- & Konzentrationsmaße\nLagemaße sind statische Kennzahlen zur Beschreibung von metrischen Variablen, wie beispielsweise das arithmetische Mittel oder der Median. Einen Überblick bietet summary():\n\nsummary(pend$netges)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n    -5.0     -3.0     -3.0    567.9    990.0 111419.0 \n\n\nAllerdings gibt es im Datensatz natürlich keine Befragten mit einem Bruttoverdienst von -5.0 EUR. Werte kleiner Null sind Zahlencodes für keine Angabe:\n\n\n\n\n\n\n\n\n\nname\nvalue\n\n\n\n\nItem fuer Fragebogenversion nicht relevant\n-10\n\n\nItem in Welle nicht erhoben\n-9\n\n\nGenerierung nicht mgl. (fehlende Werte)\n-5\n\n\nTrifft nicht zu (Filter)\n-3\n\n\n\n\n\n\n\nUm aussagekräftige Werte zu bekommen, müssen wir diese Werte mit NA überschreiben:\n\npend$netges[pend$netges &lt; 0 ] &lt;- NA # missings überschreiben\n\n\nsummary(pend$netges)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0     880    1320    1562    1890  111419   18056 \n\n\nWir können aber auch bestimmte Kennzahlen anfordern sehen uns die Bruttoverdienste der Befragten zu beschreiben:\n\nMinimum und Maximum: min(), max()\narithm. Mittel: mean()\nMedian: median()\nQuantile: quantile()\nVarianz: var()\nStandardabweichung: sd()\nGini-Koeffizient: Gini aus dem Paket {ineq}\n\nWenn eine Variable NA enthält, müssen diese explizit ignoriert werden - ansonsten wird nur NA ausgegeben:\n\nmean(pend$netges)\n\n[1] NA\n\n\nDeshalb müssen wir die Option na.rm = T angeben:\n\nmean(pend$netges,na.rm = T)\n\n[1] 1562.3\n\n\nEin Quantil einer Verteilung trennt die Daten so in zwei Teile, dass x% der Daten darunter und 100-x% darüber liegen. Mit quantile()wir durch Angabe in der Option probs = beliebige Quantilgrenzen anfordern, zB. für die 40%-Quantilgrenze:\n\nquantile(pend$netges,probs = .4, na.rm = T)\n\n 40% \n1125 \n\n\nDen Gini-Koeffizienten können wir mit Gini() aus dem Paket ineq berechnen:\n\ninstall.packages(\"ineq\") # einmal installieren\n\n\nlibrary(ineq) # ineq laden\nGini(pend$netges)\n\n[1] 0.3560557\n\n\n\n3.6.1 Kennzahlentabelle mit summarise\nMit Hilfe von summarise() aus {dplyr} können wir ein eigenes summary() bauen:\n\npend %&gt;% summarise(Minimum = min(netges,na.rm = T),\n                    Median = median(netges,na.rm = T),\n                    Mittelwert = mean(netges,na.rm = T),\n                    Maximum = max(netges,na.rm = T),\n                    Gini = Gini(netges))\n\n# A tibble: 1 × 5\n  Minimum   Median Mittelwert Maximum    Gini\n  &lt;dbl+lbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt;\n1 0           1320      1562. 111419    0.356\n\n\nDer Vorteil des Ganzen wird im nächsten Schritt klarer.\n\n\n3.6.2 Lage- und Streuungsmaße vergleichen\nHäufig werden diese Kennzahlen erst im Vergleich richtig spannend.\nDafür hilft uns das Argument .by = in summarise():\n\npend %&gt;% summarise(Minimum = min(netges,na.rm = T),\n                    Median = median(netges,na.rm = T),\n                    Mittelwert = mean(netges,na.rm = T),\n                    Maximum = max(netges,na.rm = T),\n                    Gini = Gini(netges),\n                   .by = welle)\n\n# A tibble: 13 × 6\n   welle                    Minimum   Median Mittelwert Maximum    Gini\n   &lt;dbl+lbl&gt;                &lt;dbl+lbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt;\n 1  1 [Welle 1 (2006/2007)] 1          1200       1525. 111419    0.416\n 2  3 [Welle 3 (2008/2009)] 0          1298.      1498.  12000    0.349\n 3  2 [Welle 2 (2007/2008)] 0          1320       1529.   7200    0.333\n 4  4 [Welle 4 (2010)]      0          1210       1447.  10800    0.334\n 5  5 [Welle 5 (2011)]      0          1250       1494.  33363    0.367\n 6  6 [Welle 6 (2012)]      0          1215       1459.  15950    0.348\n 7  7 [Welle 7 (2013)]      0          1250       1539.  87835    0.382\n 8  8 [Welle 8 (2014)]      0          1255       1456.   9000    0.322\n 9 10 [Welle 10 (2016)]     0          1375       1541.   6300    0.317\n10 11 [Welle 11 (2017)]     0          1500       1748.  44440    0.340\n11 12 [Welle 12 (2018)]     0          1500       1667.   7150    0.312\n12 13 [Welle 13 (2019)]     0          1550       1816.  88453    0.358\n13  9 [Welle 9 (2015)]      0          1280       1613. 110451    0.387\n\n\nHier stört aber die Sortierung der Welle (R übernimmt die Sortierung aus den Daten). Also hängen wir ein arrange() an, um die Sortierung nach welle anzufordern:\n\npend %&gt;% summarise(Minimum = min(netges,na.rm = T),\n                    Median = median(netges,na.rm = T),\n                    Mittelwert = mean(netges,na.rm = T),\n                    Maximum = max(netges,na.rm = T),\n                    Gini = Gini(netges),\n                   .by = welle) %&gt;% \n  arrange(welle)\n\n# A tibble: 13 × 6\n   welle                    Minimum   Median Mittelwert Maximum    Gini\n   &lt;dbl+lbl&gt;                &lt;dbl+lbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt;\n 1  1 [Welle 1 (2006/2007)] 1          1200       1525. 111419    0.416\n 2  2 [Welle 2 (2007/2008)] 0          1320       1529.   7200    0.333\n 3  3 [Welle 3 (2008/2009)] 0          1298.      1498.  12000    0.349\n 4  4 [Welle 4 (2010)]      0          1210       1447.  10800    0.334\n 5  5 [Welle 5 (2011)]      0          1250       1494.  33363    0.367\n 6  6 [Welle 6 (2012)]      0          1215       1459.  15950    0.348\n 7  7 [Welle 7 (2013)]      0          1250       1539.  87835    0.382\n 8  8 [Welle 8 (2014)]      0          1255       1456.   9000    0.322\n 9  9 [Welle 9 (2015)]      0          1280       1613. 110451    0.387\n10 10 [Welle 10 (2016)]     0          1375       1541.   6300    0.317\n11 11 [Welle 11 (2017)]     0          1500       1748.  44440    0.340\n12 12 [Welle 12 (2018)]     0          1500       1667.   7150    0.312\n13 13 [Welle 13 (2019)]     0          1550       1816.  88453    0.358\n\n\nWas aber wenn wir nur Welle 1 und 10 vergleichen wollen? Wir schalten einen filter() vor:\n\npend %&gt;% \n  filter(welle %in% c(1,10)) %&gt;% \n  summarise(Minimum = min(netges,na.rm = T),\n                    Median = median(netges,na.rm = T),\n                    Mittelwert = mean(netges,na.rm = T),\n                    Maximum = max(netges,na.rm = T),\n                    Gini = Gini(netges),\n                   .by = welle)\n\n# A tibble: 2 × 6\n  welle                    Minimum   Median Mittelwert Maximum    Gini\n  &lt;dbl+lbl&gt;                &lt;dbl+lbl&gt;  &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl+lbl&gt; &lt;dbl&gt;\n1  1 [Welle 1 (2006/2007)] 1           1200      1525. 111419    0.416\n2 10 [Welle 10 (2016)]     0           1375      1541.   6300    0.317\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.6.3 Übung"
  },
  {
    "objectID": "03_desc.html#übungen",
    "href": "03_desc.html#übungen",
    "title": "3  Einen Überblick erhalten",
    "section": "3.7 Übungen",
    "text": "3.7 Übungen\n\nAlle Übungen beziehen sich auf das PASS CampusFile:\n\nlibrary(haven)\npend &lt;- read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nZur Erinnerung: hier geht’s zur Übersicht der Einlesebefehle\n\n3.7.1 Übung 1\nWir interessieren uns für die Variable famstand, welche den Familienstand der Befragten enthält:\n\n\n\n\n\n\n\n\n\nfamstand\nlabel\n\n\n\n\n-8\nUnplausibler Wert\n\n\n-4\nFrage irrtuemlich nicht gestellt\n\n\n-3\nTrifft nicht zu (Filter)\n\n\n-2\nKeine Antwort\n\n\n1\nLedig\n\n\n2\nVerheiratet/eing. Lebensp., zus. lebd.\n\n\n3\nVerheiratet/eing. Lebensp., getr. lebd.\n\n\n4\nGeschieden\n\n\n5\nVerwitwet\n\n\n\n\n\n\n\n\nLassen Sie sich eine Tabelle mit den absoluten Häufigkeiten anzeigen, nutzen Sie dafür sowohl table() als auch count() (Denken Sie daran, {tidyverse} zu laden für count()).\nÜberschreiben Sie Missing-Codes mit NA.\nLassen Sie sich der relativen Häufigkeiten (Anteile) ausgeben. Verwenden Sie prop.table() auf Basis des table().\nErstellen Sie eine Kontingenztabelle, indem Sie neben famstand auch das Geschlecht zpsex (2 = Frauen, 1 = Männer) mit einbeziehen\nWie viel Prozent der Befragten sind Frauen, die in einer Gemeinde mit unter 2000 Einwohnern leben? Berechnen Sie die relativen Häufigkeiten.\n\nZurück nach oben\n\n\n3.7.2 Übung 2\n\nErstellen Sie mit Hilfe von count() eine Tabelle mit absoluten, relativen und kumulierten relativen Häufigkeiten für famstand. Erstellen Sie zunächst eine Auszählung mit count() und fügen Sie dann die relativen und kumulierten relativen Häufigkeiten hinzu.\nErstellen Sie eine Kontingenztabelle für famstand und zpsex\nWie viel Prozent der Befragten sind geschiedene Frauen?\nWie viel Prozent der Frauen sind geschieden?\nWie viel Prozent der Geschiedenen sind Frauen?\n\nZurück nach oben\n\n\n3.7.3 Übung 3\nBeschreiben Sie das Alter der Befragten (palter) mit summary und erstellen Sie selbst einen Überblick mit Hilfe von summarise(), der einen Vergleich des Befragtenalters nach Gemeindegrößen erlaubt.\n\nÜberschreiben Sie zunächst die Missings mit NA:\n\n\npend$palter[pend$palter&gt;100] &lt;- NA\n\n\nErstellen Sie einen Überblick mit summary()\nErstellen Sie einen Überblick mit dem Minimum, Median, arith. Mittel, Varianz und Maximum der Alterswerte mit Hilfe von summarise()\nErweitern Sie diesen Überblick dann so, dass sie einen Vergleich der Kennzahlen für die verschiedenen famstand-Kategorien ausgegeben bekommen.\n\nZurück nach oben"
  },
  {
    "objectID": "03_desc.html#hinweise",
    "href": "03_desc.html#hinweise",
    "title": "3  Einen Überblick erhalten",
    "section": "3.8 Hinweise",
    "text": "3.8 Hinweise\n\n3.8.1 Runden mit round()\nErläuterung: Sie können mit round(x , 3) Werte auf eine gewisse Zahl von Ziffern runden. Die zweite Zahl in der Klammer (nach dem Komma) gibt an, wieviele Dezimalstellen wir möchten:\n\nround(21.12121123,digits = 3)\n\n[1] 21.121\n\nround(21.12121123,digits = 5)\n\n[1] 21.12121\n\nround(21.12121123,digits = 0)\n\n[1] 21\n\n\nWir können also die relativen Häufigkeiten runden und so die Tabelle von oben übersichtlicher machen:\n\nxtabs(~zpsex+statakt, data = pend) %&gt;% \n  prop.table(.,margin = 1) %&gt;% \n  round(.,3)\n\n     statakt\nzpsex     1     2     3\n    1 0.470 0.325 0.205\n    2 0.430 0.261 0.309\n\n\n\n\n3.8.2 Wie kann ich mir in R automatisch die häufigste/seltenste Ausprägung ausgeben lassen?\n\nt4 &lt;- table(pend$palter)\nt4[which(t4 == max(t4))] # Modus\n\n 51 \n621 \n\n\n51 ist mit 621 Befragten die häufigste Ausprägung."
  },
  {
    "objectID": "04_viz.html#ggplot2-und-die-grammar-of-graphics",
    "href": "04_viz.html#ggplot2-und-die-grammar-of-graphics",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.1 ggplot2 und die grammar of graphics",
    "text": "4.1 ggplot2 und die grammar of graphics\nggplot2 ist die Umsetzung des Konzepts der “layered grammar of graphics” in R. Die Idee dieses Visualisierungssystems ist es, Datenvisualisierung in Parameter zu unterteilen: der zugrundeliegende Datensatz, die darzustellenden Variablen, die Wahl der darzustellenden Formen, das Koordinatensystem, Skalen und statistische Transformationen. Ein Standardbefehl in ggplot2 sieht ungefähr so aus:\n\nggplot(data = datensatz, aes(x = var1, y = var2, color = var3)) +\n  geom_point() +\n  labs(title= \"Titel\", subtitle = \"Untertitel\") +\n  theme_minimal()\n\nWir rufen also zunächst mit ggplot() eine Darstellung auf. In den weiteren Argumenten werden dann weitere Aspekte festgelegt:\n\nMit data = geben wir den data.frame an, den wir darstellen möchten\nDie Aesthetics aes() legen fest, welche Variablen dargestellt werden sollen: hier also var1 auf der x-Achse, var2 auf der y-Achse und var3 soll die Farbgebung festlegen\nDie Layers geom_.. geben die Art der Darstellung an, zB. geom_point() für Punkt- und geom_bar() für Säulendiagramme.\nMit labs können wir Beschriftungen angeben, zB. einen Titel vergeben oder die Achsenbeschriftungen anpassen\nDie Themes theme_... legen das Design der Graphik fest, zB. schwarz/weiße Achsen- und Hintergrundfarben mit theme_bw()\n\nWir arbeiten uns also jetzt durch die einzelnen layer/Schichten der Grafik:\n\n4.1.1 data =\nIn data = geben die den data.frame an, aus dem die darzustellenden Informationen kommen. Wir starten unseren ggplot also mit:\n\nggplot(data = pend_small)\n\n\n\n\n\n\n\n\n\n\n4.1.2 aes\nDiese Werte wollen wir also in einem Scatterplot darstellen, sodass das Alter auf der x-Achse und auf der y-Achse die Wochenarbeitszeit abgetragen ist:\n\nggplot(data = pend_small, aes(x = palter, y = azges1))\n\n\n\n\n\n\n\n\n\n\n4.1.3 geom\nWenn wir nur diese Angaben machen, bekommen wir lediglich ein leeres Koordinatensystem - warum? Weil wir noch nicht angegeben haben, welche Form der Darstellung wir gerne möchten. Dazu muss wir ein geom_ angeben, für Säulendiagramme ist das geom_col(), diese hängen wir an den ggplot-Befehl mit + an:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point()\n\n\n\n\n\n\n\n\nMit color = können wir den Punkten auch eine andere Farbe geben:\n\nggplot(data = pend_small, aes(x = palter, y = azges1)) + geom_point(color = \"orange\")\n\n\n\n\n\n\n\n\nHier findet sich eine Übersicht mit allen Farbnamen, die verstanden werden, es gibt aber noch viel mehr Farben - siehe Anhang.\n\n\n4.1.4 aes() Teil II\nDas sieht soweit schon ganz gut aus, allerdings werden die Punkte noch nicht getrennt nach Geschlecht dargestellt. Dazu müssen wir die Geschlechtsangabe (zpsex) in aes() angeben. Neben den Achsen werden in aes() nämlich auch die Variablen für das Aussehen der geom_s angeben - das kann neben der Farbe auch die Form, Größe oder Transparenz sein. Hier ein Überblick\nDas Geschlecht soll die Färbung der Punkte vorgeben, diese können wir in aes mit color angeben:\n\n# ergibt einen Fehler aufgrund der Labels:\nggplot(data = pend_small, aes(x = palter, y = azges1, color = zpsex )) + \n  geom_point()\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet\n\n\nEine numerische Variable für color = ergibt einen Farbverlauf, eine factor/character-Variable ergibt eine diskrete Farbskala:\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.numeric(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point()\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.character(zpsex))) + \n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAußerdem können wir mit scale_color_manual1 selbst Farben angeben, eine Liste möglicher Farben findet sich hier.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"))\n\n\n\n\n\n\n\n\n\n\n4.1.5 Beschriftungen\nWir können mit den Optionen breaks und labels zudem auch die Beschriftung der Legende bearbeiten. Dazu geben wir zunächst in breaks die Ausprägungen der Variable Geschlecht an und dann in der gleichen Reihenfolge die zu vergebenden Labels:\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )\n\n\n\n\n\n\n\n\nAbschließend passen wir dann noch mit labs die Beschriftungen an, dabei haben wir folgende Optionen:\n\ntitle: Überschrift für die Graphik\nsubtitle: Unterzeile zur Überschrift\ncaption: Anmerkung unterhalb der Graphik\nx: x-Achsenbeschriftung\ny: y-Achsenbeschriftung\nfill: Beschriftung für die Legende, wenn fill in aes() angegeben wurde\ncolor: Beschriftung für die Legende, wenn color in aes() angegeben wurde\n\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = as.factor(zpsex))) + \n  geom_point() + \n  scale_color_manual(values = c(\"lightskyblue4\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) +\n  labs(color = \"Geschlecht\", y = \"Arbeitszeit/Woche\",\n       x = \"Alter\",\n       title = \"Arbeitszeit und Alter\",\n       subtitle = \"Nach Geschlecht\",\n       caption = \"Quelle: ETB 2018\"\n       ) \n\n\n\n\n\n\n\n\nAußerdem können wir mit theme_ ein anderes Design auswählen, zB. mit theme_minimal() einen weißen Hintergrund mit grauen Markierungslinien (weitere Beispiele in den Hinweisen unter Themes)"
  },
  {
    "objectID": "04_viz.html#kombination-aus-allem",
    "href": "04_viz.html#kombination-aus-allem",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.2 Kombination aus allem",
    "text": "4.2 Kombination aus allem\n\nggplot(data = pend_small, aes(x = palter, y = azges1, \n                               shape = as.factor(zpsex),\n                               color = as_factor(PAS0100))) + \n  geom_point(size = 2) + \n  scale_color_manual(values = c(\"#007ACF\",\"navy\",\"lightskyblue\",\"orange\") ) +\n  scale_shape_manual(values = c(18,20),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\")\n                     ) +\n  labs(color = \"\", \n       fill = \"\",\n       shape = \"Geschlecht\",\n       y = \"Arbeitszeit/Woche\",\n       x = \"Alter\",\n       title = \"Arbeitszeit und Alter\",\n       subtitle = \"Nach Geschlecht\",\n       caption = \"Quelle: PASS CF 0619\"\n       ) \n\n\n\n\n\n\n\n\nÜbersicht zu shapes"
  },
  {
    "objectID": "04_viz.html#grafiken-speichern-ggsave",
    "href": "04_viz.html#grafiken-speichern-ggsave",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.3 Grafiken speichern: ggsave()",
    "text": "4.3 Grafiken speichern: ggsave()\nUm eine Grafik dann zu speichern, steht uns ggsave() zur Verfügung. Wenn wir nichts anderes angeben, wird automatisch die gerade offene Grafik2 gespeichert. Besser ist es aber explizit zu sein und die gewünschte Grafik als Objekt abzulegen und dann in ggsave() anzugeben:\n\nplot_objekt1 &lt;- \n  ggplot(data = pend_small, aes(x = palter, y = azges1, \n                               shape = as.factor(zpsex),\n                               color = as_factor(PAS0100))) + \n  geom_point(size = 2) + \n  scale_color_manual(values = c(\"lightskyblue\",\"#007ACF\",\"navy\",\"orange\") ) +\n  scale_shape_manual(values = c(18,20),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\")\n                     ) +\n  labs(color = \"\", \n       fill = \"\",\n       shape = \"Geschlecht\",\n       y = \"Arbeitszeit/Woche\",\n       x = \"Alter\",\n       title = \"Arbeitszeit und Alter\",\n       subtitle = \"Nach Geschlecht\",\n       caption = \"Quelle: PASS CF 0619\"\n       ) \n\n\nggsave(plot = plot_objekt1,\n       filename = \"./results/plot1.png\",\n       dpi = 800, # auflösung\n       width = 25, height = 11, units = \"cm\" # falls angepasst werden soll\n       )\n\nDie richtige Kombination aus Auflösung, Textgröße und Gesamtgröße des Plots zu finden hat einige Fallstricke. Hier mehr dazu.\n\n4.3.1 Übung"
  },
  {
    "objectID": "04_viz.html#verteilungen-visualisieren",
    "href": "04_viz.html#verteilungen-visualisieren",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.4 Verteilungen visualisieren",
    "text": "4.4 Verteilungen visualisieren\n\n4.4.1 Boxplot\nDefinition der Bestandteile eines Boxplots:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMit der folgenden Syntax können wir mit ggplot2 einen Boxplot erstellen. Da wir nur eine Variable betrachten, müssen wir lediglich y = oder x = angeben - je nachdem ob die Box vertikal oder horizontal orientiert sein soll.\n\nggplot(data = pend_small, aes(y = azges1)) + geom_boxplot()\n\n\n\n\n\n\n\n\nSo können wir einen Boxplot erstellen, der die Werte für Männer und Frauen getrennt darstellt:\n\nggplot(data = pend_small, aes(y = azges1, x = factor(zpsex))) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n4.4.2 Histogram\nEbenso können Verteilungen mit einem Histogramm beschrieben werden:\n\nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram()  \n\n\n\n\n\n\n\n\nWenn wir hier die Farbe ändern möchten, dann ist fill = anstelle von color = die richtige Option:\n\nggplot(data = pend_small, aes(x = azges1)) + \n  geom_histogram(fill = \"sienna1\")  \n\n\n\n\n\n\n\n\nMöchten wir das Histogramm nach Geschlecht aufsplitten, können wir auch hier wieder fill als Aesthetic angeben. Mit position = position_dodge() können wir die Balken nebeneinander stellen lassen:\n\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram() \nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAuch hier funktionieren natürlich wieder die scale_...manual Befehle, allerdings hier als scale_fill_manual anstelle scale_color_manual von oben:\n\nggplot(data = pend_small, aes(x = azges1, fill = factor(zpsex))) + \n  geom_histogram(position = position_dodge()) +\n  scale_fill_manual(values = c(\"sienna1\",\"dodgerblue4\"),\n                    breaks = 1:2, labels = c(\"Männer\",\"Frauen\")) +\n  labs(fill = \"Geschlecht\")\n\n\n\n\n\n\n\n\n\n\n4.4.3 Übung"
  },
  {
    "objectID": "04_viz.html#kategoriale-merkmale",
    "href": "04_viz.html#kategoriale-merkmale",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.5 Kategoriale Merkmale",
    "text": "4.5 Kategoriale Merkmale\nIm Folgenden sehen wir uns eine Möglichkeit an, die Kontingenztabelle aus Kapitel 2 zu visualisieren:\n\npend_small$PD0400[pend_small$PD0400&lt;0] &lt;- NA # missings ausschließen\npend_small %&gt;% \n  count(zpsex,PD0400) \n\n# A tibble: 10 × 3\n   zpsex         PD0400                              n\n   &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt;                       &lt;int&gt;\n 1 1 [Maennlich]  1 [Ueberhaupt nicht religioes]    40\n 2 1 [Maennlich]  2 [Eher nicht religioes]          41\n 3 1 [Maennlich]  3 [Eher religioes]                49\n 4 1 [Maennlich]  4 [Sehr religioes]                22\n 5 1 [Maennlich] NA                                780\n 6 2 [Weiblich]   1 [Ueberhaupt nicht religioes]    26\n 7 2 [Weiblich]   2 [Eher nicht religioes]          34\n 8 2 [Weiblich]   3 [Eher religioes]                40\n 9 2 [Weiblich]   4 [Sehr religioes]                16\n10 2 [Weiblich]  NA                                816\n\n\nMit geom_bar() können wir Säulen darstellen, indem wir ..count.. für y die Höhe als Anzahl der Beobachtungen festlegen:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = ..count..)) +\n  geom_bar(position=position_dodge()) \n\n\n\n\n\n\n\n\nWie kommen wir jetzt an die relativen Häufigkeiten? Wir passen unsere aes auf y = (..count..)/sum(..count..) an. Mit scale_y_continuous(labels = scales::label_percent(accuracy = 1)) können wir außerdem auf der y-Achse die Prozentwerte anzeigen lassen:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(x = as_factor(PD0400), fill = factor(zpsex),\n                       y = (..count..)/sum(..count..) )) +\n  geom_bar(position=position_dodge()) +\n  scale_y_continuous(labels = scales::label_percent(accuracy = 1)) \n\n\n\n\n\n\n\n\nUm jetzt ein Balken- statt einem Säulendiagramm zu erhalten, tauschen wir einfach x und y sowie die Prozentbeschriftung auf scale_x_continuous:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = as_factor(PD0400), fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position=position_dodge()) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) \n\n\n\n\n\n\n\n\nAuch diese Grafiken können wir dann wieder mit scale_... anpassen und mit labs() ausführlich labeln - alle Optionen sind konsistent über alle Darstellungsformen hinweg. Außerdem können wir die Kategorien mit breaks = und labels = auch selbst labeln, wenn uns die definierten Labels nicht gefallen:\n\npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = as_factor(PD0400), fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position=position_dodge()) +\n  scale_fill_manual(values = c(\"navajowhite\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\")) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  labs(title = \"Religiösität nach Geschlecht\",\n       subtitle = \"Relative Häufigkeiten\",\n       caption = \"Quelle: PASS-CF 0619\",\n       y = \"Religiösität\",\n       x = \"Relative Häufigkeit\",\n       fill = \"Geschlecht\" ) \npend_small %&gt;% \n  filter(!is.na(PD0400)) %&gt;% \n  ggplot(data = ., aes(y = PD0400, fill = factor(zpsex),\n                       x = (..count..)/sum(..count..) )) +\n  geom_bar(position=position_dodge()) +\n  scale_fill_manual(values = c(\"navajowhite\",\"navy\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\")) +\n  scale_x_continuous(labels = scales::label_percent(accuracy = 1)) +\n  scale_y_continuous(breaks = 1:4, \n                     labels = c(\"Überhaupt nicht\",\n                                \"Eher nicht\",\n                                \"Eher schon\",\n                                \"Sehr\")) +\n  labs(title = \"Religiösität nach Geschlecht\",\n       subtitle = \"Relative Häufigkeiten\",\n       caption = \"Quelle: PASS-CF 0619\",\n       y = \"Religiösität\",\n       x = \"Relative Häufigkeit\",\n       fill = \"Geschlecht\" ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.1 Übung"
  },
  {
    "objectID": "04_viz.html#übungen",
    "href": "04_viz.html#übungen",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.6 Übungen",
    "text": "4.6 Übungen\nNutzen Sie für alle Aufgaben die ersten 150 Beobachtungen (pend_small), um den Plot einfach zu halten. Denken Sie daran die fehlenden Werte mit filter() auszuschließen, Sie können dazu diesen Befehl verwenden:\n\npend &lt;-\n  haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n    col_select = c(\"zpsex\",\"welle\",\"bilzeit\",\"PA0445\",\"PG1270\",\"PEO0400c\")\n    )\n\n\n4.6.1 Übung 1\n\npend_u41 &lt;-\n  pend %&gt;% \n  filter(welle == 13, bilzeit &gt; 0, PA0445 &gt;0) \n\n\nErstellen Sie einen Scatterplot für die Variablen Dauer der gesamten Arbeitslosigkeitserfahrung in Monaten (PA0445, y-Achse) und Dauer der Ausbildung (bilzeit, x-Achse).\nLegen Sie die Farbe so fest, dass Männer und Frauen unterschiedliche Farben gekennzeichnet werden (zpsex)\nVerändern Sie die Farben auf goldenrod1 und dodgerblue4 fest (oder eine beliebige andere)\nBeschriften Sie die Achsen und Legende!\n\nZurück nach oben\n\n\n4.6.2 Übung 2\n\npend_u42 &lt;-\n  pend %&gt;% \n  filter(welle == 9, PG1270 &gt;0) \n\n\nErstellen Sie einen Boxplot oder Histogramm für die Verteilung der Anzahl gerauchter Zigaretten und Zigarillos pro Tag (i.d. letzten Woche) (PG1270).\nPassen Sie diese Grafik so an, dass die Verteilungen für Männer und Frauen getrennt dargestellt werden.\nWie können Sie auch die Farben nach dem Geschlecht getrennt anlegen? (Denken Sie an color = und fill =)\nVerändern Sie die Farben der Balken mit Hilfe von scale_fill_manual oder scale_fill_brewer oder scale_fill_viridis (Siehe Abschnitte Farben und ColorBreweR und viridis unter “weitere Optionen”)\n\nZurück nach oben\n\n\n4.6.3 Übung 3\n\npend_u43 &lt;-\n  pend %&gt;% \n  filter(welle == 11, PEO0400c &gt;0) \n\n\nErstellen Sie ein Säulen-Diagramm für die Antworten auf die Frage “Eine berufstätige Mutter kann ein genauso herzliches Verhältnis zu ihren Kindern haben, wie eine Mutter, die nicht erwerbstätig ist.” (PEO0400c)\nErstellen Sie ein Säulen-Diagramm für d(PEO0400c) getrennt nach der Variable migration, legen Sie also die Farbe der Säulen nach migration fest. Die Variable migration erfasst, ob die Befragten einer Nebentätigkeit nachgehen (1 = ja/ 0 = nein).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nvalue\nlabel\n\n\n\n\n\nPEO0400c\n\n1\nStimme voll und ganz zu\n\n\n\n\n\n2\nStimme eher zu\n\n\n\n\n\n3\nStimme eher nicht zu\n\n\n\n\n\n4\nStimme ueberhaupt nicht zu\n\n\n\nmigration\n\n1\nKein Migrationshintergrund\n\n\n\n\n\n2\nselbst / mind. 1 Elternteil zugezogen\n\n\n\n\n\n3\nMind. 1 Elternteil zugezogen\n\n\n\n\n\n4\nMind. 1 Grosselt. zugez., Elt. in D geb.\n\n\n\n\n\n\n\nZurück nach oben"
  },
  {
    "objectID": "04_viz.html#weitere-optionen-für-ggplot2",
    "href": "04_viz.html#weitere-optionen-für-ggplot2",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.7 Weitere Optionen für ggplot2",
    "text": "4.7 Weitere Optionen für ggplot2\n\n4.7.1 Aesthetics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.2 themes\nMit sog. themes können wir das layout der Grafik verändern. Weitere Themes sind zB: theme_light(), theme_classic() ider theme_void(), eine Liste findet sich hier. Außerdem bietet das Paket {ggthemes} (install.packages('ggthemes')) eine große Auswahl.\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) + \n  theme_minimal()\n\nggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 2) +\n  theme_dark()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3 Farben\n\np1 &lt;- ggplot(data = pend_small, aes(x = palter, y = azges1, color = factor(zpsex))) + \n  geom_point(size = 3) \n\nNeben den im Beispiel verwendeten Farben für fill können natürlich auch noch unzählige weitere Farben in scale_fill_manual und scale_color_manual verwendet werden:\n\nHier findet sich eine Übersicht mit allen Farbnamen, die verstanden werden\nAlternativ können auch sog. HEX-Codes angeben werden, die bspw. mit dem Adobe Color Wheel oder Color Hex erstellt werden können.\n\n\np1 +  scale_color_manual(values = c(\"dodgerblue4\",\"sienna1\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )\np1 +  scale_color_manual(values = c(\"#005b96\",\"#6497b1\"),\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3.1 ColorBreweR\nAlternativ zur manuellen Auswahl der Farben mit scale_fill_manual und scale_color_manual können mit scale_fill_brewer() auch vorgegebene Farbpaletten des colorbrewer verwendet werden. Dazu muss lediglich scale_fill_brewer() anstelle von scale_fill_manual angeben werden und statt values eine der Paletten - eine Übersicht findet sich hier. Die Farbpaletten von ColorBreweR sind alle in ggplot2 integriert.\n\np1 +\n  scale_color_brewer(palette = \"RdYlBu\",\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \n\n\n\n\n\n\n\n\n\n\n4.7.3.2 viridis\nAnalog dazu gibt es auch die {viridis}-Paletten, welche durchgängig “colorblind-safe” und ebenfalls in {ggplot2} integriert sind. Allerdings ist hier zu beachten, dass für Farbauswahlen basierend auf einer kategorialen Variable scale_color_viridis_d() zu verwenden ist. Soll die Farbe entlang einer numerischen/metrischen Variable bestimmt werden, dann ist scale_color_viridis_c() zu verwenden. Außerdem kann mit begin und end die Breite der Farbskala angepasst werden:\n\np1 +\n  scale_color_viridis_d(option=\"magma\",\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \np1 +\n  scale_color_viridis_d(option=\"magma\",begin = .65,end = .85,\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.7.3.3 Weitere Farbpaletten\nDarüber hinaus gibt es unzählige Pakete, die ebenfalls scale_color_ und scale_fill_-Funktionen bieten: Hier noch zwei Beispiele mit {scico} und {MetBrewer}, welches Farben aus Bildern im Metropolitan Museum of Art enthält:\n\ninstall.packages('scico')\ninstall.packages(\"MetBrewer\")\n\n{scico} Farbpaletten\n\n\n\n\n\n\n\n\n\n{MetBrewer} Farbpaletten\n\n\n\n\n\n\n\n\n\n\nlibrary(scico)\np1 +\n  scale_color_scico_d(palette = \"oslo\",begin = .5,end = .8,\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \nlibrary(MetBrewer)\np1 +\n  scale_color_met_d(name = \"Kandinsky\",\n                    breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVergleichbare Pakete gibt es auch für\n\n{DutchMasters} - Farbpaletten aus Bildern niederländischer Maler\n{wesanderson} - Farbpaletten basierend auf verschiedenen Filmen von Wes Anderson (The Grand Budapest Hotel usw.)\n{ochRe} - Farbpaletten “inspired by Australian art, landscapes and wildlife”\n{paletteer} bietet eine riesige Auswahl verschiedenster Farbpaletten\n\n\n\n\n4.7.4 Shapes\n\n\n\n\n\n\n\n\n\nZusätzlicher Überblick\n\n\n4.7.5 Linetypes\n\n\n\n\n\n\n\n\n\nÜbersicht zu Shapes und Linetypes im R Cookbook"
  },
  {
    "objectID": "04_viz.html#linksammlung",
    "href": "04_viz.html#linksammlung",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "4.8 Linksammlung",
    "text": "4.8 Linksammlung\n\nDas Graph Kapitel des R Cookbooks ist eine hervorragende Quelle für alle möglichen Optionen und eine grundlegende Übersicht - bspw. zur Anpassung der Legende, Linien- und Punktvarianten oder den Achsen\nSchriftgröße und -farbe anpassen: Hier findet sich eine gute Übersicht, wie die Schriftgröße und -farbe in {ggplot2} angepasst werden kann.\nFrom Data to Viz bietet einen Entscheidungsbaum für verschiedene Zusammenhänge und Deskriptionen mit Beispiel-Syntax\n\n\n\n\n\n\n\n\n\n\n\nDie R Graph Gallery ist noch etwas umfangreicher und bietet noch weitere Visualisierungsideen\nFür alle, die mehr zu gelungenen (und schönen) Datenvisualisierungen mit {ggplot2} erfahren möchten, ist das Tutorial von Cédric Scherer ein hervorragender Einstieg. Dieser Workshop eignet sich sehr gut für eine Vertiefung.\nDieser Workshop bietet weitere Einblicke wie Datenvisualisierungen mit {ggplot2} schöner gestaltet werden können.\nEine Liste von Erweiterungen für ggplot2\nDas Buch zu {ggplot2}"
  },
  {
    "objectID": "04_viz.html#footnotes",
    "href": "04_viz.html#footnotes",
    "title": "4  Visualisierung mit {ggplot2}",
    "section": "",
    "text": "Hätten wir color in aes angeben, wäre der entsprechende Befehl scale_color_manual.↩︎\nim Panel Plots rechts↩︎"
  },
  {
    "objectID": "05_data_wrangle1.html#labels-aus-anderen-programmen-in-r",
    "href": "05_data_wrangle1.html#labels-aus-anderen-programmen-in-r",
    "title": "5  Data Wrangling I: Labels & factor",
    "section": "5.1 Labels aus anderen Programmen in R",
    "text": "5.1 Labels aus anderen Programmen in R\nIn vielen Programmen wie Stata oder SPSS werden die labels häufig durch die Operationen “mitgeschleift” und dann ausgegeben. Das ist in R nicht der Fall. Stattdesssen können wir mit Hilfe des Variablentyps factor Labels vergeben. Das Vorgehen mag für alle, die schon lange mit Stata oder SPSS gearbeitet haben, etwas ungewöhnlich sein - ist aber in der Praxis sehr hilfreich, wenn man sich den entsprechenden Workflow angewöhnt hat.\nWenn wir bspw. die Ansicht mit View() öffnen oder eine Auszählung mit count() erstellen, werden uns labels angezeigt:\n\nView(pend_kap5)\npend_kap5 %&gt;% count(zpsex)\n\nDiese sind als attributes() Variablen zugeordnet:\n\nattributes(pend_kap5$zpsex)\n\n$label\n[1] \"Steuervariable: Geschlecht des Befragten (aus HHgrid)\"\n\n$format.stata\n[1] \"%42.0g\"\n\n$labels\nItem in Fragebogenversion nicht erhoben             Item in Welle nicht erhoben \n                                    -10                                      -9 \n                      Unplausibler Wert        Frage irrtuemlich nicht gestellt \n                                     -8                                      -4 \n               Trifft nicht zu (Filter)                            Keine Angabe \n                                     -3                                      -2 \n                            Weiss nicht                               Maennlich \n                                     -1                                       1 \n                               Weiblich \n                                      2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\n\n…leider machen die attributes() immer wieder Probleme:\n\nlibrary(ggplot2)\n\nggplot(data = pend_kap5, aes(x = palter, y = azges1, color = zpsex )) + \n  geom_point()\n\nDon't know how to automatically pick scale for object of type\n&lt;haven_labelled/vctrs_vctr/double&gt;. Defaulting to continuous.\nDon't know how to automatically pick scale for object of type\n&lt;haven_labelled/vctrs_vctr/double&gt;. Defaulting to continuous.\nDon't know how to automatically pick scale for object of type\n&lt;haven_labelled/vctrs_vctr/double&gt;. Defaulting to continuous.\n\n\nError in UseMethod(\"rescale\"): nicht anwendbare Methode für 'rescale' auf Objekt der Klasse \"c('haven_labelled', 'vctrs_vctr', 'double')\" angewendet\n\n\nIn den beiden vorherigen Kapiteln haben wir schon gesehen, dass Labels in R immer etwas extra Aufwand bedeuten. In Grafiken mussten wir mit breaks = c(1,2), labels = c(\"Männer\", \"Frauen\") die Labels extra erstellen.\nWie können wir die Labels attributes() verwenden und so Tipparbeit sparen?\n{haven} enthält sich die Funktion as_factor1, mit der wir aus Labels direkt eine factor-Variable erstellen können:\n\npend_kap5$zpsex_fct &lt;- as_factor(pend_kap5$zpsex)\n\n# ansehen:\npend_kap5 %&gt;% select(contains(\"zpsex\")) %&gt;% head()\n\n# A tibble: 6 × 2\n  zpsex         zpsex_fct\n  &lt;dbl+lbl&gt;     &lt;fct&gt;    \n1 2 [Weiblich]  Weiblich \n2 2 [Weiblich]  Weiblich \n3 1 [Maennlich] Maennlich\n4 1 [Maennlich] Maennlich\n5 2 [Weiblich]  Weiblich \n6 1 [Maennlich] Maennlich\n\n\n\nggplot(data = pend_kap5, aes(x = palter, y = azges1, color = zpsex_fct )) + \n  geom_point()\n\nDon't know how to automatically pick scale for object of type\n&lt;haven_labelled/vctrs_vctr/double&gt;. Defaulting to continuous.\nDon't know how to automatically pick scale for object of type\n&lt;haven_labelled/vctrs_vctr/double&gt;. Defaulting to continuous."
  },
  {
    "objectID": "05_data_wrangle1.html#factor-selbst-erstellen-oder-bearbeiten",
    "href": "05_data_wrangle1.html#factor-selbst-erstellen-oder-bearbeiten",
    "title": "5  Data Wrangling I: Labels & factor",
    "section": "5.2 factor selbst erstellen oder bearbeiten",
    "text": "5.2 factor selbst erstellen oder bearbeiten\nAlternativ können wir auch mit factor() sowie den Optionen levels und labels selber labeln. Die labels werden dann der Reihenfolge nach den Zahlen aus levels zugewiesen.\n\npend_kap5$zpsex_fct2 &lt;- factor(pend_kap5$zpsex,\n                               levels = c(1,2),\n                               labels = c(\"Männer\",\"Frauen\"))\n\n# ansehen:\npend_kap5 %&gt;% select(contains(\"zpsex\")) %&gt;% head()\n\n# A tibble: 6 × 3\n  zpsex         zpsex_fct zpsex_fct2\n  &lt;dbl+lbl&gt;     &lt;fct&gt;     &lt;fct&gt;     \n1 2 [Weiblich]  Weiblich  Frauen    \n2 2 [Weiblich]  Weiblich  Frauen    \n3 1 [Maennlich] Maennlich Männer    \n4 1 [Maennlich] Maennlich Männer    \n5 2 [Weiblich]  Weiblich  Frauen    \n6 1 [Maennlich] Maennlich Männer    \n\n\nAußerdem wird aus allen nicht angegebenen levels automatisch NA:\n\nattributes(pend_kap5$PSM0100)\n\n$label\n[1] \"Nutzung von sozialen Netzwerken?\"\n\n$format.stata\n[1] \"%39.0f\"\n\n$labels\nItem in Fragebogenversion nicht erhoben             Item in Welle nicht erhoben \n                                    -10                                      -9 \n                      Unplausibler Wert                     Nutzt kein Internet \n                                     -8                                      -5 \n       Frage irrtuemlich nicht gestellt                Trifft nicht zu (Filter) \n                                     -4                                      -3 \n                           Keine Angabe                             Weiss nicht \n                                     -2                                      -1 \n                                     Ja                                    Nein \n                                      1                                       2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\npend_kap5 %&gt;% select(PSM0100) %&gt;% head()\n\n# A tibble: 6 × 1\n  PSM0100                 \n  &lt;dbl+lbl&gt;               \n1  2 [Nein]               \n2  1 [Ja]                 \n3  2 [Nein]               \n4 -5 [Nutzt kein Internet]\n5 -5 [Nutzt kein Internet]\n6 -5 [Nutzt kein Internet]\n\npend_kap5$PSM0100_fct &lt;- \n  factor(pend_kap5$PSM0100, \n         levels = 1:2, \n         labels = c(\"Nutzt soziale Netzwerke\",\"Nutzt keine soziale Netzwerken\"))\n\n# Ergebnis ansehen:\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 2\n  PSM0100                  PSM0100_fct                   \n  &lt;dbl+lbl&gt;                &lt;fct&gt;                         \n1  2 [Nein]                Nutzt keine soziale Netzwerken\n2  1 [Ja]                  Nutzt soziale Netzwerke       \n3  2 [Nein]                Nutzt keine soziale Netzwerken\n4 -5 [Nutzt kein Internet] &lt;NA&gt;                          \n5 -5 [Nutzt kein Internet] &lt;NA&gt;                          \n6 -5 [Nutzt kein Internet] &lt;NA&gt;                          \n\n\nOder wir nutzen die Funktionen aus {forcats} zur recodierung eines factors. {forcats} ist Teil des {tidyverse}. Mit fct_recode() können wir die levels verändern:\n\nlevels(pend_kap5$PSM0100_fct)\n\n[1] \"Nutzt soziale Netzwerke\"        \"Nutzt keine soziale Netzwerken\"\n\npend_kap5$PSM0100_fct2 &lt;- fct_recode(pend_kap5$PSM0100_fct,\n  `Ja, nutzt soziale Netzwerke` = \"Nutzt soziale Netzwerke\", # bei Leerzeichen `` um die Wörter\n  )\n\n\npend_kap5 %&gt;% select(contains(\"PSM0100\")) %&gt;% head()\n\n# A tibble: 6 × 3\n  PSM0100                  PSM0100_fct                    PSM0100_fct2          \n  &lt;dbl+lbl&gt;                &lt;fct&gt;                          &lt;fct&gt;                 \n1  2 [Nein]                Nutzt keine soziale Netzwerken Nutzt keine soziale N…\n2  1 [Ja]                  Nutzt soziale Netzwerke        Ja, nutzt soziale Net…\n3  2 [Nein]                Nutzt keine soziale Netzwerken Nutzt keine soziale N…\n4 -5 [Nutzt kein Internet] &lt;NA&gt;                           &lt;NA&gt;                  \n5 -5 [Nutzt kein Internet] &lt;NA&gt;                           &lt;NA&gt;                  \n6 -5 [Nutzt kein Internet] &lt;NA&gt;                           &lt;NA&gt;                  \n\n\nWeitere fct_....() Funktionen aus {forcats}, einen Überblick gibt das Cheatsheet."
  },
  {
    "objectID": "05_data_wrangle1.html#übung",
    "href": "05_data_wrangle1.html#übung",
    "title": "5  Data Wrangling I: Labels & factor",
    "section": "5.3 Übung",
    "text": "5.3 Übung\n\npend_ue5 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"pnr\",\"welle\",\"PD0400\")) %&gt;% \n  filter(PD0400&gt;0)\n\nBearbeiten Sie die value labels von PD0400: Religiositaet, Selbsteinstufung\n\n\n\n\n\nvalue\nlabel\n\n\n\n\n1\nUeberhaupt nicht religioes\n\n\n2\nEher nicht religioes\n\n\n3\nEher religioes\n\n\n4\nSehr religioes\n\n\n\n\n\n\n\n\nVerschaffen Sie sich zunächst mit head() und einer Auszählung mit count() einen Überblick.\nWie können Sie die labels aus den attributes() mit as_factor() in eine Variable PD0400_fct übernehmen?\nErstellen Sie einen factor() Variable F411_01_fct2 mit value labels: 1 = Überhaupt nicht, 2 = Eher nicht,3 = Eher schon,4 = Sehr\n\nBonusübung: Verwenden Sie die gelabelte Variable für eine Balkengrafik."
  },
  {
    "objectID": "05_data_wrangle1.html#anhang",
    "href": "05_data_wrangle1.html#anhang",
    "title": "5  Data Wrangling I: Labels & factor",
    "section": "5.4 Anhang",
    "text": "5.4 Anhang\n\n5.4.1 Labels löschen mit zap_... aus {haven}\nHäufig führen die Label-attributes() zu Problemen in der weiteren Verarbeitung. Mit haven::zap_labels() können wir die Value labels aus einem Datensatz löschen mit haven::zap_label() können wir die Variable labels entfernen.\n\npend_kap5\n\n# A tibble: 683 × 6\n          pnr welle              zpsex         PSM0100             azges1 palter\n        &lt;dbl&gt; &lt;dbl+lbl&gt;          &lt;dbl+lbl&gt;     &lt;dbl+lbl&gt;           &lt;dbl+&gt; &lt;dbl+&gt;\n 1 1000002601 8 [Welle 8 (2014)] 2 [Weiblich]   2 [Nein]           22     34    \n 2 1000010402 8 [Welle 8 (2014)] 2 [Weiblich]   1 [Ja]             40     30    \n 3 1000019102 8 [Welle 8 (2014)] 1 [Maennlich]  2 [Nein]           40     34    \n 4 1000031403 8 [Welle 8 (2014)] 1 [Maennlich] -5 [Nutzt kein Int… 44     52    \n 5 1000032801 8 [Welle 8 (2014)] 2 [Weiblich]  -5 [Nutzt kein Int… 44     58    \n 6 1000032802 8 [Welle 8 (2014)] 1 [Maennlich] -5 [Nutzt kein Int… 43     62    \n 7 1000038201 8 [Welle 8 (2014)] 1 [Maennlich]  1 [Ja]             43     61    \n 8 1000040003 8 [Welle 8 (2014)] 1 [Maennlich]  2 [Nein]           36     40    \n 9 1000051801 8 [Welle 8 (2014)] 2 [Weiblich]   2 [Nein]           31     44    \n10 1000053101 8 [Welle 8 (2014)] 1 [Maennlich]  1 [Ja]             27     47    \n# … with 673 more rows\n\npend_kap5 %&gt;% \n  haven::zap_labels() # value labels raus\n\n# A tibble: 683 × 6\n          pnr welle zpsex PSM0100 azges1 palter\n        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 1000002601     8     2       2     22     34\n 2 1000010402     8     2       1     40     30\n 3 1000019102     8     1       2     40     34\n 4 1000031403     8     1      -5     44     52\n 5 1000032801     8     2      -5     44     58\n 6 1000032802     8     1      -5     43     62\n 7 1000038201     8     1       1     43     61\n 8 1000040003     8     1       2     36     40\n 9 1000051801     8     2       2     31     44\n10 1000053101     8     1       1     27     47\n# … with 673 more rows\n\n\n\n\n5.4.2 Labels selbst erstellen und ranspielen\nEin alternativer Weg geht über einen kleinen Label-data.frame und left_join() (mehr zu left_join() später.)\n\ntab2 &lt;- pend_kap5 %&gt;% count(PSM0100)\ntab2\n\n# A tibble: 3 × 2\n  PSM0100                      n\n  &lt;dbl+lbl&gt;                &lt;int&gt;\n1 -5 [Nutzt kein Internet]    28\n2  1 [Ja]                    318\n3  2 [Nein]                  337\n\n\n\nlab_df &lt;- data.frame(PSM0100=1:2)\nlab_df\n\n  PSM0100\n1       1\n2       2\n\nlab_df$PD0400_lab &lt;- factor(lab_df$PSM0100,levels = 1:2,\n                           labels = c(\"Nutzt soziale Netzwerke\",\n                                      \"Nutzt keine soziale Netzwerken\"))\nlab_df\n\n  PSM0100                     PD0400_lab\n1       1        Nutzt soziale Netzwerke\n2       2 Nutzt keine soziale Netzwerken\n\n\n\ntab2 %&gt;% \n  left_join(lab_df,by = \"PSM0100\")\n\n# A tibble: 3 × 3\n  PSM0100                      n PD0400_lab                    \n  &lt;dbl+lbl&gt;                &lt;int&gt; &lt;fct&gt;                         \n1 -5 [Nutzt kein Internet]    28 &lt;NA&gt;                          \n2  1 [Ja]                    318 Nutzt soziale Netzwerke       \n3  2 [Nein]                  337 Nutzt keine soziale Netzwerken\n\n\n\n\n5.4.3 Labels in R erstellen und nach bspw. Stata exportieren\nWenn wir aber beispielsweise einen Datensatz für Stata labeln wollen, hilft uns wieder {labelled}:\n\nlibrary(labelled)\n\n\npend_kap5$zpsex_num2 &lt;- as.numeric(pend_kap5$zpsex)\nattributes(pend_kap5$zpsex_num2)\n\nNULL\n\nval_labels(pend_kap5$zpsex_num2) &lt;- c(\"Männer\"=1,\"Frauen\"=2)\nattributes(pend_kap5$zpsex_num2)\n\n$labels\nMänner Frauen \n     1      2 \n\n$class\n[1] \"haven_labelled\" \"vctrs_vctr\"     \"double\"        \n\npend_kap5 %&gt;% count(zpsex_num2)\n\n# A tibble: 2 × 2\n  zpsex_num2     n\n  &lt;dbl+lbl&gt;  &lt;int&gt;\n1 1 [Männer]   324\n2 2 [Frauen]   359\n\n\n\npend_kap5 %&gt;% \n  select(zpsex_num2) %&gt;% \n  haven::write_dta(.,path = \"./data/pend_kap5.dta\")\n\n…in Stata:\n\nuse \"./data/pend_kap5.dta\" \ntab zpsex_num2 \n\n zpsex_num2 |      Freq.     Percent        Cum.\n------------+-----------------------------------\n     Männer |        324       47.44       47.44\n     Frauen |        359       52.56      100.00\n------------+-----------------------------------\n      Total |        683      100.00\n\n\nMehr zu labels in {labelled}."
  },
  {
    "objectID": "05_data_wrangle1.html#footnotes",
    "href": "05_data_wrangle1.html#footnotes",
    "title": "5  Data Wrangling I: Labels & factor",
    "section": "",
    "text": "Nicht zu verwechseln mit as.factor() aus base R - der _ macht einen Unterschied!↩︎"
  },
  {
    "objectID": "06_data_wrangle2.html#var",
    "href": "06_data_wrangle2.html#var",
    "title": "6  Data Wrangling II",
    "section": "6.1 Variablen erstellen",
    "text": "6.1 Variablen erstellen\nNun sehen wir uns die Möglichkeiten, Variablen zu erstellen, nochmal etwas genauer an. Grundsätzlich gibt es zwei Arten, Variablen in einen data.frame hinzuzufügen:\n\n6.1.1 base R: ...$newvar &lt;-\n\ndat3$studs_to_mean  &lt;- dat3$studs - mean(dat3$studs)\ndat3\n\n  studs profs gegr prom_recht                uni studs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625\n4 14954   250 1971      FALSE          FH Aachen     -6736.625\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375\n\n\nMit &lt;- NULL können Variablen auch gelöscht werden:\n\ndat3$studs_to_mean  &lt;-  NULL\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\n\n\n6.1.2 {dplyr}: mutate(neue_var= )\nEine alternative Möglichkeit, Variablen zu erstellen ist mutate(neu_variable = ) aus {dplyr} ({tidyverse}):\n\n\n\n\n\n\n\n\n\n\nDie grundsätzliche Struktur ist immer datensatz %&gt;% mutate(neue_var = ....):\n\ndat3 %&gt;% mutate(studs_to_mean = studs-mean(studs))\n\n  studs profs gegr prom_recht                uni studs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625\n4 14954   250 1971      FALSE          FH Aachen     -6736.625\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375\n\n\nWir können auch mehrere Variablen innerhalb eines mutate()-Befehls erstellen:\n\ndat3 %&gt;% mutate(studs_to_mean = studs-mean(studs),\n                profs_to_mean = profs-mean(profs))\n\n  studs profs gegr prom_recht                uni studs_to_mean profs_to_mean\n1 19173   322 1971       TRUE         Uni Bremen     -2517.625         -6.25\n2  5333    67 1830       TRUE         Uni Vechta    -16357.625       -261.25\n3 15643   210 1973       TRUE      Uni Oldenburg     -6047.625       -118.25\n4 14954   250 1971      FALSE          FH Aachen     -6736.625        -78.25\n5 47269   553 1870       TRUE        RWTH Aachen     25578.375        224.75\n6 23659   438 1457       TRUE       Uni Freiburg      1968.375        109.75\n7  9415   150 1818       TRUE           Uni Bonn    -12275.625       -178.25\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     16388.375        307.75\n\n\nOder Variablen können innerhalb von mutate() weiterverwendet werden:\n\ndat3 %&gt;% mutate(rel_to_mean = studs-mean(studs),\n                above_mean = rel_to_mean &gt; 0)\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625      FALSE\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625      FALSE\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625      FALSE\n4 14954   250 1971      FALSE          FH Aachen   -6736.625      FALSE\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       TRUE\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       TRUE\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625      FALSE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       TRUE\n\n\nDer Ausgangsdatensatz bleibt aber unverändert:\n\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\nWenn wir die Ergebnisse behalten wollen, müssen wir das Ergebnis in einem Objekt ablegen:\n\ndat4 &lt;-\n  dat3 %&gt;% \n  mutate(rel_to_mean = studs-mean(studs),\n         above_mean = rel_to_mean &gt; 0)\n\ndat4\n\n  studs profs gegr prom_recht                uni rel_to_mean above_mean\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625      FALSE\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625      FALSE\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625      FALSE\n4 14954   250 1971      FALSE          FH Aachen   -6736.625      FALSE\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375       TRUE\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375       TRUE\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625      FALSE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375       TRUE\n\n\n\n\n\n\n\n\nDummy-Variablen erstellen mit as.numeric()\n\n\n\nWenn wir logische Variablen mit as.numeric() in numerische Variablen umformatieren erhalten wir eine Dummy-Codierung:\n\ndat3 %&gt;% \n  mutate(prom_dummy = as.numeric(prom_recht ),\n         over10k    = as.numeric(studs &gt; 10000) # Abgleich direkt in numeric\n         )\n\n  studs profs gegr prom_recht                uni prom_dummy over10k\n1 19173   322 1971       TRUE         Uni Bremen          1       1\n2  5333    67 1830       TRUE         Uni Vechta          1       0\n3 15643   210 1973       TRUE      Uni Oldenburg          1       1\n4 14954   250 1971      FALSE          FH Aachen          0       1\n5 47269   553 1870       TRUE        RWTH Aachen          1       1\n6 23659   438 1457       TRUE       Uni Freiburg          1       1\n7  9415   150 1818       TRUE           Uni Bonn          1       0\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg          0       1\n\n\n\n\n\n\n6.1.3 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#group_by",
    "href": "06_data_wrangle2.html#group_by",
    "title": "6  Data Wrangling II",
    "section": "6.2 Gruppierung mit group_by() oder .by=",
    "text": "6.2 Gruppierung mit group_by() oder .by=\nDie wirkliche Stärke von mutate() kommt aber erst zum Tragen, wenn wir es mit weiteren {dplyr}-Funktionen kombinieren. Eine häufige Aufgabe in der Datenaufbereitung sind gruppierte Werte.\n\n\n\n\n\n\n\n\n\nWir machen unseren Beispieldatensatz noch etwas kleiner:\n\ndat5 &lt;- dat3 %&gt;% \n  select(-uni,-gegr) # nur dass alles zu sehen ist\n\nWenn wir einen Datensatz mit group_by() entlang den Werten einer Variablen gruppieren, dann werden alle weiteren mutate() Berechnungen nur innerhalb dieser Gruppen ausgeführt:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs),\n         m_profs2 = mean(profs))\n\n# A tibble: 8 × 7\n# Groups:   prom_recht [2]\n  studs profs prom_recht m_studs m_profs m_studs2 m_profs2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt;        &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 19173   322 TRUE        21691.    328.   20082       290\n2  5333    67 TRUE        21691.    328.   20082       290\n3 15643   210 TRUE        21691.    328.   20082       290\n4 14954   250 FALSE       21691.    328.   26516.      443\n5 47269   553 TRUE        21691.    328.   20082       290\n6 23659   438 TRUE        21691.    328.   20082       290\n7  9415   150 TRUE        21691.    328.   20082       290\n8 38079   636 FALSE       21691.    328.   26516.      443\n\n\nVerwenden wir group_by(), können (sollten!) wir mit ungroup() die Gruppierung wieder aufheben, sobald wir sie nicht mehr benötigen:\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  group_by(prom_recht) %&gt;%\n  mutate(m_studs2 = mean(studs)) %&gt;% \n  ungroup() %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n\n\n  studs profs prom_recht  m_studs m_profs m_studs2 m_profs2\n1 19173   322       TRUE 21690.62  328.25  20082.0   328.25\n2  5333    67       TRUE 21690.62  328.25  20082.0   328.25\n3 15643   210       TRUE 21690.62  328.25  20082.0   328.25\n4 14954   250      FALSE 21690.62  328.25  26516.5   328.25\n5 47269   553       TRUE 21690.62  328.25  20082.0   328.25\n6 23659   438       TRUE 21690.62  328.25  20082.0   328.25\n7  9415   150       TRUE 21690.62  328.25  20082.0   328.25\n8 38079   636      FALSE 21690.62  328.25  26516.5   328.25\n\n\nSeit {dplyr}-Version 1.1.1 können wir direkt in mutate() mit dem Argument .by= eine Gruppierung angeben. Diese Gruppierung .by= gilt dabei nur für die unmittelbaren Berechnungen innerhalb mutate() - wir sparen uns das ungroup().\n\ndat5 %&gt;%\n  mutate(m_studs = mean(studs),\n         m_profs = mean(profs)) %&gt;% \n  mutate(m_studs2 = mean(studs),\n         .by = prom_recht) %&gt;% \n  mutate(m_profs2 = mean(profs))\n\n  studs profs prom_recht  m_studs m_profs m_studs2 m_profs2\n1 19173   322       TRUE 21690.62  328.25  20082.0   328.25\n2  5333    67       TRUE 21690.62  328.25  20082.0   328.25\n3 15643   210       TRUE 21690.62  328.25  20082.0   328.25\n4 14954   250      FALSE 21690.62  328.25  26516.5   328.25\n5 47269   553       TRUE 21690.62  328.25  20082.0   328.25\n6 23659   438       TRUE 21690.62  328.25  20082.0   328.25\n7  9415   150       TRUE 21690.62  328.25  20082.0   328.25\n8 38079   636      FALSE 21690.62  328.25  26516.5   328.25\n\n\nMit summarise() statt mutate() erhalten wir eine Übersicht:\n\ndat5 %&gt;%\n  summarise(m_studs = mean(studs),.by = prom_recht)\n\n  prom_recht m_studs\n1       TRUE 20082.0\n2      FALSE 26516.5\n\n\n\n6.2.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#across",
    "href": "06_data_wrangle2.html#across",
    "title": "6  Data Wrangling II",
    "section": "6.3 across(): Mehrere Variablen bearbeiten",
    "text": "6.3 across(): Mehrere Variablen bearbeiten\nEine sehr vielseitige Erweiterung für mutate() und summarise() ist across(). Hier mit können wir eine Funktion auf mehrere Spalten gleichzeitig anwenden, ohne uns zu wiederholen:\n\ndat3 %&gt;%\n  summarise(studs = mean(studs),\n            profs = mean(profs))\n\n     studs  profs\n1 21690.62 328.25\n\n\nHier ist across() deutlich kürzer - für die Variablenauswahl können wir die ?select_helpers verwenden - z.B. matches():\n\ndat3 %&gt;%\n  summarise(across(.cols = matches(\"studs|profs\"),.fns = ~mean(.x)))\n\n     studs  profs\n1 21690.62 328.25\n\n\nNatürlich ist das auch kombinierbar mit group_by():\n\ndat3 %&gt;%\n  group_by(prom_recht) %&gt;%\n  summarise(across(matches(\"studs|profs\"), ~mean(.x)))\n\n# A tibble: 2 × 3\n  prom_recht  studs profs\n  &lt;lgl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 FALSE      26516.   443\n2 TRUE       20082    290\n\n\nWir können auch mehrere Funktionen durchführen, dafür müssen wir sie in einer list() angeben:\n\ndat3 %&gt;%\n  group_by(prom_recht) %&gt;%\n  summarise(across(matches(\"studs|profs\"), list(mean = ~mean(.x), sd = ~sd(.x))))\n\n# A tibble: 2 × 5\n  prom_recht studs_mean studs_sd profs_mean profs_sd\n  &lt;lgl&gt;           &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 FALSE          26516.   16352.        443     273.\n2 TRUE           20082    14858.        290     183.\n\n\nDiese list()auch vorab ablegen und dann verwenden:\n\nwert_liste &lt;- list(mean = ~mean(.x), sd = ~sd(.x), max = ~max(.x,na.rm = T))\n\ndat3 %&gt;%\n  group_by(prom_recht) %&gt;%\n  summarise(across(matches(\"studs|profs\"), wert_liste))\n\n# A tibble: 2 × 7\n  prom_recht studs_mean studs_sd studs_max profs_mean profs_sd profs_max\n  &lt;lgl&gt;           &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 FALSE          26516.   16352.     38079        443     273.       636\n2 TRUE           20082    14858.     47269        290     183.       553\n\n\nMit dem .names()-Argument können wir auch die Benennung der Spalten steuern. {.fn} steht dabei als Platzhalter für die angewendete Funktion, {.col} für den Namen der bearbeiteten Variable.\n\ndat3 %&gt;%\n  group_by(prom_recht) %&gt;%\n  summarise(across(matches(\"studs|profs\"), \n                   list(mean = ~mean(.x), sd = ~sd(.x)),\n                   .names = \"{.fn}_{.col}\"))\n\n# A tibble: 2 × 5\n  prom_recht mean_studs sd_studs mean_profs sd_profs\n  &lt;lgl&gt;           &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 FALSE          26516.   16352.        443     273.\n2 TRUE           20082    14858.        290     183.\n\n\n\n\n\n\n\n\n\n\nAlle gezeigten Funktionen funktionieren natürlich auch mit mutate():\n\ndat3 %&gt;%\n  mutate(across(matches(\"studs|profs\"), ~mean(.x), .names = \"m_{.col}\"))\n\n  studs profs gegr prom_recht                uni  m_studs m_profs\n1 19173   322 1971       TRUE         Uni Bremen 21690.62  328.25\n2  5333    67 1830       TRUE         Uni Vechta 21690.62  328.25\n3 15643   210 1973       TRUE      Uni Oldenburg 21690.62  328.25\n4 14954   250 1971      FALSE          FH Aachen 21690.62  328.25\n5 47269   553 1870       TRUE        RWTH Aachen 21690.62  328.25\n6 23659   438 1457       TRUE       Uni Freiburg 21690.62  328.25\n7  9415   150 1818       TRUE           Uni Bonn 21690.62  328.25\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg 21690.62  328.25\n\n\nMehr Beispiele in der Hilfe zu across\n\n6.3.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#eigene-funktionen",
    "href": "06_data_wrangle2.html#eigene-funktionen",
    "title": "6  Data Wrangling II",
    "section": "6.4 Eigene Funktionen",
    "text": "6.4 Eigene Funktionen\nWoher kommt aber die ~1 in across()? Dazu sehen wir uns einmal die Grundlagen von Funktionen in R an.\nDazu sehen wir uns drei Zufriedensheitsvariablen für die Befragten aus den Zeilen 12-16 an:\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nWichtig bei Beruf\n\n\n\n\n\nPEO0300a\n\nViel Geld verdienen\n\n\n\nPEO0300b\n\nEin Beruf, der Spass macht\n\n\n\nPEO0300c\n\nGute Aufstiegsmoeglichkeiten\n\n\n\nPEO0300d\n\nEin sicherer Arbeitsplatz\n\n\n\nPEO0300e\n\nEin Beruf, bei dem man seine Faehigkeiten zeigen kann\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n-10 bis -1\n1\n2\n3\n4\n\n\n\n\nt.n.z./k.A.\nSehr wichtig\nEher wichtig\nEher nicht wichtig\nUeberhaupt nicht wichtig\n\n\n\n\n\n\n\n\npend &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\")\n\nsat_small &lt;- \n  pend %&gt;% \n    filter(welle == 1) %&gt;% \n    select(matches(\"PEO0300(a|b|c)\")) %&gt;% \n    slice(12:16) %&gt;% \n    haven::zap_labels() %&gt;% haven::zap_label() # labels entfernen\nsat_small\n\n# A tibble: 5 × 3\n  PEO0300a PEO0300b PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\n\nHäufig wollen wir mehrere Variablen mit der gleichen Operation bearbeiten. Oben haben wir gesehen wie sich das mit across() für existierende Funktionen erledigen lässt. Was aber, wenn wir eine Berechnung durchführen wollen, die nicht einfach die Anwendung von mean(), sd() o.ä. ist?\n\nsat_small %&gt;% \n  mutate(dmean_PEO0300a = PEO0300a - mean(PEO0300a,na.rm = T),\n         dmean_PEO0300c = PEO0300c - mean(PEO0300c,na.rm = T))\n\n# A tibble: 5 × 5\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6         -0.200\n2        1        1        3           -0.4          0.8  \n3        1        1        3           -0.4          0.8  \n4        2        1        1            0.6         -1.2  \n5        1        1        2           -0.4         -0.200\n\n\n…und jetzt noch F1450_06? Dann hätten wir drei Mal das mehr oder weniger gleiche getippt und damit gegen das “DRY”-Prinzip2 verstoßen. Außerdem gibt es im PASS CampusFile insgesamt 5 Spalten mit ähnlichen Zufriedenheitsvariablen. Wenn wir die alle bearbeiten möchten, ist copy & paste keine echte Option.\nEigene Funktionen helfen uns, das DRY-Prinzip in R umzusetzen. Wir machen die Berechnungsschritte Teil einer function() und wenden diese dann auf die gewünschten Variablen an. Eine Funktion hat einen Input, für welchen ein Platzhalter in der () definiert wird. Dieser Platzhalter kann dann innerhalb der Funktion - zwischen den {} - aufgerufen und bearbeitet werden. Als Ergebnis erhalten wir das Objekt, das wir in return() angeben. return() muss immer als letztes angeben werden und wir können immer nur ein Objekt als Output definieren:\n\ndtomean &lt;- function(x){\n  d_x &lt;- x - mean(x,na.rm = T)\n  return(d_x)\n}\n\n\nvar1 &lt;- c(1,6,3,7,8,1,5)\nmean(var1)\n\n[1] 4.428571\n\ndtomean(var1)\n\n[1] -3.4285714  1.5714286 -1.4285714  2.5714286  3.5714286 -3.4285714  0.5714286\n\n\nWie können wir unsere Funktion dtomean() jetzt auf die Variablen aus unserem sat_small anwenden? Grundsätzlich haben wir ganz zu Beginn gesehen, dass ein data.frame lediglich zusammengefügte Sammlung von Vektoren (den Variablen) ist. Dementsprechend können wir jetzt unsere dtomean() auf eine Variable (einen Vektor) anwenden, indem wir ihn mit data.frame$variablename aufrufen:\n\ndtomean(sat_small$PEO0300a)\n\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n\nUm unsere Funktion jetzt auf jede Variable eines data.frame anzuwenden, können wir lapply() verwenden - der Output ist dann eine Liste, deren Elemente nach den Variablennamen benannt werden:\n\nlapply(sat_small,FUN = dtomean)\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\nres &lt;- lapply(sat_small,FUN = dtomean)\nclass(res)\n\n[1] \"list\"\n\n\nmap() aus {purrr} ist eine Alternative zu lapply:\n\nlapply(sat_small,FUN = dtomean)\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\nsat_small %&gt;% map(~dtomean(.x))\n\n$PEO0300a\n[1]  0.6 -0.4 -0.4  0.6 -0.4\n\n$PEO0300b\n[1]  1.6 -0.4 -0.4 -0.4 -0.4\n\n$PEO0300c\n[1] -0.2  0.8  0.8 -1.2 -0.2\n\n\nDiese formula syntax Schreibweise findet sich dann auch in across() wieder - zusätzlich haben wir hier direkt über .names = die Möglichkeit, die Variablennamen für die Ergebnisse zu bearbeiten:\n\nsat_small %&gt;% \n  mutate(across(matches(\"PEO0300\"),~dtomean(.x),.names = \"dmean_{.col}\"))\n\n# A tibble: 5 × 6\n  PEO0300a PEO0300b PEO0300c dmean_PEO0300a dmean_PEO0300b dmean_PEO0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt;\n1        2        3        2            0.6            1.6         -0.200\n2        1        1        3           -0.4           -0.4          0.8  \n3        1        1        3           -0.4           -0.4          0.8  \n4        2        1        1            0.6           -0.4         -1.2  \n5        1        1        2           -0.4           -0.4         -0.200\n\n\n\n\n\n\n\n6.4.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#hilfsfunktionen-ifelse-und-case_when",
    "href": "06_data_wrangle2.html#hilfsfunktionen-ifelse-und-case_when",
    "title": "6  Data Wrangling II",
    "section": "6.5 Hilfsfunktionen ifelse() und case_when()",
    "text": "6.5 Hilfsfunktionen ifelse() und case_when()\nifelse() ist eine große Hilfe für alle Umcodierungen: wir formulieren darin eine Bedingung und wenn diese zutrifft wird der erste Wert eingesetzt, wenn nicht wird der zweite Wert eingesetzt. Hier fragen wir also ab, ob studs-mean(studs) größer 0 ist - dann wird darüber eingesetzt, ansonsten eine darunter:\n\ndat3 %&gt;% mutate(rel_to_mean = studs-mean(studs),\n                ab_mean_lab = ifelse(rel_to_mean &gt; 0,\"darüber\",\"darunter\"))\n\n  studs profs gegr prom_recht                uni rel_to_mean ab_mean_lab\n1 19173   322 1971       TRUE         Uni Bremen   -2517.625    darunter\n2  5333    67 1830       TRUE         Uni Vechta  -16357.625    darunter\n3 15643   210 1973       TRUE      Uni Oldenburg   -6047.625    darunter\n4 14954   250 1971      FALSE          FH Aachen   -6736.625    darunter\n5 47269   553 1870       TRUE        RWTH Aachen   25578.375     darüber\n6 23659   438 1457       TRUE       Uni Freiburg    1968.375     darüber\n7  9415   150 1818       TRUE           Uni Bonn  -12275.625    darunter\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg   16388.375     darüber\n\n\ncase_when() ({dplyr}) erweitert dieses Prinzip, sodass wir mehr als zwei Optionen angeben können. Die Syntax ist aber etwas anders: hier geben wir erst die Bedingung an, dann nach einer ~3 die einzusetzenden Werte:\n\ndat3 %&gt;% mutate(alter = case_when(gegr &lt; 1500 ~ \"sehr alt\",\n                                  gegr &lt; 1900 ~ \"alt\"))\n\n  studs profs gegr prom_recht                uni    alter\n1 19173   322 1971       TRUE         Uni Bremen     &lt;NA&gt;\n2  5333    67 1830       TRUE         Uni Vechta      alt\n3 15643   210 1973       TRUE      Uni Oldenburg     &lt;NA&gt;\n4 14954   250 1971      FALSE          FH Aachen     &lt;NA&gt;\n5 47269   553 1870       TRUE        RWTH Aachen      alt\n6 23659   438 1457       TRUE       Uni Freiburg sehr alt\n7  9415   150 1818       TRUE           Uni Bonn      alt\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg     &lt;NA&gt;\n\n\nMit TRUE können alle Fälle angesprochen werden, die bis dahin keiner Bedingung entsprochen haben:\n\ndat3 %&gt;% mutate(alter = case_when(gegr &lt; 1500 ~ \"sehr alt\",\n                                  gegr &lt; 1900 ~ \"alt\",\n                                  TRUE ~ \"relativ neu\"))\n\n  studs profs gegr prom_recht                uni       alter\n1 19173   322 1971       TRUE         Uni Bremen relativ neu\n2  5333    67 1830       TRUE         Uni Vechta         alt\n3 15643   210 1973       TRUE      Uni Oldenburg relativ neu\n4 14954   250 1971      FALSE          FH Aachen relativ neu\n5 47269   553 1870       TRUE        RWTH Aachen         alt\n6 23659   438 1457       TRUE       Uni Freiburg    sehr alt\n7  9415   150 1818       TRUE           Uni Bonn         alt\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg relativ neu\n\n\nDas muss sich nicht auf eine Variable beschränken:\n\ndat3 %&gt;% mutate(alter = case_when(gegr &lt; 1500 & prom_recht == T ~ \"sehr alte Uni\",\n                                  gegr &lt; 1900 & prom_recht == T ~ \"alte Uni\",\n                                  gegr &gt; 1900 & prom_recht == T ~ \"junge Uni\",\n                                  gegr &lt; 1900 & prom_recht == F ~ \"alte Hochschule\",\n                                  gegr &gt; 1900 & prom_recht == F ~ \"junge Hochschule\"))\n\n  studs profs gegr prom_recht                uni            alter\n1 19173   322 1971       TRUE         Uni Bremen        junge Uni\n2  5333    67 1830       TRUE         Uni Vechta         alte Uni\n3 15643   210 1973       TRUE      Uni Oldenburg        junge Uni\n4 14954   250 1971      FALSE          FH Aachen junge Hochschule\n5 47269   553 1870       TRUE        RWTH Aachen         alte Uni\n6 23659   438 1457       TRUE       Uni Freiburg    sehr alte Uni\n7  9415   150 1818       TRUE           Uni Bonn         alte Uni\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg junge Hochschule\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.1 Übung"
  },
  {
    "objectID": "06_data_wrangle2.html#variablen-umbenennen",
    "href": "06_data_wrangle2.html#variablen-umbenennen",
    "title": "6  Data Wrangling II",
    "section": "6.6 Variablen umbenennen",
    "text": "6.6 Variablen umbenennen\nUm Variablen umzubenennen gibt es rename(neuer_name = alter_name)\n\nsat_small %&gt;% rename(neuername =PEO0300a)\n\n# A tibble: 5 × 3\n  neuername PEO0300b PEO0300c\n      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1         2        3        2\n2         1        1        3\n3         1        1        3\n4         2        1        1\n5         1        1        2\n\n\nFür fortgeschrittene Veränderungen empfiehlt sich ein Blick in rename_with(). Damit können wir Regular Expressions, bspw. aus {stringr} verwenden. Hier nur ein Beispiel:\n\nsat_small %&gt;% rename_with(~tolower(.))\n\n# A tibble: 5 × 3\n  peo0300a peo0300b peo0300c\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1        2        3        2\n2        1        1        3\n3        1        1        3\n4        2        1        1\n5        1        1        2\n\nsat_small %&gt;% rename_with(~str_remove(.x,\"PEO0300\"))\n\n# A tibble: 5 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     3     2\n2     1     1     3\n3     1     1     3\n4     2     1     1\n5     1     1     2\n\nsat_small %&gt;% rename_with(~str_replace(.x,\"PEO0300\",\"Beruf_\"))\n\n# A tibble: 5 × 3\n  Beruf_a Beruf_b Beruf_c\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1       2       3       2\n2       1       1       3\n3       1       1       3\n4       2       1       1\n5       1       1       2"
  },
  {
    "objectID": "06_data_wrangle2.html#übungen",
    "href": "06_data_wrangle2.html#übungen",
    "title": "6  Data Wrangling II",
    "section": "6.7 Übungen",
    "text": "6.7 Übungen\n\n6.7.1 Übung\n\nErstellen Sie dat3 wie oben gezeigt aus dat1 und dat2\nBerechnen Sie das Betreuungsverhältnis (Studierende pro Professur studs/profs) an den Hochschulen relativ zum Mittelwert des Betreuungsverhältnisses (rel_studprofs).\nLiegt das Betreuungsverhältnis über oder unter dem Mittelwert? Wie können Sie den Befehl anpassen, sodass die Variable rel_studprofs lediglich TRUE oder FALSE enthält anstelle der Zahlenwerte.\nWandeln Sie rel_studprofs in eine Dummy-Variable mit 0/1 als Werten statt TRUE/FALSE\n\n\n\n\n\n\n\nDaumenregel zur Entscheidung, ob mutate() oder ...$newvar &lt;- besser passt: Immer wenn es nur darum geht, schnell eine Variable zu erstellen/löschen, ist ...$newvar &lt;- die einfachere Wahl. Sobald es darüber hinaus geht, hat mutate() sehr große Vorteile (folgender Abschnitt).\n\n\n\nZurück nach oben\n\n\n6.7.2 Übung\n\nVerwenden Sie weiterhin den Uni-Datensatz.\nBerechnen Sie das Betreuungsverhältnis (studprofs) relativ zum Mittelwert getrennt für Hochschulen/Unis mit und ohne Promotionsrecht und fügen Sie dieses als neue Spalte ein.\nTesten Sie sowohl die Variante mit group_by() als auch .by =.\n\nZurück nach oben\n\n\n\n\n\n6.7.3 Übung\n\nVerwenden Sie den pend_small-Datensatz:\n\n\npend_small &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                               col_select = c(\"welle\",\"zpsex\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"PEO0400d\")\n                               ) %&gt;% \n  filter(welle == 2) %&gt;% \n  slice(1:15)\n\n\nBerechnen Sie den Mittelwert für die Variablen PEO0400a, PEO0400b, PEO0400c und PEO0400d:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlab\n\n\n\n\n\nPEO0400a\n\nFrau sollte bereit, Arbeitszeit wegen Familie zu verringern\n\n\n\nPEO0400b\n\nWas Frauen wirklich wollen, sind ein Heim und Kinder\n\n\n\nPEO0400c\n\nBerufst. Mutter kann genauso herzl. Verhaeltn. zu Kindern haben\n\n\n\nPEO0400d\n\nAufgabe Ehemann: Geld verdienen, Aufgabe Ehefrau: Haushalt/Fam.\n\n\n\n\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n11     2     1        4        3        2        3\n12     2     2        2        3        2        3\n13     2     1        2        3        2        3\n14     2     1        1        2        1        1\n15     2     1        1        1        1        2\n\n\n\nVerwenden Sie across(), um die Mittelwerte für alle vier Variablen zu berechnen.\nBerechnen Sie die Mittelwerte getrennt nach Geschlecht (zpsex), indem Sie group_by() oder .by = verwenden.\nFügen Sie auch die Varianz (var()) hinzu und nutzen sie .names=, um die Spaltennamen nach dem Schema kennzahl.variable zu benennen.\n\nZurück nach oben\n\n\n6.7.4 Übung\nVerwenden Sie weiterhin pend_small:\n\npend_small\n\n\n\n   welle zpsex PEO0400a PEO0400b PEO0400c PEO0400d\n1      2     2        1        1        4        1\n2      2     1        2        1        3        2\n3      2     2        1        3        1        4\n4      2     2        1        1        4        1\n5      2     2        1        1        1        1\n6      2     1        1        1        1        1\n7      2     1        1        2        1        4\n8      2     1        3        2        3        2\n9      2     2        3        3        3        3\n10     2     1        2        3        2        2\n11     2     1        4        3        2        3\n12     2     2        2        3        2        3\n13     2     1        2        3        2        3\n14     2     1        1        2        1        1\n15     2     1        1        1        1        2\n\n\n\nStandardisieren Sie die Variablen PEO0400a - PEO0400d aus pend_small nach folgendem Muster:\n\n\npend_small %&gt;% \n  mutate(std_PEO0400b = (PEO0400b - mean(PEO0400b,na.rm = T))/sd(PEO0400b,na.rm = T))\n\n\nNutzen Sie eine Funktion, um nicht wiederholt die gleichen Schritte einzugeben.\nVerwenden Sie zusätzlich across(), um die Funktion auf die gewünschten Variablen anzuwenden.\n\nZurück nach oben\n\n\n6.7.5 Übung\n\nBearbeiten Sie pend_small2:\n\n\npend_small2 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                         col_select = c(\"palter\",\"PEO0400a\",\"PEO0400b\",\"PEO0400c\",\"statakt\")) \npend_small2 &lt;- pend_small2 %&gt;% slice(5624:5640)\npend_small2\n\n# A tibble: 17 × 5\n   palter    PEO0400a                         PEO0400b        PEO0400c statakt  \n   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;                        &lt;dbl+lbl&gt;       &lt;dbl+lb&gt; &lt;dbl+lbl&gt;\n 1 77         1 [Stimme voll und ganz zu]      3 [Stimme ehe…  3 [Sti… -10 [Ite…\n 2 78        -9 [Item in Welle nicht erhoben] -9 [Item in We… -9 [Ite… -10 [Ite…\n 3 51         2 [Stimme eher zu]               4 [Stimme ueb…  1 [Sti…  -9 [Ite…\n 4 23         3 [Stimme eher nicht zu]         3 [Stimme ehe…  2 [Sti…  -9 [Ite…\n 5 17         3 [Stimme eher nicht zu]         2 [Stimme ehe…  1 [Sti…  -9 [Ite…\n 6 47         3 [Stimme eher nicht zu]         2 [Stimme ehe…  2 [Sti…  -9 [Ite…\n 7 24         3 [Stimme eher nicht zu]         4 [Stimme ueb…  1 [Sti…   1 [Erw…\n 8 52         2 [Stimme eher zu]               3 [Stimme ehe…  1 [Sti…   1 [Erw…\n 9 19         2 [Stimme eher zu]               3 [Stimme ehe…  2 [Sti…   3 [Ina…\n10 48         2 [Stimme eher zu]               3 [Stimme ehe…  1 [Sti…   1 [Erw…\n11 49        -9 [Item in Welle nicht erhoben] -9 [Item in We… -9 [Ite…  -5 [Gen…\n12 47         2 [Stimme eher zu]               3 [Stimme ehe…  1 [Sti…  -9 [Ite…\n13 48         2 [Stimme eher zu]               3 [Stimme ehe…  1 [Sti…   1 [Erw…\n14 49        -9 [Item in Welle nicht erhoben] -9 [Item in We… -9 [Ite…   1 [Erw…\n15 39         4 [Stimme ueberhaupt nicht zu]   3 [Stimme ehe…  1 [Sti…  -9 [Ite…\n16 37         3 [Stimme eher nicht zu]         4 [Stimme ueb…  1 [Sti…  -9 [Ite…\n17 38         3 [Stimme eher nicht zu]         3 [Stimme ehe…  1 [Sti…   1 [Erw…\n\n\n\nNutzen Sie ifelse(), um Personen ab 50 Jahren mit “ü50” zu kennzeichnen - lassen Sie für Personen bis unter 50 Jahren “u50” eintragen.\nFühren Sie eine Dreiteilung durch: Personen bis unter 40 bekommen “u40”, Personen bis &lt;50 “u50” und Personen über 50 Jahren “ü50”. Wie würden Sie mit case_when() vorgehen?\nNutzen Sie ifelse(), um Werte &lt; 0 in den Variablen PEO0400a, PEO0400b, PEO0400c und statakt in pend_small2 mit NA zu überschreiben.\nSchreiben Sie zunächst eine ifelse()-Funktion, die für PEO0400a alle Werte &lt; 0 mit NA überschreibt und ansonsten den Ausgangswert F1450_01 einsetzt.\nWie würde die Funktion aussehen, wenn Sie sie mit across() auf PEO0400a, PEO0400b, PEO0400c und statakt gleichzeitig anwenden?\n\nZurück nach oben"
  },
  {
    "objectID": "06_data_wrangle2.html#anhang",
    "href": "06_data_wrangle2.html#anhang",
    "title": "6  Data Wrangling II",
    "section": "6.8 Anhang",
    "text": "6.8 Anhang\n\n6.8.1 Klassen bilden mit cut()\n\ndat3\n\n  studs profs gegr prom_recht                uni\n1 19173   322 1971       TRUE         Uni Bremen\n2  5333    67 1830       TRUE         Uni Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg\n4 14954   250 1971      FALSE          FH Aachen\n5 47269   553 1870       TRUE        RWTH Aachen\n6 23659   438 1457       TRUE       Uni Freiburg\n7  9415   150 1818       TRUE           Uni Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg\n\n\nEine häufig Aufgabe in der Datenaufbereitung die Klassierung eines metrisches Merkmals, wie zum Beispiel die Professorenzahlen. Wir möchten also profs in 150er-Schritten zusammenfassen. Um die Klassen zu bilden, nutzen wir cut() und geben neben der zu unterteilenden Variable mit breaks die Klassengrenzen an. Für die Grenzen können wir seq() verwenden. Darin geben wir zunächst die obere und untere Grenze an und dann die Schrittbreiten.\n\ncut(dat3$profs,breaks = c(50, 200, 350, 500, 650))\n\n[1] (200,350] (50,200]  (200,350] (200,350] (500,650] (350,500] (50,200] \n[8] (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\ncut(dat3$profs,breaks = seq(50,650,150))\n\n[1] (200,350] (50,200]  (200,350] (200,350] (500,650] (350,500] (50,200] \n[8] (500,650]\nLevels: (50,200] (200,350] (350,500] (500,650]\n\n\nDiese Werte legen wir in einer neuen Variable im Datensatz dat3 ab:\n\ndat3$prof_class &lt;- cut(dat3$profs,breaks = seq(50,650,150))\ndat3\n\n  studs profs gegr prom_recht                uni prof_class\n1 19173   322 1971       TRUE         Uni Bremen  (200,350]\n2  5333    67 1830       TRUE         Uni Vechta   (50,200]\n3 15643   210 1973       TRUE      Uni Oldenburg  (200,350]\n4 14954   250 1971      FALSE          FH Aachen  (200,350]\n5 47269   553 1870       TRUE        RWTH Aachen  (500,650]\n6 23659   438 1457       TRUE       Uni Freiburg  (350,500]\n7  9415   150 1818       TRUE           Uni Bonn   (50,200]\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  (500,650]\n\n\nFür diese neue Variable können wir mit count() eine Häufigkeitstabelle anfordern:\n\ndat3 %&gt;% count(prof_class)\n\n  prof_class n\n1   (50,200] 2\n2  (200,350] 3\n3  (350,500] 1\n4  (500,650] 2\n\n\n( bedeutet dabei ausgeschlossen, ] inklusive. Es gibt also 3 Unis im Datensatz, die über 200 bis inklusive 350 Professuren unterhalten.\nFür die weiteren Beispiele löschen wir die prof_class wieder:\n\ndat3$prof_class &lt;- NULL\n\nEinige hilfreiche Optionen für cut() im Anhang\n\nbsp &lt;- c(1990,1998,2001,2009)\nbsp\n\n[1] 1990 1998 2001 2009\n\ncut(bsp,breaks = c(1990,2000,2010)) \n\n[1] &lt;NA&gt;             (1.99e+03,2e+03] (2e+03,2.01e+03] (2e+03,2.01e+03]\nLevels: (1.99e+03,2e+03] (2e+03,2.01e+03]\n\n# Anzahl der stellen in den labels\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4) \n\n[1] &lt;NA&gt;        (1990,2000] (2000,2010] (2000,2010]\nLevels: (1990,2000] (2000,2010]\n\n# untere Grenze mit einbeziehen\ncut(bsp,breaks = c(1990,2000,2010),dig.lab = 4,include.lowest = T) \n\n[1] [1990,2000] [1990,2000] (2000,2010] (2000,2010]\nLevels: [1990,2000] (2000,2010]\n\n# durchnummerieren statt labels:\ncut(bsp,breaks = c(1990,2000,2010),labels = FALSE)\n\n[1] NA  1  2  2\n\n# eigene labels angeben:\ncut(bsp,breaks = c(1990,2000,2010),labels = c(\"90er\",\"00er\"))\n\n[1] &lt;NA&gt; 90er 00er 00er\nLevels: 90er 00er\n\n\n\n\n6.8.2 String-Funktionen für regex\n{stringr} stellt eine ganze Reihe an sehr hilfreichen String-Funktionen mit Regular Expressions zur Verfügung, einen Überblick bietet das Cheatsheet\n\ndat3 %&gt;% mutate(uni_fh = str_detect(uni,\"Uni\"))\n\n  studs profs gegr prom_recht                uni uni_fh\n1 19173   322 1971       TRUE         Uni Bremen   TRUE\n2  5333    67 1830       TRUE         Uni Vechta   TRUE\n3 15643   210 1973       TRUE      Uni Oldenburg   TRUE\n4 14954   250 1971      FALSE          FH Aachen  FALSE\n5 47269   553 1870       TRUE        RWTH Aachen  FALSE\n6 23659   438 1457       TRUE       Uni Freiburg   TRUE\n7  9415   150 1818       TRUE           Uni Bonn   TRUE\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  FALSE\n\ndat3 %&gt;% mutate(bula = case_when(str_detect(uni,\"Bremen\")~ \"HB\",\n                                 str_detect(uni,\"Oldenb|Vechta\")~ \"NDS\",\n                                 str_detect(uni,\"Bonn|Aachen\")~ \"NRW\",\n                                 str_detect(uni,\"Freiburg\")~ \"BW\"\n                                 ))\n\n  studs profs gegr prom_recht                uni bula\n1 19173   322 1971       TRUE         Uni Bremen   HB\n2  5333    67 1830       TRUE         Uni Vechta  NDS\n3 15643   210 1973       TRUE      Uni Oldenburg  NDS\n4 14954   250 1971      FALSE          FH Aachen  NRW\n5 47269   553 1870       TRUE        RWTH Aachen  NRW\n6 23659   438 1457       TRUE       Uni Freiburg   BW\n7  9415   150 1818       TRUE           Uni Bonn  NRW\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg  NRW\n\ndat3 %&gt;% mutate(ort = str_remove(uni,\"Uni |FH |RWTH \"))\n\n  studs profs gegr prom_recht                uni             ort\n1 19173   322 1971       TRUE         Uni Bremen          Bremen\n2  5333    67 1830       TRUE         Uni Vechta          Vechta\n3 15643   210 1973       TRUE      Uni Oldenburg       Oldenburg\n4 14954   250 1971      FALSE          FH Aachen          Aachen\n5 47269   553 1870       TRUE        RWTH Aachen          Aachen\n6 23659   438 1457       TRUE       Uni Freiburg        Freiburg\n7  9415   150 1818       TRUE           Uni Bonn            Bonn\n8 38079   636 1995      FALSE FH Bonn-Rhein-Sieg Bonn-Rhein-Sieg"
  },
  {
    "objectID": "06_data_wrangle2.html#footnotes",
    "href": "06_data_wrangle2.html#footnotes",
    "title": "6  Data Wrangling II",
    "section": "",
    "text": "“Tilde” - Tastaturbefehle: Alt Gr + * auf Windows. Auf macOS Alt + N und anschließend ein Leerzeichen, damit die Tilde erscheint.↩︎\nDo not repeat yourself, siehe Wickham et al: “You should consider writing a function whenever you’ve copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).”↩︎\n“Tilde” - Tastaturbefehle: Alt Gr + * auf Windows. Auf macOS Alt + N und anschließend ein Leerzeichen, damit die Tilde erscheint.↩︎"
  },
  {
    "objectID": "references.html#vs.",
    "href": "references.html#vs.",
    "title": "Links & Weiterführendes",
    "section": "%>% vs. |>",
    "text": "%&gt;% vs. |&gt;\nIn diesem Kurs haben wir die Pipe %&gt;% aus {tidyverse} (streng genommen aus dem Paket {magrittr}) kennen gelernt. Mit dem Update auf R 4.1 wurde in base R ebenfalls eine Pipe |&gt; eingeführt und Hilfeseiten usw. ersetzen langsam, aber sicher %&gt;% durch |&gt;. Für (nahezu) alle Anwendungen, die wir kennengelernt haben, verhalten sich beide Pipes identisch - und nachdem am BIBB R die R-Version 4.0.5 zur Verfügung steht, haben wir uns an ‘alte Variante’ gehalten. Letztlich spricht aber nichts dagegen, nach einem Update auf |&gt; umzusteigen - oder einfach bei %&gt;% zu bleiben.\n\nUnter anderem steht hier mehr zu den Unterschieden zwischen beiden Pipes. Außerdem bietet dieser Blogbeitrag einen guten Überblick zu den Fallstricken beim Umstieg von %&gt;% auf |&gt;."
  },
  {
    "objectID": "references.html#anonymfun",
    "href": "references.html#anonymfun",
    "title": "Links & Weiterführendes",
    "section": "Anonyme Funktionen: .x vs. /(x)",
    "text": "Anonyme Funktionen: .x vs. /(x)\nMit R 4.1.0 wurde in base R eine neue ‘anonymous function short hand’ eingeführt, welche die ‘formula syntax’ Schreibweise ~mean(.x) ablöst, die wir in Kapitel 6 kennen gelernt haben. In der neuen base R wäre das \\(x) mean(x) geschrieben.\nAus der {purrr} release notes für Version 1.0.0 (Dezember 2022): We believe that it’s better to use these new base tools because they work everywhere: the base pipe doesn’t require that you load magrittr and the new function shorthand works everywhere, not just in purrr functions. Additionally, being able to specify the argument name for the anonymous function can often lead to clearer code.\nDementsprechend würde die Anwendung in across() wie folgt aussehen:\n\nsat_small &lt;- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",n_max = 16) %&gt;% \n    select(F1450_04,F1450_05,F1450_06) %&gt;% \n    slice(12:16)\n\n# formula syntax\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"),~mean(.x)))\n# anonymous function short hand\nsat_small %&gt;% \n  mutate(across(matches(\"F1450\"),\\(x) mean(x) ))\n\nIn diesem Skript habe ich auf die bisherige ‘formula syntax’ Schreibweise zurück gegriffen, da aktuell noch die meisten Hilfeseite mit dieser Syntax arbeiten."
  },
  {
    "objectID": "references.html#quarto",
    "href": "references.html#quarto",
    "title": "Links & Weiterführendes",
    "section": "Quarto",
    "text": "Quarto\nQuarto ist eine Erweiterung/Weiterentwicklung von RMarkdown. Allerdings erfordert Quarto eine separate Installation, mehr Infos."
  },
  {
    "objectID": "references.html#einführungen-in-r",
    "href": "references.html#einführungen-in-r",
    "title": "Links & Weiterführendes",
    "section": "Einführungen in R",
    "text": "Einführungen in R\nEine Sammlung von Lehrskripten und Unterlagen aus verschiedenen Kontexten zum selbst weiter lernen:\nR for Data Science das Standardwerk für Datenanalysen mit {tidyverse} - sehr intuitive Einführung, Fokus auf Data Science\nProblemorientiere Einführungen in spezifische Anwendungen “do more with R”\nTen simple rules for teaching yourself R\nModerne Datenanalyse mit R: Deutschsprachige Einführung in {tidyverse}\nR for the Rest of Us bietet viele Tutorials und freie Kurse an, unter anderem auch viele YouTube Videos.\nStata 2 R richtet sich alle Anwender*innen von Stata, die auf R umsteigen möchten. Allerdings wird hier anstelle des {tidyverse} das Paket {data.table} für die Datenaufbereitung gezeigt. {data.table} ist auf der einen Seite sehr schnell, jedoch von der Syntaxlogik her etwas umständlicher als das {tidyverse}. Für alle, die mit sehr großen Datensätzen arbeiten lohnt es sich aber, {data.table} auszuprobieren."
  },
  {
    "objectID": "references.html#beispiel-für-vollständiges-paper-geschrieben-mit-rmarkdown",
    "href": "references.html#beispiel-für-vollständiges-paper-geschrieben-mit-rmarkdown",
    "title": "Links & Weiterführendes",
    "section": "Beispiel für vollständiges Paper geschrieben mit RMarkdown",
    "text": "Beispiel für vollständiges Paper geschrieben mit RMarkdown\nPaper zu einem Beispieldatensatz, komplett in R Markdown geschrieben\nHier findet ihr den Source-Code"
  },
  {
    "objectID": "references.html#cheatsheets",
    "href": "references.html#cheatsheets",
    "title": "Links & Weiterführendes",
    "section": "Cheatsheets",
    "text": "Cheatsheets\nEine Sammlung an Cheatsheets für eine breite Palette an Anwendungen gibt es hier.\n\nDatenvisualisierung mit {ggplot2}\nDatensätze bearbeiten mit {dplyr}\nDatensätze erstellen/reshapen mit {tidyr}"
  },
  {
    "objectID": "references.html#ggplot2",
    "href": "references.html#ggplot2",
    "title": "Links & Weiterführendes",
    "section": "{ggplot2}",
    "text": "{ggplot2}\nEine große Stärke von ggplot2 sind die zahlreichen Erweiterungen, welche beispielsweise ermöglichen\n\nmehrere Grafiken zu kombinieren mit {patchwork}\nKarten zu erstellen mit sf, weitere Link\nfortgeschrittene Textformatierungen zu verwenden mit {ggtext}\nGrafiken als Animation zu erstellen {gganimate} - eine Einführung oder hier\nLogos in in {ggplot2} einfügen mit {ggpath}\n\nEine Übersicht zu Erweiterungspakteten für {ggplot2} findet sich hier\nAuch The R Graph Gallery bietet eine hervorragende Übersicht zu Darstellungsmöglichkeiten mit Syntaxbeispielen für {ggplot2}.\n\nTutorial von Cédric Scherer\nSession zu intuitiveren Grafiken von Cara Thompson"
  },
  {
    "objectID": "references.html#purrr",
    "href": "references.html#purrr",
    "title": "Links & Weiterführendes",
    "section": "Fortgeschrittene Anwendung von lapply()/map() mit selbstgeschriebenen Funktionen",
    "text": "Fortgeschrittene Anwendung von lapply()/map() mit selbstgeschriebenen Funktionen\n\nUmfangreiche Einführung in loops mit map() und weiteren Funktionen aus {purrr} Hendrik van Broekhuizen\nModellserien: Blog von Tim Tiefenbach zu eleganten Möglichkeiten"
  },
  {
    "objectID": "references.html#regex",
    "href": "references.html#regex",
    "title": "Links & Weiterführendes",
    "section": "regex",
    "text": "regex\nFür die Arbeit mit Textvariablen sind regular expressions (regex) eine große Hilfe. Damit lassen sich beispielsweise Textabschnitte nach bestimmten Zeichenfolgen durchsuchen, diese ersetzen usw. Der Blog von Joshua C. Fjelstul ist ein guter Einstieg. Darüber hinaus gibt es ein hilfreiches Cheatsheet zu regex in R und das regex -Paket {stringr}"
  },
  {
    "objectID": "references.html#weiteres",
    "href": "references.html#weiteres",
    "title": "Links & Weiterführendes",
    "section": "Weiteres",
    "text": "Weiteres\n{easystats} bietet eine Sammlung von Paketen, welche statische Auswertungen erleichtern und vereinheitlichen. Gleichzeitig geht diese Vereinheitlichung aber mit einer beschränkteren Flexibilität einher - das ist Geschmackssache und kommt auf den Anwendungsfall an. Wir haben aus dem easystats-Universum unter anderem {performance} und {effectsize} kennengelernt.\nEreigniszeitmodelle / Event History Modellung / Survival Analysis"
  },
  {
    "objectID": "07_inferenz.html#t-tests",
    "href": "07_inferenz.html#t-tests",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.1 t-Tests",
    "text": "7.1 t-Tests\nEines der zentralen Werkzeuge der grundlegenden Inferenzstatistik ist der t-Test. In R steht uns dafür t.test() zur Verfügung. Mit der Option mu = können wir einen Wert für die \\(H_{A}\\) angeben:\n\nt.test(pend_kap7$azges1, mu = 35)  \n\n\n    One Sample t-test\n\ndata:  pend_kap7$azges1\nt = -10.612, df = 8368, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 35\n95 percent confidence interval:\n 33.57846 34.02173\nsample estimates:\nmean of x \n  33.8001 \n\n\nEin weiterer typischer Anwendungsfall für t-Tests ist der Gruppenvergleich, dazu geben wir in t.test() die zu testende Variable und und nach einer ~1 die Gruppenvariable an. Wir testen hier also auf Altersunterschiede zwischen Männern (zpsex=1, daher group1) und Frauen (zpsex=2, daher group2).\n\nt.test(pend_kap7$azges1~pend_kap7$zpsex)\n\n\n    Welch Two Sample t-test\n\ndata:  pend_kap7$azges1 by pend_kap7$zpsex\nt = 36.395, df = 8318.8, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n 7.206945 8.027473\nsample estimates:\nmean in group 1 mean in group 2 \n       37.74659        30.12938 \n\n\nEs hat sich als Konvention etabliert, von einem signifikanten Unterschied zu sprechen wenn die Irrtumswahrscheinlichkeit unter 5% liegt. Das bedeutet:\n\nAssuming that the null hypothesis is true and the study is repeated an infinite number times by drawing random samples from the same populations(s), less than 5% of these results will be more extreme than the current result.2\n\nDa hier der p-Wert sehr viel kleiner ist als 0.05 ist (p-value &lt; 2.2e-16)3, können wir von einen statistisch signifikanten Unterschied sprechen.\nStandardmäßig bekommen wir einen beidseitigen Test (\"two.sided\"), wir können aber auch einen links- (\"less\") oder rechtsseitigen (\"greater\") Test anfordern mehr dazu:\n\nt.test(pend_kap7$palter~pend_kap7$zpsex,alternative = \"two.sided\")\nt.test(pend_kap7$palter~pend_kap7$zpsex,alternative = \"less\")\nt.test(pend_kap7$palter~pend_kap7$zpsex,alternative = \"greater\")\n\n\n\n\n\n7.1.1 Übung"
  },
  {
    "objectID": "07_inferenz.html#pearson",
    "href": "07_inferenz.html#pearson",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.2 Korrelation",
    "text": "7.2 Korrelation\nDen Korrelationskoeffizienten können wir in R mit cor.test() berechnen:\n\ncor.test(pend_kap7$palter,pend_kap7$azges1,method = \"pearson\")\n\n\n    Pearson's product-moment correlation\n\ndata:  pend_kap7$palter and pend_kap7$azges1\nt = -3.8563, df = 8367, p-value = 0.000116\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.06348945 -0.02071526\nsample estimates:\n        cor \n-0.04212165 \n\n\nEs handelt sich mit -0.0421 also um einen geringen Zusammenhang. Der p-Wert gibt uns auch hier wieder Auskunft über die stat. Signifikanz: mit 0.00012 liegt der p-Wert deutlich unter 0,05.\nFür den Spearman-Rangkorrelationskoeffizienten können wir method = \"spearman\" nutzen:\n\ncor.test(pend_kap7$palter,pend_kap7$azges1,method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  pend_kap7$palter and pend_kap7$azges1\nS = 1.0003e+11, p-value = 0.02845\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n        rho \n-0.02394976"
  },
  {
    "objectID": "07_inferenz.html#gewichtung",
    "href": "07_inferenz.html#gewichtung",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.3 Gewichtung",
    "text": "7.3 Gewichtung\n\nBei der Datenanalyse ist man oft mit einer Stichprobe aus einer größeren Population konfrontiert und man möchte aus dieser Stichprobe Rückschlüsse auf die größere Population ziehen. Die meisten statistischen Verfahren für diese sog. „Inferenzstatistik“ beruhen dabei auf der Annahme, dass die Stichprobe eine einfache Zufallsstichprobe ist. Bei einer solchen Stichprobe gelangen alle Elemente der Grundgesamtheit mit der gleichen Wahrscheinlichkeit in die Stichprobe. In der Praxis sind solche Stichproben aber die große Ausnahme. Häufig haben bestimmte Gruppen von Personen höhere Auswahlwahrscheinlichkeiten als andere. Kohler/Kreuter, S.81\n\nGewichte sind ein häufig verwendetes Mittel, ungleich verteilten Auswahlwahrscheinlichkeiten zu begegnen. Die Gewichte für den Personendatz des PASS CampusFiles sind im Datensatz pweights_cf_W13.dta zu finden. Für eine Gewichtung müssen wir diesen erst an die Personendatei ranspielen - mit einem left_join()\n\nwgt_df &lt;- haven::read_dta(\"./orig/pweights_cf_W13.dta\")\nhead(wgt_df)\n\n# A tibble: 6 × 7\n         pnr welle                   sample             wqp ppbleib   psu strpsu\n       &lt;dbl&gt; &lt;dbl+lbl&gt;               &lt;dbl+lbl&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 1000001901 1 [Welle 1 (2006/2007)] 2 [Microm-Stic… 20075.   NA       80     64\n2 1000001901 3 [Welle 3 (2008/2009)] 2 [Microm-Stic… 32959.   NA       80     64\n3 1000001902 1 [Welle 1 (2006/2007)] 2 [Microm-Stic… 23077.   NA       80     64\n4 1000002001 1 [Welle 1 (2006/2007)] 1 [BA-Stichpro…  1639.    1.87    80     64\n5 1000002001 2 [Welle 2 (2007/2008)] 1 [BA-Stichpro…  1668.    1.12    80     64\n6 1000002001 3 [Welle 3 (2008/2009)] 1 [BA-Stichpro…  1748.    1.36    80     64\n\npend_kap7 &lt;- pend_kap7 %&gt;% left_join(wgt_df, by = join_by(pnr,welle))\n\nDie einfachste Variante für eine Gewichtung ist die Option wt= in count():\n\npend_kap7 %&gt;% \n  count(zpsex,statakt)\n\n# A tibble: 8 × 3\n  zpsex statakt     n\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;\n1     1       1  4685\n2     1       2  3240\n3     1       3  2047\n4     1      NA  3555\n5     2       1  4785\n6     2       2  2899\n7     2       3  3434\n8     2      NA  3779\n\npend_kap7 %&gt;% \n  count(zpsex,statakt,wt = wqp)\n\n# A tibble: 8 × 3\n  zpsex statakt          n\n  &lt;dbl&gt;   &lt;dbl&gt;      &lt;dbl&gt;\n1     1       1 206326062.\n2     1       2  26678834.\n3     1       3  64867832.\n4     1      NA 143378863.\n5     2       1 177223245.\n6     2       2  21205451.\n7     2       3 109600208.\n8     2      NA 163820124.\n\n\nFür umfangreichere Anwendungen stehen in R stehen die Pakete {survey} und das darauf aufbauende {srvyr} zur Verfügung.\n\ninstall.packages(\"survey\")\n\nZunächst verwenden wir svydesign(), um die Gewichtung festzulegen. Im weiteren stellt {survey} dann zahlreiche Funktionen zur Verfügung, die eine gewichtete Variante der basis-Befehle sind - bspw. svymean() und svytable():\n\nlibrary(survey)\npend_kap7_wgt &lt;- svydesign(id      = ~pnr,\n                           weights = ~wqp,\n                           data    = pend_kap7)\n\nsvymean(~palter, pend_kap7_wgt, na.rm = TRUE)\n\n         mean     SE\npalter 51.171 0.5755\n\nmean(pend_kap7$palter, na.rm = TRUE)\n\n[1] 46.49612\n\n\nFür Tabellen gibt es in {survey} auch eine Funktion:\n\nsvytable(~zpsex+statakt,pend_kap7_wgt)\n\n     statakt\nzpsex         1         2         3\n    1 206326062  26678834  64867832\n    2 177223245  21205451 109600208\n\ntable(pend_kap7$zpsex,pend_kap7$statakt)\n\n   \n       1    2    3\n  1 4685 3240 2047\n  2 4785 2899 3434\n\n\nFür Regressionsmodelle gibt es bspw. survey::svyglm()\n\n\n7.3.1 Übung"
  },
  {
    "objectID": "07_inferenz.html#übungen",
    "href": "07_inferenz.html#übungen",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "7.4 Übungen",
    "text": "7.4 Übungen\n\n7.4.1 Übung 1\n\npend_ue7 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",\n                            col_select = c(\"pnr\",\"welle\",\"zpsex\",\"palter\",\"netges\")) %&gt;% \n  mutate(across(everything(), ~ifelse(.x &lt; 4,NA,.x))) # missings  mit NA überschreiben\n\nTesten Sie die Hypothese, dass ein signifikanter Unterschied im Alter (palter) zwischen Männern und Frauen besteht (zpsex). Die Missings beider Variablen wurden im mutate() der Befehle oben schon mit NA überschrieben - Sie können direkt los legen.\nSehen Sie sich die Informationen an, welche t.test() erstellt: legen Sie das Ergebnis des Tests als Objekt ab (test1 &lt;- ...) und sehen Sie sich die Informationen unter test1$ an (drücken Sie die ↹ Taste).\n\n\n7.4.2 Übung 2\n\nwgt_df &lt;- haven::read_dta(\"./orig/pweights_cf_W13.dta\")\nhead(wgt_df)\n\n# A tibble: 6 × 7\n         pnr welle                   sample             wqp ppbleib   psu strpsu\n       &lt;dbl&gt; &lt;dbl+lbl&gt;               &lt;dbl+lbl&gt;        &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 1000001901 1 [Welle 1 (2006/2007)] 2 [Microm-Stic… 20075.   NA       80     64\n2 1000001901 3 [Welle 3 (2008/2009)] 2 [Microm-Stic… 32959.   NA       80     64\n3 1000001902 1 [Welle 1 (2006/2007)] 2 [Microm-Stic… 23077.   NA       80     64\n4 1000002001 1 [Welle 1 (2006/2007)] 1 [BA-Stichpro…  1639.    1.87    80     64\n5 1000002001 2 [Welle 2 (2007/2008)] 1 [BA-Stichpro…  1668.    1.12    80     64\n6 1000002001 3 [Welle 3 (2008/2009)] 1 [BA-Stichpro…  1748.    1.36    80     64\n\npend_ue7 &lt;- pend_ue7 %&gt;% left_join(wgt_df, by = join_by(pnr,welle))\n\n\nLegen Sie die Gewichtung auf Basis von wqp an.\nBerechnen Sie den Mittelwert für den Nettoverdienst netges mit und ohne Gewichtung."
  },
  {
    "objectID": "07_inferenz.html#footnotes",
    "href": "07_inferenz.html#footnotes",
    "title": "7  Inferenzstatistik & Zusammenhangsmaße",
    "section": "",
    "text": "Tastaturbefehle: Alt Gr + * auf Windows. Auf macOS Alt + N und anschließend ein Leerzeichen, damit die Tilde erscheint.↩︎\nFailing Grade: 89% of Introduction-to-Psychology Textbooks That Define or Explain Statistical Significance Do So Incorrectly. Advances in Methods and Practices in Psychological Science, 2515245919858072.↩︎\n2.2e-16 steht für 2.2 aber mit 16 Nullen vorweg. Das ist Rs Art zu sagen, dass der Wert sehr sehr klein ist.↩︎"
  },
  {
    "objectID": "09_reg.html#lm1",
    "href": "09_reg.html#lm1",
    "title": "8  Regressionsmodelle",
    "section": "8.1 Regressionsmodelle mit lm()",
    "text": "8.1 Regressionsmodelle mit lm()\nRegressionsmodelle in R lassen sich mit lm() erstellen. Hier geben wir das Merkmal an, dass auf der y-Achse liegt (die abhängige Variable) und nach einer ~ das Merkmal für die x-Achse (unabhängige Variable). Die Interpretation des Ergebnisses wird uns die kommenden Wochen beschäftigen.\n\nlm(var2~ var1, data = dat1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nDer Wert unter var1 gibt an, um wieviel sich die Gerade pro “Schritt nach rechts” nach oben/unten verändert. Die Gerade steigt also pro Einheit von var1 um 1.8389662. Die Ergebnisse können wir unter m1 ablegen:\n\nm1 &lt;- lm(var2~ var1, data = dat1)  \n\nMit summary() bekommen wir dann eine Regressionstabelle:\n\nsummary(m1)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-8.372 -3.613  0.162  2.234 10.789 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -2.3400     4.3454  -0.538   0.6096  \nvar1          1.8390     0.7727   2.380   0.0548 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.127 on 6 degrees of freedom\nMultiple R-squared:  0.4856,    Adjusted R-squared:  0.3999 \nF-statistic: 5.664 on 1 and 6 DF,  p-value: 0.05477\n\n\nm1 enthält alle Informationen zum Modell, besonders hilfreich ist $coefficients:\n\nm1$coefficients\n\n(Intercept)        var1 \n  -2.339960    1.838966 \n\nsummary(m1)$coefficients\n\n             Estimate Std. Error    t value   Pr(&gt;|t|)\n(Intercept) -2.339960  4.3453801 -0.5384938 0.60961706\nvar1         1.838966  0.7727028  2.3799139 0.05477457\n\n\nWir können uns die einzelnen Werte mit View(m1) ansehen:\n\n\n\n\n\n\nBspw. finden sich unter fitted.values die vorhergesagten Werte für jeden Fall."
  },
  {
    "objectID": "09_reg.html#regressionsgerade-und-daten-visualisieren",
    "href": "09_reg.html#regressionsgerade-und-daten-visualisieren",
    "title": "8  Regressionsmodelle",
    "section": "8.2 Regressionsgerade und Daten visualisieren",
    "text": "8.2 Regressionsgerade und Daten visualisieren\nMit geom_smooth(method = \"lm\") können wir Regressionsgeraden auch in {ggplot2} darstellen:\nUnser Modell mit var1 und var2 können wir so darstellen:\n\nlibrary(ggplot2)\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  \n\n\n\n\n\n\n\n\nHier scheinen wir einen Ausreißer zu haben. In unserem übersichtlichen Datensatz ist der schnell gefunden. In größeren Datensätzen hilft uns geom_text():\n\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_point(size = 2) + \n  geom_smooth(method = \"lm\")  +\n  geom_text(data = . %&gt;% filter(var2 &gt; 20), aes(y = var2+3, label = id), color = \"sienna1\")\n\n\n\n\n\n\n\n\nWir können nämlich einzelne geom_ auch nur für ein Subset angeben - dazu vergeben wir data = neu (übernehmen also nicht die Auswahl aus dem Haupt-Befehl ggplot()) und setzen darin einen filter(). Außerdem verschieben wir mit var2+3 das Label etwas über den Punkt.\n\n8.2.1 Übung"
  },
  {
    "objectID": "09_reg.html#modelle-nur-für-manche-fälle-berechnen",
    "href": "09_reg.html#modelle-nur-für-manche-fälle-berechnen",
    "title": "8  Regressionsmodelle",
    "section": "8.3 Modelle nur für manche Fälle berechnen",
    "text": "8.3 Modelle nur für manche Fälle berechnen\nWenn wir jetzt das Modell nochmal berechnen wollen, haben wir zwei Möglichkeiten:\n\n8.3.1 Neuen data.frame erstellen\nWir können in R mehrere data.frame-Objekte im Speicher halten. Also können wir leicht einen neuen data.frame erstellen, der nur die Beobachtungen mit var2 &lt; 20 enthält und diesen dann für unseren lm()-Befehl verwenden:\n\ndat1_u20 &lt;- dat1 %&gt;% filter(var2&lt;20)\nm2a &lt;- lm(var2~ var1, data = dat1_u20)\nsummary(m2a)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1_u20)\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456\n\n\n\n\n8.3.2 Direkt in lm() filtern\nWir können filter()-Befehl auch direkt in das data=-Argument von lm() bauen:\n\nm2b &lt;- lm(var2~ var1, data = dat1 %&gt;% filter(var2&lt;20))\nsummary(m2b)\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1 %&gt;% filter(var2 &lt; 20))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.4737  0.1941 -1.4737  4.5230  1.1875 -2.4803 -1.4770 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   1.1382     1.9217   0.592    0.579\nvar1          0.6678     0.3877   1.722    0.146\n\nResidual standard error: 2.555 on 5 degrees of freedom\nMultiple R-squared:  0.3724,    Adjusted R-squared:  0.2469 \nF-statistic: 2.967 on 1 and 5 DF,  p-value: 0.1456"
  },
  {
    "objectID": "09_reg.html#regressionstabellen",
    "href": "09_reg.html#regressionstabellen",
    "title": "8  Regressionsmodelle",
    "section": "8.4 Regressionstabellen",
    "text": "8.4 Regressionstabellen\nWenn wir diese verschiedenen Modelle jetzt vergleichen möchten, bietet sich eine Tabelle an.\nEs gibt zahlreiche Alternativen zur Erstellung von Regressionstabellen, mein persönlicher Favorit ist modelsummary() aus dem gleichnamigen Paket {modelsummary}. Es kommt mit (nahezu) allen Modellarten zurecht und bietet darüber hinaus eine breite Palette an (u.a. auch Word-Output - dazu später mehr) und auch Koeffizientenplots (auch dazu kommen wir noch). Außerdem ist die Dokumentation hervorragend.\n\ninstall.packages(\"modelsummary\")\n\n\nlibrary(modelsummary)\nmodelsummary(list(m1,m2a,m2b))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n-2.340\n1.138\n1.138\n\n\n\n(4.345)\n(1.922)\n(1.922)\n\n\nvar1\n1.839\n0.668\n0.668\n\n\n\n(0.773)\n(0.388)\n(0.388)\n\n\nNum.Obs.\n8\n7\n7\n\n\nR2\n0.486\n0.372\n0.372\n\n\nR2 Adj.\n0.400\n0.247\n0.247\n\n\nAIC\n55.4\n36.6\n36.6\n\n\nBIC\n55.6\n36.5\n36.5\n\n\nLog.Lik.\n-24.702\n-15.321\n-15.321\n\n\nF\n5.664\n2.967\n2.967\n\n\nRMSE\n5.31\n2.16\n2.16\n\n\n\n\n\n\n\nWir werden uns noch ein bisschen ausführlicher mit den Anpassungsmöglichkeiten für {modelsummary} befassen, hier nur schon mal zwei zentrale Optionen:\n\nmit stars = T können wir uns die Signifikanz mit den gebräuchlichen Sternchen-Codes anzeigen lassen (*: p &lt; .05 usw.)\nmit gof_omit = \"IC|RM|Log\" können wir die Goodness of Fit Statistiken ausblenden die IC, RM oder Log im Namen haben (also AIC, BIC, RMSE und die LogLikelihood)\nmit \"Name\" = in list() können wir Namen angeben:\n\n\nmodelsummary(list(\"m1\"=m1,\"m2a\"=m2a,\"m2b\"=m2b),stars = T,gof_omit = \"IC|RM|Log\")\n\n\n\n\n\nm1\n m2a\n m2b\n\n\n\n\n(Intercept)\n-2.340\n1.138\n1.138\n\n\n\n(4.345)\n(1.922)\n(1.922)\n\n\nvar1\n1.839+\n0.668\n0.668\n\n\n\n(0.773)\n(0.388)\n(0.388)\n\n\nNum.Obs.\n8\n7\n7\n\n\nR2\n0.486\n0.372\n0.372\n\n\nR2 Adj.\n0.400\n0.247\n0.247\n\n\nF\n5.664\n2.967\n2.967\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\n8.4.1 Übung"
  },
  {
    "objectID": "09_reg.html#kategoriale-unabhängige-variablen",
    "href": "09_reg.html#kategoriale-unabhängige-variablen",
    "title": "8  Regressionsmodelle",
    "section": "8.5 Kategoriale unabhängige Variablen",
    "text": "8.5 Kategoriale unabhängige Variablen\nNatürlich können wir auch kategoriale unabhängige Variablen in unser Modell mit aufnehmen. Dazu müssen wir aber entsprechende Variable als factor definieren - und R so mitteilen, dass die Zahlenwerte nicht numerisch zu interpretieren sind. Wenn wir educ aus unserem kleinen Beispiel betrachten - dann steht 1 für einen grundlegenden Bildungsabschluss, 2 für einen mittleren und 3 für einen hohen Bildungsabschluss.\n\ndat1\n\n  id var1 var2 educ gend  x\n1  1    2    2    3    2  2\n2  2    1    2    1    1  1\n3  3    2    1    2    1  2\n4  4    5    9    2    2  4\n5  5    7    7    1    1  1\n6  6    8    4    3    2 NA\n7  7    9   25    2    1 NA\n8  8    5    3   -1    2 NA\n\nm3 &lt;- lm(var2~factor(educ), dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ factor(educ), data = dat1)\n\nResiduals:\n         1          2          3          4          5          6          7 \n-1.000e+00 -2.500e+00 -1.067e+01 -2.667e+00  2.500e+00  1.000e+00  1.333e+01 \n         8 \n-2.387e-15 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    3.000e+00  8.848e+00   0.339    0.752\nfactor(educ)1  1.500e+00  1.084e+01   0.138    0.897\nfactor(educ)2  8.667e+00  1.022e+01   0.848    0.444\nfactor(educ)3 -1.632e-15  1.084e+01   0.000    1.000\n\nResidual standard error: 8.848 on 4 degrees of freedom\nMultiple R-squared:  0.2848,    Adjusted R-squared:  -0.2516 \nF-statistic: 0.531 on 3 and 4 DF,  p-value: 0.685\n\n\nNoch schöner ist das aber natürlich, wenn wir educ vorher labeln:\n\ndat1$ed_fct &lt;- factor(dat1$educ, levels = 1:3,\n                        labels = c(\"basic\",\"medium\",\"high\"))\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   &lt;NA&gt;\n\n\nDann verwenden den factor im Regressionsbefehl:\n\nm3 &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)     4.500      6.257   0.719    0.512\ned_fctmedium    7.167      8.077   0.887    0.425\ned_fcthigh     -1.500      8.848  -0.170    0.874\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nIm Vergleich zu educ = basic ist der vorhergesagte Wert für var2 bei educ = medium um 7.17 höher.\nIm Vergleich zu educ = basic ist der vorhergesagte Wert für var2 bei educ = high um -1.5 höher.\n\nWir können die Referenzkategorie auch ändern:\n\ndat1$ed_fct &lt;- relevel(dat1$ed_fct,ref = \"medium\")\nm3b &lt;- lm(var2 ~ ed_fct, dat1)\nsummary(m3b)\n\n\nCall:\nlm(formula = var2 ~ ed_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7 \n -1.000  -2.500 -10.667  -2.667   2.500   1.000  13.333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   11.667      5.109   2.284   0.0844 .\ned_fctbasic   -7.167      8.077  -0.887   0.4251  \ned_fcthigh    -8.667      8.077  -1.073   0.3437  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.848 on 4 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.2594,    Adjusted R-squared:  -0.1109 \nF-statistic: 0.7005 on 2 and 4 DF,  p-value: 0.5485\n\n\n\nIm Vergleich zu educ = medium ist der vorhergesagte Wert für var2 bei educ = basic um 7.17 niedriger.\nIm Vergleich zu educ = medium ist der vorhergesagte Wert für var2 bei educ = high um 8.67 niedriger.\n\n\n8.5.1 Übung"
  },
  {
    "objectID": "09_reg.html#mehre-unabhängige-variablen",
    "href": "09_reg.html#mehre-unabhängige-variablen",
    "title": "8  Regressionsmodelle",
    "section": "8.6 Mehre unabhängige Variablen",
    "text": "8.6 Mehre unabhängige Variablen\nUm mehrere unabhängige Variablen in unser Regressionsmodellen aufzunehmen, geben wir sie mit + an:\n\nm4 &lt;- lm(var2 ~ ed_fct  + var1, dat1)\nsummary(m4)\n\n\nCall:\nlm(formula = var2 ~ ed_fct + var1, data = dat1)\n\nResiduals:\n     1      2      3      4      5      6      7 \n 4.258  2.758 -4.824 -2.082 -2.758 -4.258  6.907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)   2.3187     5.8227   0.398    0.717\ned_fctbasic  -4.8297     6.0381  -0.800    0.482\ned_fcthigh   -8.0824     5.9411  -1.360    0.267\nvar1          1.7527     0.8347   2.100    0.127\n\nResidual standard error: 6.501 on 3 degrees of freedom\n  (1 Beobachtung als fehlend gelöscht)\nMultiple R-squared:  0.7002,    Adjusted R-squared:  0.4003 \nF-statistic: 2.335 on 3 and 3 DF,  p-value: 0.2521"
  },
  {
    "objectID": "09_reg.html#modelplot",
    "href": "09_reg.html#modelplot",
    "title": "8  Regressionsmodelle",
    "section": "8.7 Koeffizientenplots",
    "text": "8.7 Koeffizientenplots\nNeben Regressionstabellen stellt {modelsummary} auch die Funktion modelplot() zur Verfügung, mit denen einfach ein Koeffizientenplot aus einem oder mehreren Modellen erstellt werden kann:\n\nmodelplot(m4)\n\n\n\n\nFür einen Modellvergleich geben wir einfach die Modelle in einer named list an, außerdem können wir mit den üblichen {ggplot2}-Befehlen die Grafik weiter anpassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4))\n\n\n\n\nMit coef_map können wir Labels für die Koeffizienten vergeben ((Intercept) bekommt keinen Namen und wird daher weggelassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4),\n          coef_map = c(\"var1\" = \"Name für var1\",\n                       \"ed_fcthigh\"  = \"Höhere Bildung\",\n                       \"ed_fctbasic\" = \"Grundlegende Bildung\"\n                          ))\n\n\n\n\nAußerdem können wir mit den üblichen {ggplot2}-Befehlen die Grafik weiter anpassen:\n\nmodelplot(list(\"Modell 1\"=m1,\n               \"Modell 4\"=m4),\n          coef_map = c(\"var1\" = \"Name für var1\",\n                       \"ed_fcthigh\"  = \"Höhere Bildung\",\n                       \"ed_fctbasic\" = \"Grundlegende\\nBildung\")) + # \\n fügt einen Zeilenumbruch ein\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"grey40\") +  # 0-Linie einfügen\n  scale_color_manual(values = c(\"orange\",\"navy\")) +\n  theme_minimal(base_size = 15,base_family = \"mono\") \n\n\n\n\nMit {broom} können wir auch einen data.frame aus den Regressionsergebnissen erstellen und den ggplot ganz selbst erstellen - siehe Anhang.\n\n8.7.1 Übung"
  },
  {
    "objectID": "09_reg.html#übungen",
    "href": "09_reg.html#übungen",
    "title": "8  Regressionsmodelle",
    "section": "8.8 Übungen",
    "text": "8.8 Übungen\nVerwenden Sie folgenden Subdatensatz des PASS CampusFiles:\n\npend_ue08 &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% \n  filter(welle == 13, netges &gt; 0, azges1 &gt; 0,schul2 &gt; 1, palter &gt; 0)\n\n\n8.8.1 Übung 1: Regression\n\nErstellen Sie ein Objekt mod1 mit einem linearen Regressionsmodell (lm) mit netges (Monatsnetto in EUR) als abhängiger und azges1 (Arbeitszeit in Stunden) als unabhängiger Variable! (siehe hier)\nBetrachten Sie Ergebnisse mod1 - was können Sie zum Zusammenhang zwischen netges und azges1 erkennen?\nVisualisieren Sie Ihr Regressionsmodell mit {ggplot2}.\nSehen Sie Ausreißer im Scatterplot? Markieren Sie diese mit Hilfe der Variable pnr und geom_text().\n\n\n\n8.8.2 Übung 2: Nur manche Beobachtungen\n\nErstellen Sie ein lm()-Modell mod2, welches nur auf den Beobachtungen mit einem Monatseinkommen unter 20.000 EUR beruht.\nErstellen Sie eine Regressionstabelle, welche diese neue Modell mod2 neben das Modell mod1 aus Übung 1 stellt.\n\n\n\n8.8.3 Übung 3: kat. UVs\n\nErstellen Sie ein Regressionsmodell mit de Einkommen der Befragen (netges) als abhängiger und dem Schulabschluss der Befragten m1202 als unabhängiger Variable:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvalue\nlabel\n\n\n\n\n\n-10 bis -1 und 1\n\nt.n.z./k.A.\n\n\n\n2\n\nSchule beendet ohne Abschluss\n\n\n\n3\n\nSonder-/Foerderschulabschluss\n\n\n\n4\n\nVolks-/Hauptschulabschluss bzw: POS 8./9. Klasse\n\n\n\n5\n\nMittlere Reife/Realschulabschluss bzw. POS 10. Klasse\n\n\n\n6\n\nFachhochschulreife\n\n\n\n7\n\nAllgem. oder fachgeb. Hochschulreife (Abitur)/EOS 12. Klasse\n\n\n\n\n\n\n\n\nAchten Sie darauf, dass schul2 als factor definiert ist. Vergeben Sie für die Levels 2-7 die Labels “ohne”, “Förderschule”,“Hauptschule”,“Mittlere Reife”,“FOS/BOS”,“Abi” und legen sie den factor als Variable schul2_fct in Ihrem data.frame ab - siehe Code-Hilfe unten:\n\n\n\nCode\npend_ue08$schul2_fct &lt;-  \n  factor(pend_ue08$schul2,levels = 2:7, labels = c(\"ohne\",\"Förderschule\",\"Hauptschule\",\"Mittlere Reife\",\"FOS/BOS\",\"Abi\"))\n\n\n\nErstellen Sie das Regressionsmodell mit dieser neuen factor-Variable für schul2_fct als unabhängiger Variablen.\nÄndern Sie die Referenzkategorie auf die Ausprägung Mittlere Reife (schul2 = 5) und schätzen Sie das Modell erneut.\n\n\n\n8.8.4 Übung 4: mehrere UVs & Koeffizientenplot\n\nPassen Sie das lm()-Modell mod1 (mit allen Fällen aus pend_u08) so an, dass neben der Arbeitszeit zusätzlich den Schulabschluss (schul2) als unabhängige Variable mit aufgenommen werden.\nErstellen Sie auch eine grafische Gegenüberstellung der beiden Modelle mit und ohne den Schulabschluss"
  },
  {
    "objectID": "09_reg.html#anhang",
    "href": "09_reg.html#anhang",
    "title": "8  Regressionsmodelle",
    "section": "8.9 Anhang",
    "text": "8.9 Anhang\n\ndat1 &lt;- dat1 %&gt;% select(-matches(\"compl\"))\n\n\n8.9.1 Vorhergesagte Werte\nDie vorhergesagten Werte von lm() finden sich unter $fitted.values:\n\nm1$fitted.values\n\n        1         2         3         4         5         6         7         8 \n 1.337972 -0.500994  1.337972  6.854871 10.532803 12.371769 14.210736  6.854871 \n\n\nDiese vorhergesagten Werte entsprechen einfach der Summe aus dem Wert unter Intercept und dem Wert unter var1 multipliziert mit dem jeweiligen Wert für var1.\n\nm1\n\n\nCall:\nlm(formula = var2 ~ var1, data = dat1)\n\nCoefficients:\n(Intercept)         var1  \n     -2.340        1.839  \n\n\nFür die erste Zeile aus dat1 ergibt sich also m1 folgender vorhergesagter Wert: 2.1351+0.5811*1=2.7162\nDie Werte unter fitted.values folgen der Reihenfolge im Datensatz, sodass wir sie einfach als neue Spalte in dat1 ablegen können:\n\ndat1$lm_vorhersagen &lt;- m1$fitted.values\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_vorhersagen\n1  1    2    2    3    2  2   high       1.337972\n2  2    1    2    1    1  1  basic      -0.500994\n3  3    2    1    2    1  2 medium       1.337972\n4  4    5    9    2    2  4 medium       6.854871\n5  5    7    7    1    1  1  basic      10.532803\n6  6    8    4    3    2 NA   high      12.371769\n7  7    9   25    2    1 NA medium      14.210736\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871\n\n\nDie Grafik zeigt wie Vorhersagen auf Basis von m1 aussehen: Sie entsprechen den Werten auf der blauen Geraden (der sog. Regressionsgeraden) an den jeweiligen Stellen für var1.\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) +\n  geom_point(size = 3) +      \n  geom_smooth(method = \"lm\", color = \"darkblue\" , se = FALSE,size =.65) +\n  geom_point(aes(x = var1, y = lm_vorhersagen), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8),y=c(0,8)) \n\n\n\n\n\n\n\n\n\n\n\n8.9.2 Residuen\nDie hellblauen Punkte (also die Vorhersagen von m1) liegen in der Nähe der tatsächlichen Punkte. Trotzdem sind auch die hellblauen Punkte nicht deckungsgleich mit den tatsächlichen Werten. Diese Abweichungen zwischen den vorhergesagten und tatsächlichen Werten werden als Residuen bezeichnet: \\[Residuum = beobachteter\\, Wert \\; - \\; vorhergesagter\\,Wert\\] \\[\\varepsilon_{\\text{i}} = \\text{y}_{i} - \\hat{y}_{i}\\] Wir können diese per Hand berechnen als Differenz zwischen dem tatsächlichen und dem vorhergesagten Wert oder einfach unter m1$residuals aufrufen:\n\nm1$residuals\n\n         1          2          3          4          5          6          7 \n 0.6620278  2.5009940 -0.3379722  2.1451292 -3.5328032 -8.3717694 10.7892644 \n         8 \n-3.8548708 \n\n\nAuch die Residuen für lm können wir in dat1 ablegen:\n\ndat1$lm_residuen &lt;- m1$residuals\ndat1\n\n  id var1 var2 educ gend  x ed_fct lm_vorhersagen lm_residuen\n1  1    2    2    3    2  2   high       1.337972   0.6620278\n2  2    1    2    1    1  1  basic      -0.500994   2.5009940\n3  3    2    1    2    1  2 medium       1.337972  -0.3379722\n4  4    5    9    2    2  4 medium       6.854871   2.1451292\n5  5    7    7    1    1  1  basic      10.532803  -3.5328032\n6  6    8    4    3    2 NA   high      12.371769  -8.3717694\n7  7    9   25    2    1 NA medium      14.210736  10.7892644\n8  8    5    3   -1    2 NA   &lt;NA&gt;       6.854871  -3.8548708\n\n\nHier sind die Residuen für lm hellblau eingezeichnet:\n\n\nCode\nggplot(dat1, aes(x = var1, y = var2)) + \n  geom_smooth(method = \"lm\", color = \"darkblue\" , se = FALSE,size =.65) +\n  geom_segment(aes(x = var1, xend = var1, y = var2, yend = lm_vorhersagen), color = \"dodgerblue3\", size = .65, linetype = 1) +\n  geom_point(size = 3) +\n  geom_point(aes(x = var1, y = lm_vorhersagen), color = \"dodgerblue3\", size = 3) +\n  expand_limits(x = c(0,8),y=c(0,8)) \n\n\n\n\n\n\n\n\n\n\n\n8.9.3 Annahmen checken\nmodel dashboard\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\n\nmodel_test &lt;- check_model(m4)\nplot(model_test)\n\n\n\n\n\n\n8.9.4 Test auf Normalverteilung der Residuen\nGrafische Überprüfung: Q-Q-Plot\n\nlibrary(ggfortify)\nautoplot(m1,which = 2)\n\n\n\n\n\n\n\n\n\n\nÜberprüfen lässt sich die NV-Annahme mit dem Shapiro-Wilk-Test & shapiro.test(). Dieser testet die \\(H_0\\): “Die Residuen sind normalverteilt” gegen die \\(H_A\\): “Die Residuen weichen signifikant von der Normalverteilung ab”\n\nshapiro.test(m1$residuals) \n\n\n    Shapiro-Wilk normality test\n\ndata:  m1$residuals\nW = 0.95346, p-value = 0.746\n\n\n\n\n8.9.5 Test auf Homoskedastizität\nHomoskedastizität ist gegeben, wenn die vorhergesagten Werte über den kompletten Wertebereich (ungefähr) gleich weit von den tatsächlichen Werten (m1\\$fitted.values) entfernt sind. Auch hier gibt es eine graphische Überprüfungsmethode sowie einen Test. Zur graphischen Überprüfung werden die vorhergesagten Werten und die Residuen als Scatterplot dargestellt. Auch hier hilft uns autoplot():\n\nautoplot(m1, which = 1)\n\n\n\n\n\n\n\n\n\n\nDer dazugehörige Test ist der Breusch-Pagan-Test. Dieser testet die \\(H_0\\) “Homoskedastizität” gegen die \\(H_A\\) “Heteroskedastizität”, der p-Wert gibt also an mit welcher Irrtumswahrscheinlichkeit wir die Homoskedastizitäts-Annahme verwerfen müssen. In R können wir dafür bptest aus dem Paket lmtest verwenden:\n\ninstall.packages(\"lmtest\")\n\n\nlibrary(lmtest)\nbptest(m3)\n\n\n    studentized Breusch-Pagan test\n\ndata:  m3\nBP = 3.6069, df = 2, p-value = 0.1647\n\n\n\n\n8.9.6 Test auf Multikollinearität\n\ninstall.packages(\"car\")\n\n\n# library(car)\npendx &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\",n_max = 300)  %&gt;% filter(netges &gt;0, palter &gt;0 )\nmox &lt;- lm(netges ~ palter + azges1,data=pendx)\ncar::vif(mox)\n\n  palter   azges1 \n1.000133 1.000133 \n\n\nInterpretation:\n\n\nEin verbreiteter Schwellenwert des VIF beträgt 10,00. Werte des VIF über 10 deuten auf ein schwerwiegendes Multikollinearitätsproblem, oftmals werden Gegenmaßnahmen schon ab einem strikteren Grenzwert von ca. 5,00 empfohlen. Im konkreten Beispiel ist für alle UVs also nach beiden Grenzwerten alles in Ordnung.\nBeim Vorliegen von Mulitkollinearität gibt es mehrere Möglichkeiten, das zu beheben: Wir können eine oder mehrere unabh. Variablen aus dem Modell ausschließen. Das ist letztlich eine inhaltliche Frage und kann nicht mit einem Standardrezept gelöst werden. Alternativ können wir die kollinearen unabh. Variablen zu Indexvariablen zusammenfassen. Wir würden also einen gemeinsamen Index, bspw. der Mittelwert über die jeweiligen unabh. Variablen, erstellen.\n\n\n\n8.9.7 Regressionsmodelle vergleichen\nMit dem Paket {performance} können wir auch einen umfassenden Modellvergleich bekommen:\n\ninstall.packages(\"performance\")\n\n\nlibrary(performance)\ncompare_performance(m1,m4,metrics = c(\"R2\",\"R2_adj\"))\n\nWarning: When comparing models, please note that probably not all models were fit\n  from same data.\n\n\n# Comparison of Model Performance Indices\n\nName | Model |    R2 | R2 (adj.)\n--------------------------------\nm1   |    lm | 0.486 |     0.400\nm4   |    lm | 0.700 |     0.400\n\n\n\n\n8.9.8 Individuelle Koeffizientenplots mit {broom}\nmodelplot() bietet eine schnelle Art, Koeffizientenplots zu erstellen, allerdings verwende ich häufig {broom}. Mit broom::tidy(..., conf.int = TRUE) bekommen wir einen data.frame mit den Ergebnissen des Regressionsmodells, die wir bspw. in einem {ggplot2} weiterverarbeiten können - wenn uns die Standardlösung von modelplot() nicht weiterhilft/gefällt:\n\nlibrary(broom) ## schon geladen als Teil des tidyverse\ntidy(m3, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term         estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)      4.5       6.26     0.719   0.512    -12.9      21.9\n2 ed_fctmedium     7.17      8.08     0.887   0.425    -15.3      29.6\n3 ed_fcthigh      -1.5       8.85    -0.170   0.874    -26.1      23.1\n\ntidy(m3, conf.int = TRUE) %&gt;% \n  mutate(term = str_replace(term, \"ed_fct\", \"Education: \")) %&gt;% \n  ggplot(aes(y = term, x = estimate)) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\", color = \"navy\") +\n  geom_errorbarh(aes(xmin = conf.low, xmax  = conf.high), height = .1) + \n  geom_point(color = \"orange\", shape = 18,size = 7) +\n  theme_minimal(base_size = 16)"
  },
  {
    "objectID": "09_reg2.html#complcses",
    "href": "09_reg2.html#complcses",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.1 Nur vollständige Zeilen behalten",
    "text": "9.1 Nur vollständige Zeilen behalten\nWenn wir die beiden Modelle m1 und m3 vergleichen, sehen wir unterschiedliche Fallzahlen:\n\nm1 &lt;- lm(var2~ var1, data = dat1)  \nm4 &lt;- lm(var2 ~ ed_fct  + var1, dat1)\nmodelsummary(list(\"m1\"=m1,\"m4\"=m4),gof_omit = \"IC|RM|Log|F\",output = \"flextable\")\n\n\n m1m4(Intercept)-2.340-2.511(4.345)(5.681)var11.8391.753(0.773)(0.835)ed_fctmedium4.830(6.038)ed_fcthigh-3.253(6.554)Num.Obs.87R20.4860.700R2 Adj.0.4000.400\n\n\nEs zeigt sich, dass in Modell m4 mit edu_fct 1 Fall verloren geht. Woran liegt das? Dazu lohnt sich ein Blick in die Daten:\n\ndat1\n\n  id var1 var2 educ gend  x ed_fct\n1  1    2    2    3    2  2   high\n2  2    1    2    1    1  1  basic\n3  3    2    1    2    1  2 medium\n4  4    5    9    2    2  4 medium\n5  5    7    7    1    1  1  basic\n6  6    8    4    3    2 NA   high\n7  7    9   25    2    1 NA medium\n8  8    5    3   -1    2 NA   &lt;NA&gt;\n\n\nDie Angabe für ed_fct fehlt in für id = 8.\nUm die Modelle zu vergleichen sollten wir also nur die Zeilen verwenden, für die auch die Werte für ed_fct vorliegen. Hier können wir diese Zeilen per Hand auswählen (und id=8 ausschließen), in größeren Datensätzen ist das aber mühsam.\n\n9.1.1 complete.cases()\nHier hilft uns complete.cases(). Diese Funktion erstellt eine logische Variable, welche ein TRUE für alle vollständigen Fälle (also ohne ein NA). Unvollständige Fälle werden mit einem FALSE versehen. Dazu geben wir an, welche Variablen jeweils für diese Betrachtung berücksichtigt werden sollen und legen die Variable einfach im Datensatz als neue Spalte an. Für Modell 1 ist ein Fall complete, wenn var2 und var1 vorliegen. Wir wählen also mit select() die relevanten Variablen aus und wenden complete.cases auf diese Auswahl an:\n\ndat1 %&gt;% select(var1,var2) %&gt;% complete.cases(.) \n\n[1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE\n\ndat1$compl_m1 &lt;- dat1 %&gt;% select(var1,var2) %&gt;% complete.cases(.) \ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1\n1  1    2    2    3    2  2   high     TRUE\n2  2    1    2    1    1  1  basic     TRUE\n3  3    2    1    2    1  2 medium     TRUE\n4  4    5    9    2    2  4 medium     TRUE\n5  5    7    7    1    1  1  basic     TRUE\n6  6    8    4    3    2 NA   high     TRUE\n7  7    9   25    2    1 NA medium     TRUE\n8  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE\n\n\n\n\n\n\n\n\ncomplete.cases() alleine sucht in allen Variablen nach NA\n\n\n\n\n\nAchtung: wenn wir keine Variablen angeben, werden NA aus allen Variablen berücksichtigt, hier also auch die NA aus x - die uns hier nicht interessieren:\n\ndat1 %&gt;% complete.cases(.) \n\n[1]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE\n\ndat1$compl &lt;- dat1 %&gt;% complete.cases(.) \ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl\n1  1    2    2    3    2  2   high     TRUE  TRUE\n2  2    1    2    1    1  1  basic     TRUE  TRUE\n3  3    2    1    2    1  2 medium     TRUE  TRUE\n4  4    5    9    2    2  4 medium     TRUE  TRUE\n5  5    7    7    1    1  1  basic     TRUE  TRUE\n6  6    8    4    3    2 NA   high     TRUE FALSE\n7  7    9   25    2    1 NA medium     TRUE FALSE\n8  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE FALSE\n\n\n\n\n\n…das gleiche machen wir für Modell m4, welches neben var2 und var1 ja auch noch ed_fct enthält:\n\ndat1$compl_m4 &lt;- dat1 %&gt;% select(var1,var2,ed_fct) %&gt;% complete.cases(.)\n\nSo sieht das dann im Datensatz aus:\n\ndat1\n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl_m4\n1  1    2    2    3    2  2   high     TRUE     TRUE\n2  2    1    2    1    1  1  basic     TRUE     TRUE\n3  3    2    1    2    1  2 medium     TRUE     TRUE\n4  4    5    9    2    2  4 medium     TRUE     TRUE\n5  5    7    7    1    1  1  basic     TRUE     TRUE\n6  6    8    4    3    2 NA   high     TRUE     TRUE\n7  7    9   25    2    1 NA medium     TRUE     TRUE\n8  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE    FALSE\n\n\n\n\n9.1.2 Fälle mit missings finden\nJetzt können wir nach diesen Variablen filtern und uns diese Fälle genauer ansehen. Dazu filtern wir nach den Fällen, die zwar in m1 enthalten (also compl_m1 = TRUE) sind, aber nicht in m4 (compl_m4 = FALSE):\n\ndat1 %&gt;% filter(compl_m1 == T & compl_m4 == F) \n\n  id var1 var2 educ gend  x ed_fct compl_m1 compl_m4\n1  8    5    3   -1    2 NA   &lt;NA&gt;     TRUE    FALSE\n\n\n\n\n9.1.3 Modelle nur mit vollständigen Fällen berechnen\nAußerdem können wir jetzt auch das Modell m1 so erstellen, dass wir nur die Fälle miteinbeziehen, die auch in Modell2 berücksichtigt werden:\n\nm1_m4vars &lt;- lm(var2 ~ var1     , data = filter(dat1,compl_m4 == T))\nmodelsummary(list(\"m1\"=m1,\"m1 mit m4vars\"=m1_m4vars,\"m4\"=m4),gof_omit = \"IC|RM|Log|F\",output = \"flextable\")\n\n\n m1m1 mit m4varsm4(Intercept)-2.340-1.832-2.511(4.345)(4.646)(5.681)var11.8391.8481.753(0.773)(0.814)(0.835)ed_fctmedium4.830(6.038)ed_fcthigh-3.253(6.554)Num.Obs.877R20.4860.5080.700R2 Adj.0.4000.4090.400\n\n\nJetzt haben wir also in m1 mit m4vars und m4 die gleiche Fallzahl und können so die Ergebnisse direkt miteinander vergleichen."
  },
  {
    "objectID": "09_reg2.html#inter",
    "href": "09_reg2.html#inter",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.2 Interaktionen",
    "text": "9.2 Interaktionen\nInteraktionen zwischen zwei Variablen können wir mit * berechnen:\n\ndat1$g_fct &lt;- factor(dat1$gend,levels = 1:2,\n                     labels = c(\"women\",\"men\"))\nm5 &lt;- lm(var2 ~ var1 * g_fct, dat1)\nsummary(m5)\n\n\nCall:\nlm(formula = var2 ~ var1 * g_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7       8 \n-1.5000  2.6145 -0.8827  4.5000 -7.3687 -1.5000  5.6369 -1.5000 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    -3.1117     4.7702  -0.652   0.5498  \nvar1            2.4972     0.8211   3.041   0.0384 *\ng_fctmen        5.9451     8.4973   0.700   0.5227  \nvar1:g_fctmen  -2.1639     1.5331  -1.411   0.2310  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.493 on 4 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.5177 \nF-statistic: 3.504 on 3 and 4 DF,  p-value: 0.1286\n\n\nInteraktionen sollten immer visualisiert werden. Dafür ist {ggeffects} eine große Hilfe:\n\ninstall.packages(\"ggeffects\")\n\n\nlibrary(ggeffects)\n\nWarning: Paket 'ggeffects' wurde unter R Version 4.2.3 erstellt\n\nggpredict(m5, terms = c(\"var1\",\"g_fct[women,men]\")) %&gt;% plot()\n\n\n\n# oder nebeneinander:\nggpredict(m5, terms = c(\"var1\",\"g_fct[women,men]\")) %&gt;% plot(facet=TRUE)\n\n\n\n\nWir können diese Darstellung mit den bekannten {ggplot2}-Befehlen verändern:\n\nggpredict(m5, terms = c(\"var1\",\"g_fct[women,men]\")) %&gt;% plot() + \n  scale_color_manual(values = c(\"orange\",\"lightskyblue3\"),breaks = c(\"women\",\"men\"),labels=c(\"Frauen\",\"Männer\")) +\n  scale_fill_manual(values = c(\"orange\",\"lightskyblue3\"),breaks = c(\"women\",\"men\"),labels=c(\"Frauen\",\"Männer\")) +\n  labs(title = \"Vorhergesagte Werte für var2\",\n       color = \"Gender\",\n       x = \"Werte für var1\",\n       y = \"Vorhergesagte Werte für var1\")\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale."
  },
  {
    "objectID": "09_reg2.html#quad",
    "href": "09_reg2.html#quad",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.3 Quadratische Terme & Polynome",
    "text": "9.3 Quadratische Terme & Polynome\n\nm6 &lt;- lm(var2 ~ var1 + I(var1^2), dat1 %&gt;% filter(id != 7))\nsummary(m6)\n\n\nCall:\nlm(formula = var2 ~ var1 + I(var1^2), data = dat1 %&gt;% filter(id != \n    7))\n\nResiduals:\n      1       2       3       4       5       6       7 \n-0.5443  1.4334 -1.5443  3.2043  1.2713 -1.0248 -2.7957 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  -1.8580     3.4066  -0.545    0.614\nvar1          2.6481     1.9083   1.388    0.238\nI(var1^2)    -0.2235     0.2110  -1.059    0.349\n\nResidual standard error: 2.524 on 4 degrees of freedom\nMultiple R-squared:  0.5099,    Adjusted R-squared:  0.2648 \nF-statistic: 2.081 on 2 and 4 DF,  p-value: 0.2402\n\n\n\nggpredict(m6, terms = c(\"var1\")) %&gt;% plot()"
  },
  {
    "objectID": "09_reg2.html#gew",
    "href": "09_reg2.html#gew",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.4 Gewichtetes Regressionsmodell",
    "text": "9.4 Gewichtetes Regressionsmodell\n\nlibrary(survey)\npend &lt;- haven::read_dta(\"./orig/PENDDAT_cf_W13.dta\") %&gt;% filter(netges &gt; 0 , palter &gt; 0, azges1 &gt; 0) %&gt;% \n  mutate(zpsex_fct = factor(zpsex, levels = 1:2, labels = c(\"M\",\"W\")))\nwgt_df &lt;- haven::read_dta(\"./orig/pweights_cf_W13.dta\")\npend_wgt &lt;- pend %&gt;% left_join(wgt_df, by = join_by(pnr,welle))\n\n\nmodx &lt;- lm(netges ~ palter + I(palter^2),data=pend)\n\npend_weighted &lt;- svydesign(id      = ~pnr,\n                           weights = ~wqp,\n                           data    = pend_wgt)\n\n# family = gaussian() bekommen wir ein lineares Regressionsmodell, wie bei lm() - mit gewichtet\nsurvey_modx &lt;- svyglm(netges ~ palter + I(palter^2), \n                    family = gaussian(), data = etb18,design = pend_weighted)\n\nmodelsummary(list(\"lm()\"=modx,\"svyglm()\"= survey_modx),gof_omit = \"RM|IC|Log\",output = \"flextable\")\n\n\n lm()svyglm()(Intercept)811.753463.721(354.363)(504.015)palter24.64053.580(17.071)(26.471)I(palter^2)-0.147-0.489(0.197)(0.314)Num.Obs.79967996R20.0040.007R2 Adj.0.004-2.252F15.5258.495"
  },
  {
    "objectID": "09_reg2.html#rbst",
    "href": "09_reg2.html#rbst",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.5 “Robuste” Standardfehler",
    "text": "9.5 “Robuste” Standardfehler\nHäufig müssen die Standardfehler an Verstöße gegen die allgemeinen Annahmen (Homoskedastizität usw.) angepasst werden.\nDie gute Nachricht ist, dass R eine ganze Reihe an Möglichkeiten bietet, Standard-Fehler zu korrigieren. Unter anderem mit {sandwich} oder {estimatr}.\nEine sehr einfache Variante ist die Korrektur von Standardfehlern in {modelsummary}, die wir uns etwas genauer ansehen:\nWir können sog. heteroskedasticity-consistent (HC) “robuste” Standardfehler mit der vcov-Option HC in modelsummary() anfordern. Die Hilfe-Seite für {modelsummary} bietet eine Liste mit allen Optionen.\nEine Option ist auch stata, um Ergebnisse aus Statas , robust zu replizieren. Hier mehr zu den Hintergründen und Unterschieden.\nBasierend auf den oben eingelesenen Daten können wir folgendes Modell schätzen:\n\nmod1 &lt;- lm(netges ~ palter + I(palter^2),data=pend) \n\nlibrary(modelsummary)\nmodelsummary(list(mod1,mod1,mod1,mod1),vcov = c(\"classical\",\"HC\",\"HC2\",\"stata\"),gof_omit = \"RM|IC|Log\",output = \"flextable\")\n\n\n (1)(2)(3)(4)(Intercept)811.753811.753811.753811.753(354.363)(171.599)(171.543)(171.520)palter24.64024.64024.64024.640(17.071)(8.923)(8.920)(8.919)I(palter^2)-0.147-0.147-0.147-0.147(0.197)(0.112)(0.112)(0.112)Num.Obs.7996799679967996R20.0040.0040.0040.004R2 Adj.0.0040.0040.0040.004F15.52523.44923.44123.440Std.ErrorsIIDHCHC2HC1\n\n\nFür geclusterste SE geben wir ~clustervariable an;\n\nmodelsummary(mod1, vcov = c(\"classical\",~pnr), stars = T,gof_omit = \"RM|IC|Log|F\",output = \"flextable\")\n\n\n (1)(2)(Intercept)811.753*811.753**(354.363)(274.972)palter24.64024.640+(17.071)(14.475)I(palter^2)-0.147-0.147(0.197)(0.185)Num.Obs.79967996R20.0040.004R2 Adj.0.0040.004Std.ErrorsIIDby: pnr+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001"
  },
  {
    "objectID": "09_reg2.html#fe",
    "href": "09_reg2.html#fe",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.6 Fixed effects Modelle mit {fixest}",
    "text": "9.6 Fixed effects Modelle mit {fixest}\n\ninstall.packages(\"fixest\")\n\n{fixest}) bietet eine große Auswahl an Möglichkeiten: logistische FE-Modelle, mehr-dimensionale Fixed Effects, Multiway clustering, … Und es ist sehr schnell, bspw. schneller als Statas reghdfe. Für mehr Details empfiehlt sich die Vignette.\nDie zentrale Funktion zur Schätzung linearer FE-Regressionsmodelle ist feols() - sie funktioniert ganz ähnlich zu lm(). Auch hier geben wir wieder eine Formel nach dem Schema abhängige Variabe ~ unabhängige Variable(n) an. Wir fügen lediglich mit | die Variable hinzu, welche die FEs festlegt:\n\nlibrary(fixest)\nfe_mod1 &lt;- feols(netges ~ palter + I(palter^2) | pnr, data = pend)\nfe_mod1\n\nOLS estimation, Dep. Var.: netges\nObservations: 7,996 \nFixed-effects: pnr: 2,444\nStandard-errors: Clustered (pnr) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \npalter      133.811281  14.558248  9.19144  &lt; 2.2e-16 ***\nI(palter^2)  -0.848429   0.154417 -5.49441 4.3261e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1,222.2     Adj. R2: 0.513287\n                Within R2: 0.009765\n\n\n{fixest} clustert automatisch die Standardfehler entlang der FE-Variable (hier also pnr). Wenn wir das mal nicht möchten, können wir mit der se-Option = \"standard\" ungeclusterte SE anfordern:\n\nsummary(fe_mod1, se = 'standard')\n\nOLS estimation, Dep. Var.: netges\nObservations: 7,996 \nFixed-effects: pnr: 2,444\nStandard-errors: IID \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \npalter      133.811281  39.896986  3.35392 0.00080209 ***\nI(palter^2)  -0.848429   0.429629 -1.97479 0.04834109 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1,222.2     Adj. R2: 0.513287\n                Within R2: 0.009765\n\nsummary(fe_mod1, cluster = ~pnr)\n\nOLS estimation, Dep. Var.: netges\nObservations: 7,996 \nFixed-effects: pnr: 2,444\nStandard-errors: Clustered (pnr) \n              Estimate Std. Error  t value   Pr(&gt;|t|)    \npalter      133.811281  14.558248  9.19144  &lt; 2.2e-16 ***\nI(palter^2)  -0.848429   0.154417 -5.49441 4.3261e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nRMSE: 1,222.2     Adj. R2: 0.513287\n                Within R2: 0.009765\n\n\n{modelsummary} zeigt die geclusterten SE:\n\nmodelsummary(fe_mod1,gof_omit = \"R|IC|Log|F\",stars = T,output = \"flextable\")\n\n\n (1)palter133.811***(14.558)I(palter^2)-0.848***(0.154)Num.Obs.7996Std.Errorsby: pnr+ p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001"
  },
  {
    "objectID": "09_reg2.html#mlvl",
    "href": "09_reg2.html#mlvl",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.7 Mehrebenenmodelle mit {lme4}",
    "text": "9.7 Mehrebenenmodelle mit {lme4}\nMit lmer() können wir ein Random Intercept Modell berechnen, indem wir mit ( 1 | pnr) angeben, dass für pnr jeweils ein eigenes Random Intercept berechnet werden soll:\n\nlibrary(lme4)\nml_m3 &lt;- lmer(netges ~ palter + I(palter^2) + ( 1 | pnr), data=pend)\n\nmodelsummary(list(ml_m3),gof_omit = \"R|IC|Log|F\",output = \"flextable\")\n\n\n (1)(Intercept)754.388(392.459)palter18.523(19.083)I(palter^2)-0.020(0.222)SD (Intercept pnr)1327.674SD (Observations)1414.455Num.Obs.7996\n\n\nMehr zu Mehrebenenmodellen und {lme4} in Blogposts von Rense Nieuwenhuis und Tristan Mahr."
  },
  {
    "objectID": "09_reg2.html#anhang-predictions-mit-marginaleffects-und-manuelle-darstellung",
    "href": "09_reg2.html#anhang-predictions-mit-marginaleffects-und-manuelle-darstellung",
    "title": "9  Regressionsmodelle: Erweiterungen",
    "section": "9.8 Anhang: Predictions mit marginaleffects und “manuelle” Darstellung",
    "text": "9.8 Anhang: Predictions mit marginaleffects und “manuelle” Darstellung\nWir hatten im Kapitel Interaktionen folgendes Modell geschätzt:\n\nsummary(m5)\n\n\nCall:\nlm(formula = var2 ~ var1 * g_fct, data = dat1)\n\nResiduals:\n      1       2       3       4       5       6       7       8 \n-1.5000  2.6145 -0.8827  4.5000 -7.3687 -1.5000  5.6369 -1.5000 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)    -3.1117     4.7702  -0.652   0.5498  \nvar1            2.4972     0.8211   3.041   0.0384 *\ng_fctmen        5.9451     8.4973   0.700   0.5227  \nvar1:g_fctmen  -2.1639     1.5331  -1.411   0.2310  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.493 on 4 degrees of freedom\nMultiple R-squared:  0.7244,    Adjusted R-squared:  0.5177 \nF-statistic: 3.504 on 3 and 4 DF,  p-value: 0.1286\n\n\nMit predictions() aus {marginaleffects} können wir basierend auf unserem Modell vorhergesagte Werte für bestimmte Werte berechnen. Dazu geben wir die die gewünschten mit einem expand.grid() an.\n\n# Kombinationen aller Werte erstellen\nexpand.grid(var1 = 1:5, \n            g_fct =  c(\"women\",\"men\"))\n\n   var1 g_fct\n1     1 women\n2     2 women\n3     3 women\n4     4 women\n5     5 women\n6     1   men\n7     2   men\n8     3   men\n9     4   men\n10    5   men\n\n\nDiese Werte geben wir dann in predictions() als newdata = an:\n\nlibrary(marginaleffects)\np &lt;- predictions(m5, \n                 newdata = expand.grid(var1 = 1:5,\n                                       g_fct =  c(\"women\",\"men\")) )\n                 \nhead(data.frame(p))\n\n  rowid   estimate std.error  statistic      p.value  conf.low conf.high var1\n1     1 -0.6145251  4.126052 -0.1489378 0.8816027065 -8.701438  7.472388    1\n2     2  1.8826816  3.555532  0.5295076 0.5964533448 -5.086034  8.851397    2\n3     3  4.3798883  3.099641  1.4130307 0.1576466975 -1.695297 10.455074    3\n4     4  6.8770950  2.814641  2.4433298 0.0145524331  1.360501 12.393689    4\n5     5  9.3743017  2.754104  3.4037579 0.0006646564  3.976358 14.772245    5\n6     6  3.1666667  5.861938  0.5402082 0.5890534765 -8.322520 14.655853    1\n  g_fct var2\n1 women    2\n2 women    2\n3 women    2\n4 women    2\n5 women    2\n6   men    2\n\n\nFür den ggplot() verwenden wir dann geom_line() zusammen mit\n\ngeom_errorbar() für eine Darstellung mit Konfidenzintervallen als Error Bars\nmit geom_ribbon() erhalten wir die Konfidenzintervalle als Konfidenzbänder (hier müssen wir mit alpha = die Deckkraft der etwas heruntersetzen und die Farbe mit fill= angeben um den Bereich einzufärben).\n\n\npred_plt &lt;- \n    ggplot(data= data.frame(p),\n           aes(x = var1, \n               y =  estimate, \n               ymin = conf.low,ymax = conf.high,\n               color = g_fct)) + \n      geom_line() + \n      scale_color_manual(values = c(\"orange\",\"lightskyblue3\"),breaks = c(\"women\",\"men\"),labels=c(\"Frauen\",\"Männer\")) +\n      labs(title = \"Vorhergesagte Werte für var2\",\n           color = \"Gender\",\n           x = \"Werte für var1\",\n           y = \"Vorhergesagte Werte für var1\") +\n      theme_minimal()\n\n# Konfidenzintervalle\npred_plt + \n  geom_point(size = 2.75) +\n  geom_errorbar(width = .1)\n# mit Konfidenzbändern\npred_plt + \n  geom_ribbon(alpha = .1, color = NA,aes(fill = g_fct)) +\n  scale_fill_manual(values = c(\"orange\",\"lightskyblue3\"),breaks = c(\"women\",\"men\"),labels=c(\"Frauen\",\"Männer\")) +\n  labs(fill = \"Gender\")"
  },
  {
    "objectID": "10_log_reg.html#logmod",
    "href": "10_log_reg.html#logmod",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.1 Das logistische Regressionsmodell",
    "text": "10.1 Das logistische Regressionsmodell\nSomit sieht unser logistisches Regressionsmodell in der allgemeinen Schreibweise wie folgt aus:\n\\[\\begin{equation*}\n\\widehat{Logit(soc\\_med=1)} = \\widehat{ln\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{palter}\n\\end{equation*}\\]\nIn R können wir ein solches Modell mit glm() und der Option family=\"binomial\" berechnen:2\n\nm2 &lt;- glm(soc_med ~ palter, family = \"binomial\", data = pend11)\nsummary(m2)\n\n\nCall:\nglm(formula = soc_med ~ palter, family = \"binomial\", data = pend11)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.1014  -0.9246  -0.4485   0.8999   2.4047  \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.194321   0.107660   29.67   &lt;2e-16 ***\npalter      -0.073518   0.002315  -31.75   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 7557.2  on 5461  degrees of freedom\nResidual deviance: 6217.5  on 5460  degrees of freedom\n  (22962 Beobachtungen als fehlend gelöscht)\nAIC: 6221.5\n\nNumber of Fisher Scoring iterations: 3\n\n\nDie Interpretation der \\(\\beta\\) aus einem logistischen Regressionsmodell bezieht sich also auf die Logits (die logarithmierten Odds):\n\nEs besteht ein am 0,001-Niveau signifikanter Zusammenhang zwischen dem Alter und der Wahrscheinlichkeit, Social Media zu verwenden. Mit einem um 1 Jahr Lebensalter Einkommen gehen um 0.073518 niedrigere Logits einher, dass die Befragten Social Media zu verwenden."
  },
  {
    "objectID": "10_log_reg.html#average-marginal-effects",
    "href": "10_log_reg.html#average-marginal-effects",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.2 average marginal effects",
    "text": "10.2 average marginal effects\nLogits sind aber sehr unhandlich - wie verändert sich jetzt aber die Wahrscheinlichkeit für \\(\\texttt{soc\\_med} = 1\\) mit palter? Hier haben wir das Problem, dass die Ableitung der “rücktransformierten Funktion” nicht so einfach ist wie im Fall der OLS. Verändern wir nämlich auch die Regressionsgleichung von oben3 mit exp() und \\(p=\\frac{Odds}{1+Odds}\\), so landen wir bei\n\\[\\begin{equation*}\n\\widehat{P(soc\\_med=1)} = \\frac{e^{\\hat\\beta0+\\hat\\beta1 \\times \\texttt{palter}}}{1+e^{\\hat\\beta0+\\hat{\\beta1}\\times \\texttt{palter}}}\n\\end{equation*}\\]\nDiesen Ausdruck müssten wir nach palter ableiten, um eine Antwort zu bekommen um wieviel sich die vorhergesagte Wahrscheinlichkeit für \\(\\texttt{soc\\_med} = 1\\) mit einem um einen Jahr höheren Befragtenalter verändert. Durch die Tatsache dass palter hier im Exponenten der e-Funktion und sowohl im Dividenden als auch Divisor (“oben und unten”) steht, wird die Ableitung hier aber deutlich komplizierter als das in den bisherigen lm()-Modellen der Fall war. Für uns ist an dieser Stelle aber nur wichtig, dass wir für die Berechnung der Veränderung der vorhergesagten Wahrscheinlichkeiten die sog. marginalen Effekte aus dem Paket {marginaleffects} brauchen. Darin findet sich der Befehl avg_slopes(), welcher uns erlaubt ein \\(\\beta\\) zwischen dem Einkommen und der Wahrscheinlichkeit für \\(\\texttt{soc\\_med} = 1\\) zu berechnen. Dieses wird auch als average marginal effect bezeichnet, da sie den durchschnittlichen marginalen Effekt der betrachteten unabhängigen Variable auf die abhängige Variable wiedergeben.\n\ninstall.packages(\"marginaleffects\") # nur einmal nötig\nlibrary(marginaleffects)\n\n\navg_slopes(m2)\n\n\n   Term Estimate Std. Error     z Pr(&gt;|z|)   2.5 %  97.5 %\n palter  -0.0142   0.000266 -53.4   &lt;0.001 -0.0147 -0.0137\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high \n\n\n\nMit einem um 1 Jahr höheren Lebensalter geht im Durchschnitt eine um 0.01419 (1.41891 Prozentpunkte) geringere Wahrscheinlichkeit einher, Social Media zu verwenden."
  },
  {
    "objectID": "10_log_reg.html#predictions",
    "href": "10_log_reg.html#predictions",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.3 Predictions",
    "text": "10.3 Predictions\nAlternativ können die Ergebnisse aus log. Regressionen auch als vorhergesagte Werte dargestellt werden. Vorhergesagte Werte können wir mit predictions() aus {marginaleffects} erstellen:\n\npredictions(m2, newdata = datagrid(palter  = c(18,25,65))) \n\n\n Estimate Pr(&gt;|z|) 2.5 % 97.5 % palter\n    0.867   &lt;0.001 0.850  0.881     18\n    0.795   &lt;0.001 0.777  0.812     25\n    0.170   &lt;0.001 0.155  0.186     65\n\nColumns: rowid, estimate, p.value, conf.low, conf.high, soc_med, palter \n\n\nDas können wir in einem ggplot() grafisch darstellen:\n\navg_predictions(m2, variables = list(palter  = 18:65)) %&gt;% # vorhergesagte Werte\n  data.frame() %&gt;% \n  ggplot(aes(y = estimate , x = palter)) + \n  geom_errorbar(aes(ymin = conf.low, ymax= conf.high), color = \"slateblue\",width = .1) + # konfidenzintervalle\n  geom_point(color = \"slateblue\") + # punktschätzer\n  theme_minimal()"
  },
  {
    "objectID": "10_log_reg.html#übung-1",
    "href": "10_log_reg.html#übung-1",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.4 Übung 1",
    "text": "10.4 Übung 1"
  },
  {
    "objectID": "10_log_reg.html#feglm",
    "href": "10_log_reg.html#feglm",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.5 Fixed effects logistische Regression mit {fixest}",
    "text": "10.5 Fixed effects logistische Regression mit {fixest}\nMit feglm() lassen sich auch logistische FE-Modelle schätzen:\n\nlibrary(fixest)\nfeglm(soc_med ~ palter |pnr, data = pend11, family = binomial)\n\nNOTES: 22,962 observations removed because of NA values (LHS: 22,962, RHS: 60).\n       2,284 fixed-effects (4,563 observations) removed because of only 0 (or only 1) outcomes.\n\n\nGLM estimation, family = binomial, Dep. Var.: soc_med\nObservations: 899 \nFixed-effects: pnr: 332\nStandard-errors: Clustered (pnr) \n       Estimate Std. Error  t value Pr(&gt;|t|) \npalter 0.097697   0.118551 0.824096  0.40988 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nLog-Likelihood:  -582.6   Adj. Pseudo R2: -0.468364\n           BIC: 3,430.1     Squared Cor.:  0.08793 \n\nfe_log1 &lt;- feglm(soc_med ~ palter |pnr, data = pend11, family = binomial)\n\nNOTES: 22,962 observations removed because of NA values (LHS: 22,962, RHS: 60).\n       2,284 fixed-effects (4,563 observations) removed because of only 0 (or only 1) outcomes.\n\navg_slopes(fe_log1,by = TRUE, variables = \"palter\")\n\n\n   Term Estimate Std. Error     z Pr(&gt;|z|)   2.5 % 97.5 %\n palter   0.0223     0.0313 0.711    0.477 -0.0391 0.0837\n\nColumns: term, estimate, std.error, statistic, p.value, conf.low, conf.high"
  },
  {
    "objectID": "10_log_reg.html#ame1",
    "href": "10_log_reg.html#ame1",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.6 Übung",
    "text": "10.6 Übung\n\netb_ue10 &lt;- haven::read_dta(\"./data/BIBBBAuA_2018_suf1.0.dta\",\n                            col_select = c(\"F1605e\",\"m1202\")) %&gt;% \n  filter(F1605e &lt; 4, !is.na(F1605e), m1202 %in% 1:4) %&gt;% \n  mutate(fam_beruf = 2-F1605e,\n         m1202 = factor(m1202))\n\n\nErstellen Sie ein logistisches Regressionsmodell mit PAS0400 basierend auf der Frage\n\nNicht-Erwerbstaetige: Stellensuche in den letzten vier Wochen?\nals abhängiger Variable (1 = ja, 0 = nein.) Verwenden Sie die Ausbildung palter als unabhängige Variable.\nBerechnen Sie die AME mit marginaleffects."
  },
  {
    "objectID": "10_log_reg.html#anhang-hintergrund-zu-log.-regression-average-marginal-effects",
    "href": "10_log_reg.html#anhang-hintergrund-zu-log.-regression-average-marginal-effects",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.7 Anhang: Hintergrund zu log. Regression & average marginal effects",
    "text": "10.7 Anhang: Hintergrund zu log. Regression & average marginal effects\nWenn wir uns fragen, ob sich Befragte mit höherem Einkommen seltener im Freien arbeiten, hilft uns die OLS-Vorgehensweise nicht so richtig weiter. Die “Punktewolke” zur Optimierung der Abweichung zwischen tatsächlichen und vorhergesagten Werten (Residuen) sieht hier anders aus als bisher:\n\n\nCode\nggplot(pend11, aes(x = palter, y = soc_med)) +\n  geom_point(color = \"#172869\") +\n  theme(aspect.ratio = .75)\n\n\n\n\n\n\n\n\n\nUm trotzdem ein Regressionsmodell zu berechnen, könnten wir die abhängige Variable uminterpretieren. \\(\\hat{y}\\) wird dann nicht mehr dichotom, sondern als metrische Wahrscheinlichkeit interpretiert, dass der Befragte mehr als die Hälfte der Arbeitszeit im Freien arbeitet (also die Wahrscheinlichkeit für soc_med = 1). Das können wir dann wie gehabt in eine Regressionsgleichung aufnehmen, zB. mit dem Einkommen als unabhängiger Variable:\n\\[\\begin{equation*}\n\\widehat{y_i} = P(soc\\_med\\texttt{\\small{=}}1) = \\hat\\beta0 + \\hat\\beta1 * \\texttt{palter}_i\n\\end{equation*}\\]\nAllerdings führt das zwangsläufig zu Verstößen gegen die Annahmen bzgl. der Residuen - die Fehler werden immer heteroskedastisch und nicht normalverteilt sein. Zudem wird es vorhergesagte Werte geben, die nicht sinnvoll interpretiert werden können, weil es mit 0 und 1 Grenzen gibt, jenseits derer Wahrscheinlichkeiten nicht existieren (zB gibt es keine negativen Wahrscheinlichkeiten).\n\n\nCode\nggplot(pend11, aes(x = palter, y = soc_med)) +\n  geom_point(color = \"#172869\", size = .75) +\n  geom_smooth(method = \"lm\", color = lacroix_palette(\"PeachPear\",6)[2],se = F ) + \n  labs(y = \"P(soc_med = 1)\", x = \"Einkommen (in 100 EUR)\",\n       title = \"lineares Wahrscheinlichkeitsmodell\")\n\n\n\n\n\n\n\n\n\n\nlibrary(ggfortify)\nautoplot(m1,which = 1:2) # Homosk. & NV \n\n\n\n\n\n\n\n\n\n\n\n10.7.1 Logistische Linkfunktion\nUm diese Probleme zu umgehen, sind für dichotome abhängige Variablen logistische Regressionsmodelle ein sehr verbreitetes Vorgehen. Dafür werden neben dem bereits angesprochenen Schritt der Betrachtung von \\(\\hat{y}\\) als Wahrscheinlichkeit zwei weitere Transformationen der abhängigen Variable vorgenommen:\n\nOdds statt Wahrscheinlichkeiten: Um die obere Grenze des Wertebereichs der abhängigen Variablen auf \\(+\\infty\\) auszudehnen, werden statt Wahrscheinlichkeiten Odds betrachtet. Odds sind definiert als der Quotient aus Wahrscheinlichkeit und der Gegenwahrscheinlichkeit für ein gegebenes Ereignis. In unserem Beispiel sind also die Odds dafür, dass eine Befragter angibt, social media zu nutzen:\n\n\\[Odds(soc\\_med=1) = \\frac{P(soc\\_med=1)}{P(soc\\_med=0)}= \\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)} \\]\nDie Odds gehen gegen 0, je unwahrscheinlicher das betrachtete Ereignis ist. Für sehr wahrscheinliche Ereignisse nehmen die Odds Werte an, die gegen \\(+\\infty\\) gehen, das Verhältnis zwischen Dividend (“Zähler”) und Divisor (“Nenner”) wird immer größer.\n\nLogits statt Odds: Damit bleibt aber noch das Problem der negativen Werte bestehen: Auch Odds sind nur für [0;\\(+\\infty\\)] definiert. Um auch den negativen Wertebereich sinnvoll interpretierbar zu machen, werden die Odds logarithmiert, wir erhalten die sogenannten Logits:\n\n\\[Logit(soc\\_med=1) = log(Odds(soc\\_med=1)) = log\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)\\]\nDie Logarithmierung führt für Werte zwischen 0 und 1 zu negativen Werten, für Werte größer als 1 zu positiven Werten.\nDementsprechend gibt es bei logistischen Regressionen drei Einheiten:\n\nWahrscheinlichkeiten \\(P = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl aller Möglichkeiten}}\\)\n\\(\\text{Odds} = \\frac{P}{1-P} = \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}}\\)\n\\(\\text{log-Odds/Logits} = log(Odds) = log( \\frac{\\text{Anzahl Treffer}}{\\text{Anzahl Nicht-Treffer}})\\)\n\n\n\n\n\n\n\n\n\n\n\n$$P$$\n$$Odds = \\frac{P}{1-P}$$\n\n$$Logits = log(Odds)$$\n\n\n\n\n\n$$\\frac{1}{2}$$\n\n\n$$1$$\n\n\noder 1:1\n\n\n0\n\n\n\n\n$$\\frac{1}{3}$$\n\n\n$$0.5$$\n\n\noder 1:2\n\n\n-0.6931\n\n\n\n\n$$\\frac{1}{4}$$\n\n\n$$0.33$$\n\n\noder 1:3\n\n\n-1.0986\n\n\n\n\n$$\\frac{1}{5}$$\n\n\n$$0.25$$\n\n\noder 1:5\n\n\n-1.3863\n\n\n\n\n$$\\frac{2}{3}$$\n\n\n$$2$$\n\n\noder 2:1\n\n\n0.6931\n\n\n\n\n$$\\frac{3}{4}$$\n\n\n$$3$$\n\n\noder 3:1\n\n\n1.0986\n\n\n\n\n$$1$$\n\n\n$$\\frac{1}{0}$$\n\n\nsicher\n\n\nInf\n\n\n\n\n\n\n\n\n\n\n10.7.2 Vorhergesagte Werte\nZunächst stellt sich die Frage, was Logits denn bedeuten. Eigentlich möchten wir ja Wahrscheinlichkeiten im Wertebereich zwischen 0 und 1 (bzw. 0% und 100%) als Interpretationseinheit haben. Die Berechnung eines vorhergesagten Werts für einen Befragten mit einem Alter von 25 Jahren (palter=25) ergibt durch einsetzen bzw. predict() natürlich auch die Logits:\n\nsummary(m2)$coefficients\n\n              Estimate  Std. Error   z value      Pr(&gt;|z|)\n(Intercept)  3.1943207 0.107659911  29.67048 1.846515e-193\npalter      -0.0735175 0.002315329 -31.75251 2.931805e-221\n\n3.1943207    + -0.0735175  * 25\n\n[1] 1.356383\n\npredict(m2, data.frame(palter = 25))\n\n       1 \n1.356383 \n\n\n\nBefragte mit einem Alter von 25 Jahren haben dem Modell zu Folge Logits von 1.35638, social media zu verwenden.\n\nUm an die Wahrscheinlichkeit für soc_med = 1 zu bekommen, müssen wir die Transformationsschritte sozusagen “rückabwickeln”! Dafür müssen wir zunächst mit exp den ln() vor den Odds heraus rechnen und können dann durch die die Formel \\(p=\\frac{Odds}{1+Odds}\\) die Wahrscheinlichkeit aus den odds berechnen:\n\nlogits &lt;- predict(m2, data.frame(palter = 25)) \nexp(logits) # Odds statt Logits\n\n       1 \n3.882127 \n\nodds &lt;- exp(logits) \nodds/(1+odds) # Wahrscheinlichkeit statt Odds \n\n        1 \n0.7951712 \n\nexp(logits)/(1+exp(logits)) # beide Schritte auf einmal\n\n        1 \n0.7951712 \n\n\n\nDie Wahrscheinlichkeit, dass ein Befragter mit einem Einkommen von 1000 Euro angibt, mehr als die Hälfte Ihrer Arbeitszeit im Freien zu arbeiten, liegt also unserem Modell zu Folge bei 92.123%.\n\nMit der Option type=\"response\" können wir das auch mit predict() direkt berechnen:\n\npredict(m2, data.frame(palter = 25), type=\"response\")\n\n        1 \n0.7951712 \n\n\n\n\n10.7.3 Die Idee von average marginal effects\nWie verändern sich dann die vorhergesagten Werte, wenn wir palter um eine Einheit (also 100€) erhöhen? Die Logits verändern sich pro Einheit palter natürlich genau um \\(\\hat\\beta1\\), also hier -0.07352. Um sich die Steigung an einigen Werten anzusehen, berechnen wir jeweils die Abstände der vorhergesagten Werte für \\(x-0.5\\) und \\(x+0.5\\):\nUm die Werte jeweils mit dem eingesetzten Wert zu beschriften, stellen wir den Wert mit  \"\"= voran:\n\npredict(m2, data.frame(palter=c(\"19.5\"=19.5,\"20.5\"=20.5,\"30.5\"=30.5,\"31.5\"=31.5,\n                                \"54.5\"=54.5,\"55.5\"=55.5)))\n\n      19.5       20.5       30.5       31.5       54.5       55.5 \n 1.7607294  1.6872119  0.9520369  0.8785194 -0.8123832 -0.8859007 \n\n\nDie Differenzen sind immer gleich - entsprechend der Interpretation gehen mit einem um eine Einheit höheren palter um 0.07352 höhere Logits einher, dass die Befragten Social Media verwenden:\n\nSteigung bei palter = 20: 1.68721 \\(-\\) 1.76073 = -0.07352 \nSteigung bei palter = 31: 0.87852 \\(-\\) 0.95204 = -0.07352 \nSteigung bei palter = 45: -0.88590 \\(-\\) -0.81238 = -0.07352 \n\nWenn wir uns diese Schritte aber jeweils für die vorhergesagten Wahrscheinlichkeiten ansehen, sieht das aber anders aus:\n\npredict(m2, data.frame(palter=c(\"19.5\"=19.5,\"20.5\"=20.5,\"30.5\"=30.5,\"31.5\"=31.5,\n                                \"54.5\"=54.5,\"55.5\"=55.5)), type = \"response\")\n\n     19.5      20.5      30.5      31.5      54.5      55.5 \n0.8533010 0.8438571 0.7215246 0.7065153 0.3073829 0.2919565 \n\n\nHier werden die Differenzen mit zunehmendem palter immer kleiner:\n\nSteigung bei palter = 20: 0.84386 \\(-\\) 0.85330 = -0.00944 \nSteigung bei palter = 31: 0.70652 \\(-\\) 0.72152 = -0.01501 \nSteigung bei palter = 55: 0.29196 \\(-\\) 0.30738 = -0.01543 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiese Steigungen werden für alle Beobachtungen aus dem zu Grunde liegenden Datensatz aufsummiert und dann der Durchschnitt gebildet (\\(\\rightarrow\\) average marginal effects)"
  },
  {
    "objectID": "10_log_reg.html#links",
    "href": "10_log_reg.html#links",
    "title": "10  Logistische Regressionsmodelle",
    "section": "10.8 Links",
    "text": "10.8 Links\n\nDie Seite zu {marginaleffects} bietet sehr ausführliche und anschauliche Beispiele zu den verschiedenen Varianten marginaler Effekte\nAusführliche Einführung zu marginalen Effekten von Andrew Heiss\n\nAbleitungen grafisch erstellt"
  },
  {
    "objectID": "10_log_reg.html#footnotes",
    "href": "10_log_reg.html#footnotes",
    "title": "10  Logistische Regressionsmodelle",
    "section": "",
    "text": "Leseempfehlung: Logistische Regression von Henning Best & Christof Wolf, S. 827-854 in “Handbuch der sozialwissenschaftlichen Datenanalyse”↩︎\nfamily=\"binomial\" ist dabei entscheidend: glm(soc_med ~ palter, data = pend11) oder glm(soc_med ~ palter, family = gaussian(), data = pend11) ist gleichbedeutend mit lm(soc_med ~ palter, data = pend11): es wird ein lineares OLS-Modell berechnet.↩︎\n\\(\\widehat{Logit(soc\\_med=1)} = \\widehat{ln\\left(\\frac{P(soc\\_med=1)}{1-P(soc\\_med=1)}\\right)} = \\hat\\beta0 + \\hat{\\beta1}\\times \\texttt{palter}\\)↩︎"
  }
]